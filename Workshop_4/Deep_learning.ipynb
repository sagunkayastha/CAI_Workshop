{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagunkayastha/CAI_Workshop/blob/main/Workshop_4/Deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6C4xBXM_0Ho6"
      },
      "outputs": [],
      "source": [
        "### Change to gpu runtime\n",
        "\n",
        "# Standard Libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random as rn\n",
        "\n",
        "# Visualization libraries\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style({\"axes.facecolor\": \".95\"})\n",
        "\n",
        "# Modeling and Machine Learning\n",
        "from IPython.display import Image\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import accuracy_score\n",
        "# from sklearn.externals.six import StringIO\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "\n",
        "\n",
        "# Seed for reproducability\n",
        "seed = 1234\n",
        "np.random.seed(seed)\n",
        "rn.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6Q2TH890Ho8"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/sagunkayastha/CAI_Workshop/main/Workshop_3/Inputs/test.csv\n",
        "!wget https://raw.githubusercontent.com/sagunkayastha/CAI_Workshop/main/Workshop_3/Inputs/train.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCEfHS3I0Ho8"
      },
      "outputs": [],
      "source": [
        "# Specify Paths for easy dataloading\n",
        "\n",
        "TRAIN_PATH = 'train.csv'\n",
        "TEST_PATH = 'test.csv'\n",
        "\n",
        "# Load in training and testing data\n",
        "train_df = pd.read_csv(TRAIN_PATH)\n",
        "test_df = pd.read_csv(TEST_PATH)\n",
        "concat_df = pd.concat([train_df, test_df])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQjDBH8s0Ho9"
      },
      "outputs": [],
      "source": [
        "# Visualize target distribution\n",
        "train_df['label'].value_counts().sort_index().plot(kind='bar', figsize=(10, 6), rot=0)\n",
        "plt.title('Visualization of class distribution for the MNIST Dataset', fontsize=20, weight='bold')\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.xlabel('Class', fontsize=16)\n",
        "plt.ylabel('Frequency', fontsize=16);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGWAo-vM0Ho9"
      },
      "source": [
        "## Creating single neuron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWiy1LZY0Ho-"
      },
      "outputs": [],
      "source": [
        "\n",
        "def sigmoid(x):\n",
        "    \"\"\"Sigmoid activation function.\"\"\"\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def single_neuron_forward(inputs, weights, bias):\n",
        "    \"\"\"Forward pass through a single neuron using a loop for the weighted sum.\"\"\"\n",
        "    total = 0\n",
        "    for input, weight in zip(inputs, weights):\n",
        "        total += input * weight\n",
        "    # total = np.dot(inputs, weights) + bias\n",
        "\n",
        "\n",
        "    total += bias\n",
        "    return sigmoid(total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnwqWeWd0Ho_"
      },
      "source": [
        "!['inp'](https://raw.githubusercontent.com/sagunkayastha/CAI_Workshop/a4714e1d1c59d5fff5289ed950097251e119f6cc/Workshop_4/images/single_neuron_example.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmVXhAag0Ho_"
      },
      "outputs": [],
      "source": [
        "# Number of inputs to the neuron\n",
        "num_inputs = 3\n",
        "\n",
        "# Initialize weights and bias to random values\n",
        "weights = [0.4,0.9,-0.11]\n",
        "bias = [0.1]\n",
        "\n",
        "# Example input\n",
        "inputs = np.array([0.5, -0.2, 0.1])\n",
        "y_true = 1.12\n",
        "\n",
        "y_pred = single_neuron_forward(inputs, weights, bias)\n",
        "print(\"Output:\", y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVvGaFSI0HpA"
      },
      "source": [
        "Binary Cross-Entropy Loss=−(y⋅log(p)+(1−y)⋅log(1−p))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i48fagYi0HpA"
      },
      "outputs": [],
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "    \"\"\"Binary Cross-Entropy loss function.\"\"\"\n",
        "    return -np.sum(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SjcgRWx0HpA"
      },
      "outputs": [],
      "source": [
        "def sigmoid_derivative(x):\n",
        "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "def binary_cross_entropy_derivative(y_true, y_pred):\n",
        "    \"\"\"Derivative of binary cross-entropy loss.\"\"\"\n",
        "    return -(y_true / y_pred) + ((1 - y_true) / (1 - y_pred))\n",
        "\n",
        "def update_weights(inputs, weights, bias, y_true, y_pred, learning_rate):\n",
        "    \"\"\"Update weights and bias using gradient descent.\"\"\"\n",
        "    error = binary_cross_entropy_derivative(y_true, y_pred)\n",
        "    sigmoid_deriv = sigmoid_derivative(y_pred)\n",
        "\n",
        "    # Gradient with respect to each weight\n",
        "    weights_gradient = inputs * error * sigmoid_deriv\n",
        "\n",
        "    # Gradient with respect to bias\n",
        "    bias_gradient = error * sigmoid_deriv\n",
        "\n",
        "    # Update weights and bias\n",
        "    weights = weights - learning_rate * weights_gradient\n",
        "    bias = bias -  learning_rate * bias_gradient\n",
        "    return weights, bias\n",
        "\n",
        "\n",
        "# Update weights\n",
        "print(f'loss before: {loss_function(y_true, y_pred)}')\n",
        "print(f\"Initial weights: {weights}\")\n",
        "weights, bias = update_weights(inputs, weights, bias, y_true, y_pred, learning_rate=0.001)\n",
        "print(f'Updated weights: {weights}')\n",
        "\n",
        "y_pred = single_neuron_forward(inputs, weights, bias)\n",
        "print(f'loss after: {loss_function(y_true, y_pred)}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical, plot_model"
      ],
      "metadata": {
        "id": "br078mTm3F0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8sR--TaM3vqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmmctNuY0HpB"
      },
      "outputs": [],
      "source": [
        "# Get all pixel features\n",
        "features = [col for col in train_df.columns if col.startswith('pixel')]\n",
        "# Split up training to for validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_df[features],\n",
        "                                                  train_df['label'],\n",
        "                                                  test_size=0.25,\n",
        "                                                  random_state=seed)\n",
        "y_train = y_train.values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[10]"
      ],
      "metadata": {
        "id": "H9vuWdTn3-IY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)"
      ],
      "metadata": {
        "id": "BKNTldGl3xnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.imshow(X_train.iloc[21].values.reshape(28,28), cmap='gray')\n",
        "y_train[21]"
      ],
      "metadata": {
        "id": "ake7RmIq4ECr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyocKjzB0HpB"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "\n",
        "    Dense(784, input_shape=(784,), activation='relu'),\n",
        "    # Second hidden layer with a specified number of neurons (e.g., 100)\n",
        "    Dense(100, activation='relu'),\n",
        "    # Output layer for multi-class classification\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to one-hot vector\n",
        "\n",
        "# y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "OimBqn_Z2251"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ef5uAhP_0HpC"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, y_train, epochs=10, batch_size=8, shuffle=True, validation_data = (X_val, y_val) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6hOwiZ30HpC"
      },
      "outputs": [],
      "source": [
        "plot_model(model, to_file='mlp-mnist.png', show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZQ4gAOSS5lT0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}