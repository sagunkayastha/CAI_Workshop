{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagunkayastha/CAI_Workshop/blob/main/Workshop_s3/DL_intro_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gmu17YK-JZwu"
      },
      "outputs": [],
      "source": [
        "\n",
        "import datetime\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56288-8XJZwv"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/sagunkayastha/CAI_Workshop/main/Workshop_s3/UCI_Credit_Card.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KubkxmBYJZwx"
      },
      "outputs": [],
      "source": [
        "# Read the data using pandas into a dataframe called df\n",
        "df = pd.read_csv('UCI_Credit_Card.csv', delimiter=',')\n",
        "df.dataframeName = 'UCI_Credit_Card.csv'\n",
        "nRow, nCol = df.shape\n",
        "print(f'There are {nRow} rows and {nCol} columns')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMwG95wNJZwx"
      },
      "outputs": [],
      "source": [
        "# Print the first 5 rows of the dataframe\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUGNlC6XJZwx"
      },
      "source": [
        "\n",
        "<div style=\"border-radius: 30px 0 30px 0px; border:#FFA500 solid; padding: 15px; background-color: #0d202b; font-size:100%; text-align:left \">\n",
        "   This dataset contains information on default payments, demographic factors, credit data, history of payment, and bill statements of credit card clients in Taiwan from April 2005 to September 2005.\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zNDf2eoJZwz"
      },
      "source": [
        "<div style=\"border-radius: 10px; border: 2px solid #d3d3d3; padding: 15px; background-color: #0d202b;\">\n",
        "    <h2 style=\"color: #007c3e;\">Variables</h2>\n",
        "    <p><strong>ID:</strong> ID of each client</p>\n",
        "    <p><strong>LIMIT_BAL:</strong> Amount of given credit in NT dollars (includes individual and family/supplementary credit)</p>\n",
        "    <p><strong>SEX:</strong> Gender (1=male, 2=female)</p>\n",
        "    <p><strong>EDUCATION:</strong> (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)</p>\n",
        "    <p><strong>MARRIAGE:</strong> Marital status (1=married, 2=single, 3=others)</p>\n",
        "    <p><strong>AGE:</strong> Age in years</p>\n",
        "    <p><strong>PAY_0:</strong> Repayment status in September, 2005 (-1=pay duly, 1=payment delay for one month, 2=payment delay for two months, ... 8=payment delay for eight months, 9=payment delay for nine months and above)</p>\n",
        "    <p><strong>PAY_2:</strong> Repayment status in August, 2005 (scale same as above)</p>\n",
        "    <p><strong>PAY_3:</strong> Repayment status in July, 2005 (scale same as above)</p>\n",
        "    <p><strong>PAY_4:</strong> Repayment status in June, 2005 (scale same as above)</p>\n",
        "    <p><strong>PAY_5:</strong> Repayment status in May, 2005 (scale same as above)</p>\n",
        "    <p><strong>PAY_6:</strong> Repayment status in April, 2005 (scale same as above)</p>\n",
        "    <p><strong>BILL_AMT1:</strong> Amount of bill statement in September, 2005 (NT dollar)</p>\n",
        "    <p><strong>BILL_AMT2:</strong> Amount of bill statement in August, 2005 (NT dollar)</p>\n",
        "    <p><strong>BILL_AMT3:</strong> Amount of bill statement in July, 2005 (NT dollar)</p>\n",
        "    <p><strong>BILL_AMT4:</strong> Amount of bill statement in June, 2005 (NT dollar)</p>\n",
        "    <p><strong>BILL_AMT5:</strong> Amount of bill statement in May, 2005 (NT dollar)</p>\n",
        "    <p><strong>BILL_AMT6:</strong> Amount of bill statement in April, 2005 (NT dollar)</p>\n",
        "    <p><strong>PAY_AMT1:</strong> Amount of previous payment in September, 2005 (NT dollar)</p>\n",
        "    <p><strong>PAY_AMT2:</strong> Amount of previous payment in August, 2005 (NT dollar)</p>\n",
        "    <p><strong>PAY_AMT3:</strong> Amount of previous payment in July, 2005 (NT dollar)</p>\n",
        "    <p><strong>PAY_AMT4:</strong> Amount of previous payment in June, 2005 (NT dollar)</p>\n",
        "    <p><strong>PAY_AMT5:</strong> Amount of previous payment in May, 2005 (NT dollar)</p>\n",
        "    <p><strong>PAY_AMT6:</strong> Amount of previous payment in April, 2005 (NT dollar)</p>\n",
        "    <p><strong>default.payment.next.month:</strong> Default payment (1=yes, 0=no)</p>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zOxY6dPJZwz"
      },
      "outputs": [],
      "source": [
        "# we are going to rename some of the columns to make them easier to work with\n",
        "df.rename(columns={'default.payment.next.month':'def_pay'}, inplace=True)\n",
        "df.rename(columns={'PAY_0':'PAY_1'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGsmQGH9JZw0"
      },
      "outputs": [],
      "source": [
        "# Descriptive statistics for each column\n",
        "summary_stats = df.describe()\n",
        "summary_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxEk4bl9JZw0"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUs6ECIjJZw0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Set the aesthetic style of the plots\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Draw histograms for each feature\n",
        "df.hist(figsize=(16, 14), bins=30)\n",
        "plt.suptitle('Feature Distributions', fontsize=20)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPKBFkLaJZw1"
      },
      "outputs": [],
      "source": [
        "# How many defaulters\n",
        "perc_default = df.def_pay.sum() / len(df.def_pay)\n",
        "print(f'The percentage of defaulters in the data is {perc_default*100} %')\n",
        "df['def_pay'].value_counts().plot(kind='pie',explode=[0.1,0],autopct=\"%1.1f%%\")\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDJ4XrhaJZw1"
      },
      "outputs": [],
      "source": [
        "pay_x_fts = ['PAY_1', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
        "plt.figure(figsize=(15,12))\n",
        "\n",
        "for i,col in enumerate(pay_x_fts):\n",
        "    plt.subplot(3,2,i + 1)\n",
        "    ax = sns.barplot(x = col, y = \"def_pay\", data = df, palette = 'rocket', errorbar = None)\n",
        "    plt.ylabel(\"% of Default\", fontsize= 12)\n",
        "    plt.ylim(0,1.2)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    for p in ax.patches:\n",
        "        ax.annotate(\"%.2f\" %(p.get_height()), (p.get_x()+0.09, p.get_height()+0.03),fontsize=13)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTMfIsBtJZw1"
      },
      "source": [
        "-> Most customers are duly paying their credit card bills. And it's pretty clear that their likelihood of default are much lower than the rest.\n",
        "\n",
        "\n",
        "-> Credit card holders who consistently delay their payments for more than 3 months are significantly more likely to face defaults."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a47xBBEaJZw2"
      },
      "outputs": [],
      "source": [
        "# Age Distribution of Credit Card Holders\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df['AGE'], bins=25, kde=True, color='skyblue')\n",
        "plt.title('Age Distribution of Credit Card Holders')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "\"\"\"The histogram above shows the age distribution of credit card holders in the dataset, including a density estimate to visualize the overall shape and spread of ages. This can help us understand the demographic makeup of the dataset in terms of age.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qe4rcjD-JZw2"
      },
      "outputs": [],
      "source": [
        "# Define bins and names for age groups\n",
        "bins = [20,30,40,50,60,70,80]\n",
        "names = ['21-30','31-40','41-50','51-60','61-70','71-80']\n",
        "\n",
        "\n",
        "df_temp = df.copy()\n",
        "# Create a new column in the DataFrame to categorize age into bins\n",
        "# 'right=True' includes the right bin edge\n",
        "df_temp['AGE_BIN'] = pd.cut(x=df.AGE, bins=bins, labels=names, right=True)\n",
        "\n",
        "# Count the number of occurrences for each age group\n",
        "age_cnt = df_temp.AGE_BIN.value_counts()\n",
        "\n",
        "# Count the number of occurrences for each age group where 'def_pay' is 0\n",
        "age_0 = (df_temp.AGE_BIN[df_temp['def_pay'] == 0].value_counts())\n",
        "\n",
        "# Count the number of occurrences for each age group where 'def_pay' is 1\n",
        "age_1 = (df_temp.AGE_BIN[df_temp['def_pay'] == 1].value_counts())\n",
        "\n",
        "# Initialize the plot\n",
        "plt.subplots(figsize=(8,5))\n",
        "\n",
        "# Create a bar plot for the age groups where 'def_pay' is 0\n",
        "plt.bar(age_0.index, age_0.values, label='0')\n",
        "\n",
        "# Create a bar plot for the age groups where 'def_pay' is 1\n",
        "plt.bar(age_1.index, age_1.values, label='1')\n",
        "\n",
        "# Annotate the bar chart with the count values for 'def_pay' 0\n",
        "for x, y in zip(names, age_0):\n",
        "    plt.text(x, y, y, fontsize=12)\n",
        "\n",
        "# Annotate the bar chart with the count values for 'def_pay' 1\n",
        "for x, y in zip(names, age_1):\n",
        "    plt.text(x, y, y, fontsize=12)\n",
        "\n",
        "# Customize tick labels\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "\n",
        "# Add title to the plot\n",
        "plt.title(\"Number of clients in each age group\", fontsize=15)\n",
        "\n",
        "# Add legend to the plot\n",
        "plt.legend(loc='upper right', fontsize=15)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDbgpmaHJZw2"
      },
      "outputs": [],
      "source": [
        "# Proportion of Defaults by Education Level\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='EDUCATION', hue='def_pay', data=df, palette=\"coolwarm\")\n",
        "plt.title('Defaults by Education Level')\n",
        "plt.xlabel('Education Level')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='Default', labels=['No', 'Yes'])\n",
        "plt.show()\n",
        "\n",
        "\"\"\"\n",
        "The plot above shows the counts of defaults versus non-defaults across different education levels. It provides a clear view of how education level might relate to the likelihood of defaulting on payments.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cw0KWVHuJZw3"
      },
      "outputs": [],
      "source": [
        "\n",
        "data = df\n",
        "grad =  data['EDUCATION'][data['EDUCATION']==1].count()\n",
        "grad_default = data['EDUCATION'][(data['EDUCATION']==1)&(data['def_pay']==1)].count()\n",
        "\n",
        "uni =  data['EDUCATION'][data['EDUCATION']==2].count()\n",
        "uni_default = data['EDUCATION'][(data['EDUCATION']==2)&(data['def_pay']==1)].count()\n",
        "\n",
        "high =  data['EDUCATION'][data['EDUCATION']==3].count()\n",
        "high_default = data['EDUCATION'][(data['EDUCATION']==3)&(data['def_pay']==1)].count()\n",
        "\n",
        "other =  data['EDUCATION'][data['EDUCATION'] > 3].count()\n",
        "other_default = data['EDUCATION'][(data['EDUCATION'] > 3)&(data['def_pay']==1)].count()\n",
        "\n",
        "total_education = [grad, uni, high, other]\n",
        "default_education = [grad_default,uni_default,high_default, other_default]\n",
        "degree = [1,2,3,4]\n",
        "plt.bar(degree,total_education, color='m',alpha=0.5, label='Total')\n",
        "plt.bar(degree,default_education, color='b',alpha=0.5, label='Default')\n",
        "\n",
        "plt.xticks([1,2,3,4],['Grad School','University','High School','Other'])\n",
        "plt.ylabel('Number of Accounts');plt.title('Fig.3 : Education ',fontweight=\"bold\", size=12)\n",
        "plt.legend();plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lIRJqsBJZw3"
      },
      "outputs": [],
      "source": [
        "# Payment Status Overview for PAY_0\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='PAY_1', data=df, palette=\"viridis\")\n",
        "plt.title('Payment Status in the Latest Month')\n",
        "plt.xlabel('Payment Status')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "\"\"\"\n",
        "The plot above illustrates the distribution of payment statuses for the latest month, providing insights into the payment behavior of the credit card users, including those who paid duly, those who delayed payments, and the extent of such delays.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJ0SFt0iJZw3"
      },
      "outputs": [],
      "source": [
        "# Correlation Heatmap\n",
        "plt.figure(figsize=(14, 10))\n",
        "corr = df.iloc[:, 1:-1].corr() # Exclude ID and target variable for correlation\n",
        "sns.heatmap(corr, cmap=\"YlGnBu\", annot=False)\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90m_bwWqJZw4"
      },
      "outputs": [],
      "source": [
        "# Boxplot of Credit Limit by Education Level\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='EDUCATION', y='LIMIT_BAL', data=df, palette=\"Set2\")\n",
        "plt.title('Credit Limit by Education Level')\n",
        "plt.xlabel('Education Level')\n",
        "plt.ylabel('Credit Limit')\n",
        "plt.show()\n",
        "\n",
        "\"\"\"\n",
        "The boxplot above visualizes the distribution of credit limits across different education levels. This plot can reveal trends and disparities in credit limits, potentially reflecting the financial trustworthiness perceived by credit issuers based on education.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLdSyDD_JZw4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "\n",
        "# Features and target variable\n",
        "X = df.drop(['ID', 'def_pay'], axis=1)\n",
        "y = df['def_pay']\n",
        "\n",
        "# Splitting the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalizing the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Verifying the shape of the datasets\n",
        "X_train_scaled.shape, X_test_scaled.shape, y_train.shape, y_test.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPVDXbejJZw4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(X_train_scaled, y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=128,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1)\n",
        "history = model.fit(X_train_scaled, y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=128,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdrgKqEhJZw4"
      },
      "outputs": [],
      "source": [
        "model.evaluate(X_test_scaled, y_test, verbose=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSQafxa_JZw4"
      },
      "source": [
        "#### -----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g22eNPeIJZw5"
      },
      "outputs": [],
      "source": [
        "# Focus on these columns\n",
        "cols = ['SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_1', 'PAY_2', 'BILL_AMT1', 'BILL_AMT2', 'def_pay']\n",
        "df_mod = df[cols]\n",
        "# The pairwise correlations\n",
        "df_mod.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJPFn7frJZw5"
      },
      "outputs": [],
      "source": [
        "# Correlation Heatmap\n",
        "plt.figure(figsize=(14, 10))\n",
        "corr = df_mod.iloc[:, 1:-1].corr() # Exclude ID and target variable for correlation\n",
        "sns.heatmap(corr, cmap=\"YlGnBu\", annot=False)\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULeuMBAWJZw5"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "\n",
        "# Features and target variable\n",
        "X = df_mod.drop(['def_pay'], axis=1)\n",
        "y = df_mod['def_pay']\n",
        "\n",
        "# Splitting the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalizing the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Verifying the shape of the datasets\n",
        "X_train_scaled.shape, X_test_scaled.shape, y_train.shape, y_test.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMAsct9HJZw5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(X_train_scaled, y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=128,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1)\n",
        "history = model.fit(X_train_scaled, y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=128,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJanfoiIJZw6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "onnx",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}