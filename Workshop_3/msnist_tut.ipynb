{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagunkayastha/CAI_Workshop/blob/main/Workshop_3/msnist_tut.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtWyysqTI8Q7"
      },
      "outputs": [],
      "source": [
        "# Standard Libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random as rn\n",
        "\n",
        "# Visualization libraries\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style({\"axes.facecolor\": \".95\"})\n",
        "\n",
        "# Modeling and Machine Learning\n",
        "from IPython.display import Image\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import accuracy_score\n",
        "# from sklearn.externals.six import StringIO\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "\n",
        "\n",
        "# Seed for reproducability\n",
        "seed = 1234\n",
        "np.random.seed(seed)\n",
        "rn.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/sagunkayastha/CAI_Workshop/main/Workshop_3/Inputs/test.csv\n",
        "!wget https://raw.githubusercontent.com/sagunkayastha/CAI_Workshop/main/Workshop_3/Inputs/train.csv"
      ],
      "metadata": {
        "id": "17nq3hTtJC9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxWsLKoJI8Q_"
      },
      "outputs": [],
      "source": [
        "# Specify Paths for easy dataloading\n",
        "\n",
        "TRAIN_PATH = 'train.csv'\n",
        "TEST_PATH = 'test.csv'\n",
        "\n",
        "# Load in training and testing data\n",
        "train_df = pd.read_csv(TRAIN_PATH)\n",
        "test_df = pd.read_csv(TEST_PATH)\n",
        "concat_df = pd.concat([train_df, test_df])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udMXXIHNI8Q_"
      },
      "outputs": [],
      "source": [
        "def acc(y_true : np.ndarray, y_pred : np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "        Calculates the accuracy score between labels and predictions.\n",
        "\n",
        "        :param y_true: The true labels of the data\n",
        "        :param y_pred: The predictions for the data\n",
        "\n",
        "        :return: a floating point number denoting the accuracy\n",
        "    \"\"\"\n",
        "    return round(accuracy_score(y_true, y_pred) * 100, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7WZkZU0I8RA"
      },
      "outputs": [],
      "source": [
        "# Visualize target distribution\n",
        "train_df['label'].value_counts().sort_index().plot(kind='bar', figsize=(10, 6), rot=0)\n",
        "plt.title('Visualization of class distribution for the MNIST Dataset', fontsize=20, weight='bold')\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.xlabel('Class', fontsize=16)\n",
        "plt.ylabel('Frequency', fontsize=16);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpJ0W4zEI8RB"
      },
      "outputs": [],
      "source": [
        "plt.imshow(train_df.loc[np.random.randint(1000)][:-1].values.reshape(28,28), cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpF9eJudI8RB"
      },
      "outputs": [],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsSAtm5gI8RB"
      },
      "outputs": [],
      "source": [
        "# Get all pixel features\n",
        "features = [col for col in train_df.columns if col.startswith('pixel')]\n",
        "# Split up training to for validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_df[features],\n",
        "                                                  train_df['label'],\n",
        "                                                  test_size=0.25,\n",
        "                                                  random_state=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plxDCWT8I8RB"
      },
      "outputs": [],
      "source": [
        "# Train baseline decision tree model\n",
        "clf = DecisionTreeClassifier(max_depth=10, random_state=seed)\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XIfgWnbI8RC"
      },
      "outputs": [],
      "source": [
        "# Evaluate the baseline model\n",
        "train_preds_baseline = clf.predict(X_train)\n",
        "val_preds_baseline = clf.predict(X_val)\n",
        "acc_baseline_train = acc(train_preds_baseline, y_train)\n",
        "acc_baseline_val = acc(val_preds_baseline, y_val)\n",
        "print(f'Training accuracy for our baseline (using all pixel features): {acc_baseline_train}%')\n",
        "print(f'Validation accuracy for our baseline (using all pixel features): {acc_baseline_val}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8_7HoOPI8RC"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "pca = PCA(n_components=50).fit(concat_df[features])\n",
        "pca_result = pca.transform(concat_df[features])\n",
        "\n",
        "\n",
        "# Create a DataFrame with the PCA results\n",
        "# If you have labels for each point, you can add them to the DataFrame for color coding\n",
        "pca_df = pd.DataFrame(data=pca_result[:, 0:2], columns=['PC1', 'PC2'])\n",
        "pca_df['label'] = concat_df['label'].values\n",
        "\n",
        "# Visualize the first two principal components\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.scatterplot(x='PC1', y='PC2', hue='label', data=pca_df, palette=\"Set1\", alpha=0.7)\n",
        "plt.title('PCA - First Two Principal Components')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8oMmI76I8RD"
      },
      "outputs": [],
      "source": [
        "explained_variance_ratio = pca.explained_variance_ratio_\n",
        "\n",
        "# Print the explained variance ratio for each component\n",
        "for i, variance in enumerate(explained_variance_ratio):\n",
        "    print(f\"Principal Component {i+1}: {variance:.2%} of the variance\")\n",
        "    if i==5:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NHNaRzrI8RD"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(pca_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDizrJskI8RD"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Split up the PCA results in training and testing data\n",
        "pca_cols = [f'component_{i+1}' for i in range(50)]\n",
        "pca_train = pd.DataFrame(pca_result[:len(train_df)], columns=pca_cols)\n",
        "pca_test = pd.DataFrame(pca_result[len(train_df):], columns=pca_cols)\n",
        "\n",
        "# Perform another split for t-sne feature validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(pca_train,\n",
        "                                                  train_df['label'],\n",
        "                                                  test_size=0.25,\n",
        "                                                  random_state=seed)\n",
        "\n",
        "# Train model with PCA features\n",
        "clf = DecisionTreeClassifier(max_depth=10, random_state=seed)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model with the 50 PCA features and compare to the baseline model\n",
        "train_preds = clf.predict(X_train)\n",
        "val_preds = clf.predict(X_val)\n",
        "acc_pca_train = acc(train_preds, y_train)\n",
        "acc_pca_val = acc(val_preds, y_val)\n",
        "print(f'Training accuracy with PCA features (50 components): {acc_pca_train}%')\n",
        "print(f'Validation accuracy with PCA features (50 components): {acc_pca_val}%')\n",
        "# Check out how it performed compared to the baseline\n",
        "acc_diff = round(acc_pca_val - acc_baseline_val, 2)\n",
        "print(f'\\nThis is a difference of {acc_diff}% in validation accuracy compared to the baseline.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeoYy7ZWI8RE"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "\n",
        "tsne = TSNE()\n",
        "transformed = tsne.fit_transform(pca_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4x6z0rwI8RE"
      },
      "outputs": [],
      "source": [
        "transformed.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuJQ8rWzI8RF"
      },
      "outputs": [],
      "source": [
        "# Split up the t-SNE results in training and testing data\n",
        "tsne_train = pd.DataFrame(transformed[:len(train_df)], columns=['component1', 'component2'])\n",
        "tsne_test = pd.DataFrame(transformed[len(train_df):], columns=['component1', 'component2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHcbGMsPI8RF"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Split up the t-SNE results in training and testing data\n",
        "tsne_train = pd.DataFrame(transformed[:len(train_df)], columns=['component1', 'component2'])\n",
        "tsne_test = pd.DataFrame(transformed[len(train_df):], columns=['component1', 'component2'])\n",
        "\n",
        "# Visualize the results for t-SNE on MNIST\n",
        "plt.figure(figsize=(14, 14))\n",
        "plt.title(f\"Visualization of t-SNE results on the MNIST Dataset\\n\\\n",
        "Amount of datapoints: {len(tsne_train)}\", fontsize=24, weight='bold')\n",
        "sns.scatterplot(x=\"component1\", y=\"component2\",\n",
        "                data=tsne_train, hue=train_df['label'],\n",
        "                palette=\"Set1\", legend=\"full\")\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.xlabel(\"Component 1\", fontsize=16)\n",
        "plt.ylabel(\"Component 2\", fontsize=16)\n",
        "plt.legend(fontsize=16)\n",
        "plt.show()  # Explicitly show the plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhbIXdvUI8RF"
      },
      "outputs": [],
      "source": [
        "# Perform another split for t-sne feature validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(tsne_train,\n",
        "                                                  train_df['label'],\n",
        "                                                  test_size=0.25,\n",
        "                                                  random_state=seed)\n",
        "\n",
        "# Train model with t-sne features\n",
        "clf = DecisionTreeClassifier(max_depth=10, random_state=seed)\n",
        "clf.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f88vgxClI8RF"
      },
      "outputs": [],
      "source": [
        "# Evaluate model with t-SNE features and compare to the baseline model\n",
        "train_preds = clf.predict(X_train)\n",
        "val_preds = clf.predict(X_val)\n",
        "acc_tsne_train = acc(train_preds, y_train)\n",
        "acc_tsne_val = acc(val_preds, y_val)\n",
        "print(f'Training accuracy with t-SNE features: {acc_tsne_train}%')\n",
        "print(f'Validation accuracy with t-SNE features: {acc_tsne_val}%')\n",
        "# Compare t-SNE results with the baseline model\n",
        "acc_diff = round(acc_tsne_val - acc_baseline_val, 2)\n",
        "print(f'\\nThis is an improvement of {acc_diff}% in validation accuracy over the baseline!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z92zlvfNI8RF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5qZO77nI8RF"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Train baseline KNN model\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the baseline model\n",
        "train_preds_baseline = knn.predict(X_train)\n",
        "val_preds_baseline = knn.predict(X_val)\n",
        "acc_baseline_train = acc(train_preds_baseline, y_train)\n",
        "acc_baseline_val = acc(val_preds_baseline, y_val)\n",
        "print(f'Training accuracy for our baseline (using all pixel features): {acc_baseline_train}%')\n",
        "print(f'Validation accuracy for our baseline (using all pixel features): {acc_baseline_val}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MYs04J4I8RG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}