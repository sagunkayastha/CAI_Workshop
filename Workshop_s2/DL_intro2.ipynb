{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***A Single Neuron***\n",
    "\n",
    "!['Single_neuron'](https://raw.githubusercontent.com/sagunkayastha/CAI_Workshop/main/Workshop_s2/images/i1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting crop yield based on two inputs: ***(Regression task)*** \n",
    "- the amount of water provided to the crop (irrigation)  \n",
    "- the amount of fertilizer used. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "Both of these factors have optimal ranges, and too much or too little of either can negatively impact the crop yield.\n",
    "\n",
    "- Water (Irrigation): Essential for growth, but both too little and too much can reduce crop yield due to drought stress or waterlogging.\n",
    "\n",
    "- Fertilizer: Needed for nutrients; however, too little can stunt growth due to deficiency, and too much can harm yield through toxicity and environmental damage.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- \n",
    "Lets define weights(importance) based on thier impact on crop yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "weights = [0.6, 0.2] ## my assumption is that importance of water is higher than fertilizer\n",
    "bias = 0.1\n",
    "# 0.6 is the weight of the first input, 0.3 is the weight of the second input \n",
    "# 0.6 gallons of water and 0.3 lb of fertilizer\n",
    "x = [0.6, 0.3]  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining Inputs: In our model, these inputs are weighted based on their impact on crop yield, with a bias term included to account for other factors influencing yield (such as soil quality or pest levels).\n",
    "\n",
    "$$z = \\sum_{i=1}^{n} x_i w_i + b$$\n",
    "\n",
    "$$output = \\sigma(z)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model calculates the predicted crop yield by balancing the effects of water and fertilizer. \n",
    "\n",
    "It recognizes the non-linear relationship: both inputs contribute positively to yield up to a point, but beyond their optimal ranges, the effect reverses and becomes negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crop yield for 0.6 gallons of water and 0.3 lb of fertilizer:  0.6271477663131956\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "z = (x[0] * weights[0]) + (x[1] * weights[1]) + bias\n",
    "crop_yield = sigmoid(z)\n",
    "print(\"Crop yield for 0.6 gallons of water and 0.3 lb of fertilizer: \", crop_yield)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning from Feedback (Backpropagation):\n",
    "After the harvest, the actual yields are compared to the model's predictions. \n",
    "\n",
    "This feedback allows the model to adjust the weights of water and fertilizer inputs. \n",
    "\n",
    "If yields are lower than expected at extreme values of either input, the model learns to adjust the importance (weight) it assigns to staying within optimal ranges.\n",
    "\n",
    "lets suppose the actual yield was **0.81**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error(Loss):  0.033434939364253756\n"
     ]
    }
   ],
   "source": [
    "# MSE loss function\n",
    "def loss_function(predicted, real):\n",
    "    return (predicted - real) **2\n",
    "\n",
    "actual = 0.81\n",
    "loss = loss_function(crop_yield, actual)\n",
    "print(\"Error(Loss): \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![loss](https://www.researchgate.net/publication/329960546/figure/fig2/AS:865846410899458@1583445279578/Weight-update-by-gradient-descent-in-the-cost-function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusting Weights: **Adjusting Knobs** Through backpropagation, the model:\n",
    "\n",
    "- Increases the negative weight of water and fertilizer inputs as they move beyond their optimal ranges, reflecting the detrimental effects of both excessive and insufficient application.\n",
    "- Fine-tunes the bias and weights to better capture the complex, non-linear relationships between inputs and crop yield, aiming for the optimal use of resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error(Loss):  0.015996964321260375\n"
     ]
    }
   ],
   "source": [
    "# Forward propagation\n",
    "\n",
    "def forward(x, weights, bias):\n",
    "    z = np.dot(x, weights) + bias\n",
    "    return sigmoid(z)\n",
    "\n",
    "# change weights \n",
    "# Try changing the weights and bias to see how they affect the error\n",
    "weights = [0.1, 0.5]\n",
    "bias = 0.56\n",
    "x = [0.6, 0.3]  \n",
    "crop_yield = forward(x, weights, bias)\n",
    "loss = loss_function(crop_yield, actual)\n",
    "print(\"Error(Loss): \", loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Making Predictions: First, the network makes predictions based on its current settings (weights). Think of these weights like knobs that can be turned to change the network's behavior.\n",
    "\n",
    "Measuring Mistakes: After making predictions, the network looks at how far off it was from the correct answers. This difference is called the loss, and the network's goal is to make this as small as possible.\n",
    "\n",
    "Asking \"How Much?\": The network then asks, \"How much does each weight affect the loss?\" To find this out, it computes the partial derivatives of the loss function with respect to each weight. These partial derivatives are called gradients.\n",
    "\n",
    "Finding Direction: The gradients tell the network not just how much, but also in which direction to adjust each weight (knob) to reduce the mistakes. If a gradient is positive, reducing the weight decreases the loss, and if it's negative, increasing the weight does.\n",
    "\n",
    "Adjusting Knobs: Finally, the network slightly adjusts each knob (weight) in the direction indicated by the gradients to make better predictions next time. This step is repeated many times, and with each repetition, the network gets better at making predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "\n",
    "--------------\n",
    "\n",
    "**How much does each weight affect loss or how important is a particular weight**\n",
    "\n",
    "The gradients for updating the weights and bias are calculated using the chain rule as follows: \n",
    "\n",
    "**Dominoes** - first output then activation then summation(z)\n",
    "\n",
    "- Gradient with respect to weights:\n",
    "  $$dLoss/dWeights = dLoss/dOutput \\cdot dOutput/dZ \\cdot dZ/dWeights$$\n",
    "  \n",
    "- Gradient with respect to bias:\n",
    "  $$dLoss/dBias = dLoss/dOutput \\cdot dOutput/dZ \\cdot dZ/dBias$$\n",
    "\n",
    "\n",
    "Ignore calculus if you find it too complicated. But basically we are trying to find out how much affect does each weight (gallons of water and fertilizer) has on our final loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Using a learning rate eta we update the weights and bias as follows:\n",
    "\n",
    "$$w_i^{new} = w_i - \\eta \\cdot \\frac{\\partial L}{\\partial w_i}$$\n",
    "$$b^{new} = b - \\eta \\cdot \\frac{\\partial L}{\\partial b}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def backward(x, weights, bias, output, target, learning_rate):\n",
    "    \"\"\"Perform backpropagation and update the weights and bias.\"\"\"\n",
    "    # Compute the derivative of the loss with respect to output\n",
    "    dLoss_dOutput = -(target - output)  # we ignore the factor of 2 for simplicity\n",
    "\n",
    "    # Compute the derivative of the output with respect to z\n",
    "    dOutput_dZ = output * (1 - output)\n",
    "    \n",
    "    # Compute the gradient of the loss with respect to weights\n",
    "    dLoss_dWeights = dLoss_dOutput * dOutput_dZ * x\n",
    "\n",
    "    # Compute the gradient of the loss with respect to bias\n",
    "    dLoss_dBias = dLoss_dOutput * dOutput_dZ\n",
    "\n",
    "\n",
    "    # Update the weights and bias\n",
    "    weights -= learning_rate * dLoss_dWeights\n",
    "    bias -= learning_rate * dLoss_dBias\n",
    "\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets implement forward and backward pass together. This is called an **Iteration**(**Terminology**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error(Loss):  0.033434939364253756\n",
      "Updated weights:  [0.60256542 0.20128271] Updated bias:  0.10427569678243\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weights = np.array([0.6, 0.2])\n",
    "bias = np.array(0.1)\n",
    "x = np.array([0.6, 0.3])\n",
    "\n",
    "\n",
    "crop_yield = forward(x, weights, bias)\n",
    "loss = loss_function(crop_yield, actual)\n",
    "print(\"Error(Loss): \", loss)\n",
    "\n",
    "weights, bias = backward(x, weights, bias, crop_yield, actual, 0.1)\n",
    "print(\"Updated weights: \", weights, \"Updated bias: \", bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would perform this iteratively for all the samples in our dataset. We can update the weights for each example, for a batch of example or for whole dataset.\n",
    "\n",
    "\n",
    " Stochastic Gradient Descent, Batch Gradient descent (**Terminology**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error(Loss) epoch : 0 0.033434939364253756\n",
      "Error(Loss) epoch : 1 0.03290729108643822\n",
      "Error(Loss) epoch : 2 0.032389608201726115\n",
      "Error(Loss) epoch : 3 0.03188167940840362\n",
      "Error(Loss) epoch : 4 0.031383297959557674\n",
      "Error(Loss) epoch : 5 0.03089426158373801\n",
      "Error(Loss) epoch : 6 0.030414372405329917\n",
      "Error(Loss) epoch : 7 0.029943436864789445\n",
      "Error(Loss) epoch : 8 0.029481265638878904\n",
      "Error(Loss) epoch : 9 0.029027673561031\n",
      "Error(Loss) epoch : 10 0.02858247954195932\n",
      "Error(Loss) epoch : 11 0.028145506490621124\n",
      "Error(Loss) epoch : 12 0.02771658123563171\n",
      "Error(Loss) epoch : 13 0.027295534447218824\n",
      "Error(Loss) epoch : 14 0.026882200559798602\n",
      "Error(Loss) epoch : 15 0.026476417695245096\n",
      "Error(Loss) epoch : 16 0.026078027586921494\n",
      "Error(Loss) epoch : 17 0.02568687550452988\n",
      "Error(Loss) epoch : 18 0.025302810179834895\n",
      "Error(Loss) epoch : 19 0.024925683733306187\n",
      "Error(Loss) epoch : 20 0.024555351601723212\n",
      "Error(Loss) epoch : 21 0.024191672466777253\n",
      "Error(Loss) epoch : 22 0.02383450818470382\n",
      "Error(Loss) epoch : 23 0.023483723716971373\n",
      "Error(Loss) epoch : 24 0.023139187062051095\n",
      "Error(Loss) epoch : 25 0.0228007691882857\n",
      "Error(Loss) epoch : 26 0.022468343967874137\n",
      "Error(Loss) epoch : 27 0.022141788111984848\n",
      "Error(Loss) epoch : 28 0.02182098110700659\n",
      "Error(Loss) epoch : 29 0.02150580515194439\n",
      "Error(Loss) epoch : 30 0.021196145096964908\n",
      "Error(Loss) epoch : 31 0.02089188838309282\n",
      "Error(Loss) epoch : 32 0.020592924983058643\n",
      "Error(Loss) epoch : 33 0.020299147343295815\n",
      "Error(Loss) epoch : 34 0.02001045032708264\n",
      "Error(Loss) epoch : 35 0.01972673115882498\n",
      "Error(Loss) epoch : 36 0.019447889369470738\n",
      "Error(Loss) epoch : 37 0.019173826743050053\n",
      "Error(Loss) epoch : 38 0.018904447264329816\n",
      "Error(Loss) epoch : 39 0.01863965706757312\n",
      "Error(Loss) epoch : 40 0.018379364386391733\n",
      "Error(Loss) epoch : 41 0.018123479504678918\n",
      "Error(Loss) epoch : 42 0.01787191470860975\n",
      "Error(Loss) epoch : 43 0.01762458423969473\n",
      "Error(Loss) epoch : 44 0.017381404248872686\n",
      "Error(Loss) epoch : 45 0.01714229275162717\n",
      "Error(Loss) epoch : 46 0.01690716958411181\n",
      "Error(Loss) epoch : 47 0.016675956360268012\n",
      "Error(Loss) epoch : 48 0.016448576429919308\n",
      "Error(Loss) epoch : 49 0.016224954837825736\n",
      "Error(Loss) epoch : 50 0.016005018283681463\n",
      "Error(Loss) epoch : 51 0.015788695083039435\n",
      "Error(Loss) epoch : 52 0.015575915129145466\n",
      "Error(Loss) epoch : 53 0.015366609855664834\n",
      "Error(Loss) epoch : 54 0.015160712200285054\n",
      "Error(Loss) epoch : 55 0.014958156569176798\n",
      "Error(Loss) epoch : 56 0.01475887880229662\n",
      "Error(Loss) epoch : 57 0.014562816139514323\n",
      "Error(Loss) epoch : 58 0.014369907187547886\n",
      "Error(Loss) epoch : 59 0.01418009188768934\n",
      "Error(Loss) epoch : 60 0.013993311484305188\n",
      "Error(Loss) epoch : 61 0.013809508494094081\n",
      "Error(Loss) epoch : 62 0.013628626676086135\n",
      "Error(Loss) epoch : 63 0.013450611002367392\n",
      "Error(Loss) epoch : 64 0.0132754076295132\n",
      "Error(Loss) epoch : 65 0.01310296387071518\n",
      "Error(Loss) epoch : 66 0.012933228168585761\n",
      "Error(Loss) epoch : 67 0.012766150068624913\n",
      "Error(Loss) epoch : 68 0.012601680193334387\n",
      "Error(Loss) epoch : 69 0.012439770216963823\n",
      "Error(Loss) epoch : 70 0.012280372840874697\n",
      "Error(Loss) epoch : 71 0.01212344176950707\n",
      "Error(Loss) epoch : 72 0.011968931686935639\n",
      "Error(Loss) epoch : 73 0.011816798234000501\n",
      "Error(Loss) epoch : 74 0.01166699798599915\n",
      "Error(Loss) epoch : 75 0.011519488430926508\n",
      "Error(Loss) epoch : 76 0.01137422794824956\n",
      "Error(Loss) epoch : 77 0.011231175788203774\n",
      "Error(Loss) epoch : 78 0.01109029205159842\n",
      "Error(Loss) epoch : 79 0.010951537670118956\n",
      "Error(Loss) epoch : 80 0.010814874387113564\n",
      "Error(Loss) epoch : 81 0.010680264738852632\n",
      "Error(Loss) epoch : 82 0.010547672036249081\n",
      "Error(Loss) epoch : 83 0.010417060347028361\n",
      "Error(Loss) epoch : 84 0.010288394478336942\n",
      "Error(Loss) epoch : 85 0.010161639959778423\n",
      "Error(Loss) epoch : 86 0.010036763026866444\n",
      "Error(Loss) epoch : 87 0.00991373060488434\n",
      "Error(Loss) epoch : 88 0.009792510293141007\n",
      "Error(Loss) epoch : 89 0.009673070349613238\n",
      "Error(Loss) epoch : 90 0.009555379675964764\n",
      "Error(Loss) epoch : 91 0.009439407802932561\n",
      "Error(Loss) epoch : 92 0.009325124876071088\n",
      "Error(Loss) epoch : 93 0.009212501641845663\n",
      "Error(Loss) epoch : 94 0.00910150943406572\n",
      "Error(Loss) epoch : 95 0.008992120160649758\n",
      "Error(Loss) epoch : 96 0.008884306290713486\n",
      "Error(Loss) epoch : 97 0.008778040841972676\n",
      "Error(Loss) epoch : 98 0.008673297368453344\n",
      "Error(Loss) epoch : 99 0.008570049948500748\n"
     ]
    }
   ],
   "source": [
    "# since we have only one data point, we can update the weights and bias directly.\n",
    "# This is basically Batch Gradient Descent where we use all the data points to update the weights and bias. and our batch size is 1\n",
    "\n",
    "weights = np.array([0.6, 0.2])\n",
    "\n",
    "bias = np.array(0.1)\n",
    "x = np.array([0.6, 0.3])\n",
    "\n",
    "initial_wb = [weights.copy(), bias.copy()]\n",
    "for epoch in range(100):\n",
    "    crop_yield = forward(x, weights, bias)\n",
    "    loss = loss_function(crop_yield, actual)\n",
    "    weights, bias = backward(x, weights, bias, crop_yield, actual, learning_rate=0.1)\n",
    "    print(f\"Error(Loss) epoch : {epoch} {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights and bias:  [0.6 0.2] 0.1\n",
      "Updated weights and bias:  [0.77149565 0.28574782] 0.3858260804059064\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial weights and bias: \", initial_wb[0], initial_wb[1])\n",
    "print(\"Updated weights and bias: \", weights, bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets try a generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import generate_data, plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "opacity": 0.8,
          "size": 5
         },
         "mode": "markers",
         "type": "scatter3d",
         "x": [
          3.745401188473625,
          9.50714306409916,
          7.319939418114051,
          5.986584841970366,
          1.5601864044243652,
          1.5599452033620265,
          0.5808361216819946,
          8.661761457749352,
          6.011150117432088,
          7.080725777960454,
          0.20584494295802447,
          9.699098521619943,
          8.324426408004218,
          2.1233911067827616,
          1.8182496720710062,
          1.8340450985343382,
          3.0424224295953772,
          5.247564316322379,
          4.319450186421157,
          2.9122914019804194,
          6.118528947223795,
          1.3949386065204183,
          2.9214464853521815,
          3.663618432936917,
          4.56069984217036,
          7.851759613930136,
          1.9967378215835974,
          5.142344384136116,
          5.924145688620425,
          0.46450412719997725,
          6.075448519014383,
          1.7052412368729153,
          0.6505159298527952,
          9.488855372533333,
          9.656320330745594,
          8.08397348116461,
          3.0461376917337066,
          0.9767211400638387,
          6.842330265121569,
          4.4015249373960135,
          1.2203823484477883,
          4.951769101112702,
          0.34388521115218396,
          9.093204020787821,
          2.587799816000169,
          6.62522284353982,
          3.1171107608941098,
          5.200680211778108,
          5.4671027934327965,
          1.8485445552552704,
          9.695846277645586,
          7.7513282336111455,
          9.394989415641891,
          8.948273504276488,
          5.978999788110851,
          9.218742350231167,
          0.884925020519195,
          1.959828624191452,
          0.45227288910538066,
          3.2533033076326436,
          3.8867728968948203,
          2.713490317738959,
          8.287375091519294,
          3.567533266935893,
          2.8093450968738076,
          5.426960831582485,
          1.4092422497476265,
          8.021969807540398,
          0.7455064367977082,
          9.868869366005173,
          7.722447692966574,
          1.987156815341724,
          0.05522117123602399,
          8.154614284548341,
          7.068573438476172,
          7.2900716804098735,
          7.712703466859457,
          0.7404465173409036,
          3.5846572854427263,
          1.1586905952512971,
          8.631034258755935,
          6.232981268275579,
          3.308980248526492,
          0.6355835028602363,
          3.109823217156622,
          3.2518332202674705,
          7.29606178338064,
          6.3755747135521315,
          8.872127425763265,
          4.722149251619493,
          1.195942459383017,
          7.13244787222995,
          7.607850486168974,
          5.612771975694963,
          7.70967179954561,
          4.937955963643907,
          5.227328293819941,
          4.275410183585496,
          0.2541912674409519,
          1.0789142699330445,
          0.3142918568673425,
          6.364104112637804,
          3.143559810763267,
          5.085706911647028,
          9.07566473926093,
          2.4929222914887497,
          4.103829230356297,
          7.555511385430487,
          2.2879816549162246,
          0.7697990982879299,
          2.8975145291376805,
          1.6122128725400442,
          9.29697652342573,
          8.08120379564417,
          6.334037565104235,
          8.714605901877178,
          8.036720768991145,
          1.8657005888603584,
          8.925589984899778,
          5.393422419156507,
          8.074401551640625,
          8.960912999234932,
          3.1800347497186388,
          1.1005192452767676,
          2.279351625419417,
          4.271077886262563,
          8.18014765922493,
          8.607305832563434,
          0.06952130531190703,
          5.107473025775658,
          4.17411003148779,
          2.2210781047073027,
          1.198653673336828,
          3.3761517140362796,
          9.429097039125192,
          3.2320293202075523,
          5.187906217433661,
          7.030189588951778,
          3.63629602379294,
          9.717820827209607,
          9.624472949421111,
          2.5178229582536416,
          4.972485058923855,
          3.0087830981676964,
          2.848404943774676,
          0.36886947354532795,
          6.095643339798968,
          5.026790232288615,
          0.5147875124998935,
          2.7864646423661146,
          9.082658859666537,
          2.395618906669724,
          1.448948720912231,
          4.89452760277563,
          9.856504541106007,
          2.4205527151150044,
          6.721355474058786,
          7.616196153287175,
          2.3763754399239967,
          7.282163486118596,
          3.677831327192532,
          6.3230583059357945,
          6.335297107608947,
          5.357746840747585,
          0.902897700544083,
          8.35302495589238,
          3.2078006497173583,
          1.8651851039985423,
          0.40775141554763916,
          5.908929431882418,
          6.775643618422825,
          0.16587828927856152,
          5.12093058299281,
          2.2649577519793795,
          6.451727904094499,
          1.7436642900499144,
          6.90937738102466,
          3.867353463005374,
          9.367299887367345,
          1.3752094414599325,
          3.410663510502585,
          1.1347352124058907,
          9.246936182785628,
          8.77339353380981,
          2.579416277151556,
          6.59984046034179,
          8.172222002012159,
          5.5520081159946235,
          5.296505783560065,
          2.418522909004517,
          0.9310276780589921,
          8.972157579533267,
          9.004180571633304,
          6.33101457273268,
          3.390297910487007,
          3.492095746126609,
          7.259556788702394,
          8.971102599525771,
          8.870864242651173,
          7.798755458576238,
          6.420316461542877,
          0.8413996499504883,
          1.6162871409461377,
          8.985541885270793,
          6.0642905965958995,
          0.09197051616629648,
          1.014715428660321,
          6.635017691080558,
          0.05061583846218687,
          1.6080805141749865,
          5.487337893665861,
          6.918951976926932,
          6.519612595026006,
          2.242693094605598,
          7.121792213475358,
          2.3724908749680007,
          3.2539969815926773,
          7.464914051180242,
          6.496328990472147,
          8.49223410494178,
          6.576128923003433,
          5.683086033354716,
          0.9367476782809248,
          3.6771580305943354,
          2.6520236768172545,
          2.4398964337908358,
          9.730105547524456,
          3.930977246667604,
          8.920465551771134,
          6.311386259972629,
          7.948113035416484,
          5.026370931051921,
          5.769038846263591,
          4.925176938188639,
          1.952429877980445,
          7.224521152615053,
          2.807723624408558,
          0.2431596643145384,
          6.454722959071678,
          1.7711067940704894,
          9.404585843529143,
          9.539285770025874,
          9.148643902204485,
          3.7015870025544437,
          0.15456616528867428,
          9.283185625877254,
          4.281841483173143,
          9.666548190436696,
          9.636199770892528,
          8.530094554673601,
          2.944488920695857,
          3.8509772860192526,
          8.511366715168569,
          3.1692200515627764,
          1.6949274668609249,
          5.568012624583502,
          9.36154774160781,
          6.96029796674973,
          5.700611700893649,
          0.9717649377076854,
          6.150072266991698,
          9.900538501042632,
          1.4008401523652403,
          5.183296523637368,
          8.773730719279554,
          7.407686177542044,
          6.97015740995268,
          7.024840839871093,
          3.5949115121975517,
          2.9359184426449336,
          8.093611554785136,
          8.101133946791808,
          8.670723185801037,
          9.132405525564714,
          5.113423988609378,
          5.015162946871996,
          7.9829517896677515,
          6.4996393077776515,
          7.019668772577034,
          7.95792669436101,
          8.900053418175663,
          3.379951568515358,
          3.75582952639944,
          0.93981939840869,
          5.78280140996174,
          0.35942273796742086,
          4.655980181324601,
          5.426446347075766,
          2.865412521282844,
          5.9083326056901075,
          0.3050024993904943,
          0.37348188749214417,
          8.226005606596583,
          3.601906414112629,
          1.2706051265188478,
          5.222432600548044,
          7.699935530986108,
          2.1582102749684315,
          6.228904758190002,
          0.85347464993768,
          0.516817211686077,
          5.31354631568148,
          5.406351216101065,
          6.374299014982066,
          7.260913337226615,
          9.758520794625346,
          5.163003483011953,
          3.2295647294124596,
          7.9518619476870365,
          2.708322512620742,
          4.389714207056361,
          0.7845638134226596,
          0.2535074341545751,
          9.626484146779251,
          8.359801205122059,
          6.95974206093698,
          4.089529444142698,
          1.7329432007084578,
          1.5643704267108605,
          2.502428981645953,
          5.4922666470612045,
          7.145959227000623,
          6.601973767177313,
          2.7993389694594284,
          9.54865280663194,
          7.378969166957685,
          5.543540525114007,
          6.117207462343522,
          4.196000624277899,
          2.4773098950115746,
          3.559726786512616,
          7.578461104643691,
          0.14393488629755868,
          1.1607264050691624,
          0.4600264202175275,
          0.40728802318970136,
          8.554605840110073,
          7.036578593800237,
          4.741738290873252,
          0.9783416065100148,
          4.916158751168323,
          4.734717707805657,
          1.7320186991001518,
          4.33851649237973,
          3.9850473439737346,
          6.158500980522165,
          6.350936508676438,
          0.4530400977204452,
          3.746126146264712,
          6.258599157142363,
          5.031362585800877,
          8.564898411883222,
          6.58693631618945,
          1.629344270814297,
          0.7056874740042984,
          6.424192782063156,
          0.26511310541621813,
          5.8577558127346325,
          9.402302414249576,
          5.75474177875879,
          3.881699262065219,
          6.432882184423532,
          4.582528904915167,
          5.45616789315935,
          9.41464808776525,
          3.8610263780077423,
          9.611905638239142,
          9.053506419560637,
          1.9579113478929644,
          0.6936130087516545,
          1.0077800137742665,
          0.18221825651549728,
          0.944429607559284,
          6.830067734163569,
          0.7118864846022899,
          3.189756302937613,
          8.448753109694545,
          0.23271935735825866,
          8.144684825889358,
          2.8185477477339993,
          1.1816482762165625,
          6.967371653641506,
          6.28942846779884,
          8.77472013527053,
          7.350710438038858,
          8.034809303848485,
          2.820345725713065,
          1.7743954377972282,
          7.506147516408584,
          8.06834739267264,
          9.905051420006734,
          4.126176769114265,
          3.720180857927832,
          7.764129607419968,
          3.4080354025301784,
          9.307573256035647,
          8.584127518430119,
          4.289940273750183,
          7.508710677914974,
          7.545428740846823,
          1.031238688359326,
          9.025529066795666,
          5.052523724478571,
          8.264574661077416,
          3.2004960103061175,
          8.955232284962005,
          3.892016787341631,
          0.1083765148029836,
          9.053819764192637,
          0.9128667678613356,
          3.1931363759041487,
          9.50061967050805,
          9.506071469375561,
          5.734378881232861,
          6.318372121697992,
          4.4844552197831975,
          2.9321077169806453,
          3.2866454536991596,
          6.725184560770384,
          7.5237452943768,
          7.915790437258485,
          7.896181427945539,
          0.9120610304869037,
          4.944203047025814,
          0.5755876001664428,
          5.495288823237355,
          4.41530501373377,
          8.877041827582998,
          3.5091501255207866,
          1.1706701642760586,
          1.4299168205283586,
          7.615106317174723,
          6.182180633162611,
          1.0112267612279024,
          0.8410680611499743,
          7.009691314591199,
          0.7276300636419353,
          8.218600592903563,
          7.062422271564962,
          0.8134878064189976,
          0.8483771408519192,
          9.866395785011754,
          3.742707957561203,
          3.706421470668909,
          8.127995672575025,
          9.472485773838587,
          9.860010638228708,
          7.533781852589416,
          3.762595855309158,
          0.8350071669866876,
          7.771469159274368,
          5.58404249735805,
          4.242220092469763,
          9.06354385094736,
          1.1119748230615134,
          4.926251042908591,
          0.11353644767419069,
          4.6866064199412625,
          0.5630327568183735,
          1.1881791626807192,
          1.1752624677710488,
          6.492103021160636,
          7.460448792654233,
          5.833687650971596,
          9.621725484745419,
          3.748705795237041,
          2.8571208628186073,
          8.685991281894603,
          2.235958385194526,
          9.632225394406113,
          0.12154474689816341,
          9.69878826707639,
          0.43159911950576113,
          8.911431136980712,
          5.277011090862999,
          9.929647961193004,
          0.7379656473539886,
          5.538542844013207,
          9.69302535619099,
          5.230978441701488,
          6.293986381352625,
          6.957486889846171,
          4.545410647677732,
          6.275580800840634,
          5.843143119231002,
          9.01158010490989,
          0.4544638034145787,
          2.809631895922303,
          9.504114840765588,
          8.902637838909163,
          4.55656752785713,
          6.201325978015367,
          2.7738118298113266,
          1.881211597237613,
          4.636984049399821,
          3.533522280260528,
          5.836561118508721,
          0.7773463696498484,
          9.743948076661665,
          9.86210744479603,
          6.981617140197452,
          5.360963663441204,
          3.0952761628632777,
          8.137950197069486,
          6.847311725538793,
          1.626169393448913,
          9.109271844938425,
          8.22537242923169,
          9.49799913291924,
          7.2571950838836,
          6.134151959357899,
          4.182430362906189,
          9.327284833540133,
          8.660638895004084,
          0.45218670106189407,
          0.26366974497252005,
          3.7646336687804958,
          8.105533307818328,
          9.872761293149445,
          1.5041689110352818,
          5.941307153521351,
          3.8089085663102153,
          9.699143978146033,
          8.421189231357086,
          8.383287047111379,
          4.686931597949703,
          4.148195023376652,
          2.7340707193070624,
          0.5637549665092711,
          8.647223762550531,
          8.129010091300776,
          9.997176732861305,
          9.966368370739055,
          5.5543170560262745,
          7.689874151805105,
          9.44765729882428,
          8.496473906774115,
          2.4734810174319763,
          4.505441353100935,
          1.2915941515149498,
          9.540510272587223,
          6.0617463445088005,
          2.2864280550346274,
          6.7170068440585675,
          6.181282404578958,
          3.5816271803284048,
          1.1355759219962902,
          6.715731955927996,
          5.2030770090379335,
          7.723183917356393,
          5.201635011119934,
          8.5218150031854,
          5.519068387744856,
          5.609379715353863,
          8.76653602658345,
          4.034828662123971,
          1.3401522845064073,
          0.28782676313338973,
          7.55137255673619,
          6.203095513534647,
          7.0407976809922355,
          2.129641615089107,
          1.3637147558676976,
          0.14544665667881929,
          3.5058755880659698,
          5.899176868546331,
          3.922440450997323,
          4.374749220237291,
          9.041586944937483,
          3.4825546702330037,
          5.139894891598108,
          7.8365301274114305,
          3.9654278232127016,
          6.220867002278735,
          8.623637087467452,
          9.495206236576422,
          1.4707348092903794,
          9.265876251614944,
          4.921162930795382,
          2.5824438829895833,
          4.591357562382613,
          9.800325752854771,
          4.926180939928696,
          3.287516102875082,
          6.334008543167258,
          2.401456187781931,
          0.7586332810866392,
          1.2887972191064923,
          1.2804583895777244,
          1.5190269351229435,
          1.3882717264941014,
          6.4087474480321465,
          1.8188008439914483,
          3.456672833238632,
          8.967884099060118,
          4.739616402628723,
          6.675577385210271,
          1.7231987120162984,
          1.9228901880867078,
          0.40868616266478863,
          1.6893506307216455,
          2.7859033903195862,
          1.7701048427674682,
          0.8870253375705561,
          1.206358711006008,
          4.607787680327258,
          2.063337184057925,
          3.6426986104807546,
          5.034172708548569,
          6.903948286293653,
          0.39312139841098936,
          7.994103989090426,
          6.279003894909078,
          0.8175903194887191,
          8.735786241067773,
          9.208724005318132,
          0.6107795985486375,
          2.7687764814720373,
          8.062012797930613,
          7.482596903836583,
          1.8452101935637732,
          2.093493233367103,
          3.70472102791382,
          4.845229851910213,
          6.1825477153029595,
          3.689136395697724,
          4.625347161331479,
          7.474709381337565,
          0.366832028905979,
          2.5243694434402073,
          7.133495858845524,
          8.952068376871994,
          5.116774421156661,
          5.321134852653157,
          1.0717201133977605,
          4.474123668234546,
          5.326172664550231,
          2.4247050363472966,
          2.6924323094938094,
          3.7728416310462265,
          0.20071197777726368,
          3.220791655831783,
          2.1144800699654462,
          3.2749735217791462,
          1.1976213181925122,
          8.90527280739895,
          5.935924535540487,
          6.791023191444896,
          7.891712386073383,
          4.984421989290572,
          0.8692028808742369,
          5.371065418185478,
          5.868411180208791,
          7.4543947418433,
          4.316595462296794,
          1.2758030279556376,
          2.8377590579872445,
          3.630822963986351,
          6.459172413316012,
          5.707783046689119,
          3.5609672589784624,
          9.865152487929796,
          6.057748193568871,
          2.372267917359945,
          1.0178247262040374,
          1.5285913918433203,
          2.459577283845081,
          1.6068137325955567,
          1.8656702405130576,
          2.850951686938471,
          1.7337359529475482,
          8.967654246264251,
          0.8023374566164221,
          5.245113895702547,
          4.103968269896615,
          9.823786169086064,
          1.1203890216805235,
          3.9785559904574166,
          9.69470433275369,
          8.655071258939802,
          8.1707207094928,
          2.579028270449398,
          1.7088758739006582,
          6.68643219924431,
          9.293759891275858,
          5.567628930139298,
          5.7161268946989985,
          2.7997909366028417,
          7.694929331919369,
          1.8704374855752337,
          3.2367923640424365,
          4.254364386164168,
          5.07610378684455,
          2.4240973241508024,
          1.1483682473920354,
          6.1062004244163255,
          2.8863055324025577,
          5.812382214226123,
          1.5436271527420231,
          4.811401018548175,
          5.325894325515859,
          0.5182353682242691,
          3.366042781939206,
          1.3441467693897424,
          0.6337497047276774,
          9.899602323899453,
          3.2235384497472297,
          8.09874445854635,
          2.5464065476376385,
          6.8150272222392925,
          7.6022785988968655,
          5.956387406078443,
          4.715761885501584,
          4.118409141472686,
          3.4886826654299528,
          9.29529144247826,
          8.306194077877292,
          9.650269106665126,
          1.2429722348554473,
          7.308674752036443,
          9.383404568210379,
          1.8123306616566015,
          0.664962673667775,
          7.4112064929005905,
          5.744731131799119,
          8.41828776758272,
          1.397723766262895,
          7.952673118598902,
          2.0162732004774453,
          1.636559428657045,
          1.6426579793099294,
          8.14574720231382,
          6.651972206962001,
          5.230654247691193,
          3.5883048412350247,
          8.772005408131083,
          3.924451074226354,
          8.16599439471577,
          4.391349085702184,
          3.769444294249076,
          4.626797856696064,
          3.0137787416414206,
          7.476093801762511,
          5.027203900924792,
          2.322126951468173,
          8.995745732745684,
          3.8389122137321143,
          5.435528611139886,
          9.06472110964547,
          6.242379959139921,
          1.1689804070836407,
          9.398321236134752,
          6.277080530714178,
          3.3490561465708613,
          1.3927207266338726,
          7.9402518927029595,
          6.200727559285135,
          5.334610919763215,
          8.938925830509577,
          7.885972112245307,
          1.5167487973275118,
          3.1172206779554825,
          2.4848913981446574,
          7.43946292572677,
          0.3353243473577938,
          5.698896848713165,
          7.624586857406905,
          8.767656367617494,
          3.4208174871590744,
          8.212573046720129,
          1.1063173695520723,
          8.464522917345182,
          1.2748866233198242,
          3.9728729056036727,
          7.972953657795536,
          1.4991742734877378,
          2.2925139523264146,
          7.222525683930662,
          7.200365365460744,
          6.411476328852973,
          6.939484444671001,
          5.427244433475962,
          2.5179905890695276,
          3.4569599350391944,
          1.8159771680142567,
          9.084505613336283,
          5.833917947661204,
          4.008514167636399,
          4.620058036441327,
          9.472833396118153,
          1.533514031160802,
          5.862298320167972,
          5.05888678884466,
          6.1145423543464785,
          0.18110183820840509,
          8.721239089441514,
          9.321182824836123,
          5.65133183589209,
          6.966508238768922,
          9.224993811772958,
          7.072386343133986,
          1.5253904291426135,
          5.762883601668132,
          6.067150463828559,
          4.24130671302386,
          7.3644423562472285,
          9.343670147690148,
          9.255685129067764,
          4.508393714041321,
          1.1323804584075525,
          9.848411989623346,
          8.388980864459342,
          1.2466268120326685,
          9.208418826173723,
          8.698963620621283,
          5.188380571260721,
          5.912754357449293,
          3.9900270387013026,
          0.5476163882203133,
          3.3519724164590095,
          8.028534485980114,
          0.04632023004602859,
          3.334991716911442,
          3.9816869359094333,
          5.373956029379229,
          9.198556164127606,
          3.4634599436596125,
          3.469532018962277,
          7.3750124810974835,
          4.522179408898071,
          2.2460482293998196,
          4.524395161326934,
          1.4085702037979986,
          1.763869865062233,
          4.983677727394797,
          4.189254495045479,
          9.148459010681,
          3.623938991166331,
          5.805883502780435,
          6.322642879195303,
          0.13094456588333636,
          6.635373720167106,
          1.7803596686975143,
          9.610703174694551,
          1.4866272775311296,
          4.146241237270237,
          0.8534966807864386,
          9.968742518459473,
          5.021950103312426,
          5.953850173200438,
          0.6707647738842748,
          7.499604703991778,
          2.0990559309558576,
          8.980542894407137,
          2.0513964048200717,
          1.9068772066366657,
          0.3654966784809488,
          4.720669451099992,
          5.648411332626164,
          0.6570863942835237,
          7.755276166950106,
          4.532888347480276,
          5.243902693275801,
          4.407627469382281,
          4.00763060875326,
          5.596403313082179,
          1.552402459307125,
          1.8192813049527112,
          8.617856210135173,
          9.461154621336327,
          3.7330931627975295,
          2.707446731435538,
          6.439995432390157,
          4.087341710980964,
          0.2538635566034486,
          1.5615259736619036,
          7.159722288473976,
          6.589239419101514,
          0.2709599250348349,
          2.219721619329494,
          2.310747965880714,
          6.718927435987284,
          0.19710537754364155,
          1.0410858198457384,
          7.999160853731894,
          1.7854466205433361,
          6.527461078518747,
          2.381827810467265,
          0.9944139275934516,
          2.4317219099945406,
          7.2226693185565916,
          8.556964681062858,
          8.302198645669916,
          3.9718352961845484,
          6.680851365706461,
          2.0498429541582097,
          2.9314773026101326,
          8.963358185211197,
          0.13001923510736035,
          0.8550853085446808,
          2.078862551460273,
          0.26532203873819715,
          1.8143543508979731,
          5.830415609696922,
          4.214245505924979,
          8.926717110769749,
          8.17443561738441,
          3.4181735169787597,
          2.594234334312925,
          3.7969240816726693,
          5.902949425148077,
          2.6806364082287626,
          6.24148907849134,
          4.0941165219124045,
          5.520471808519803,
          4.361265291353167,
          2.9446575954191765,
          9.484533069621566,
          7.636057941597608,
          1.4011317576645255,
          8.684679758979128,
          4.874311982495136,
          8.945522268940914,
          7.998552559473152,
          4.252135044692334,
          0.22469308320117398,
          2.686773593849461,
          5.416342146608669,
          6.334782198261473,
          2.578876854332023,
          1.3935607407282413,
          8.34930236799299,
          9.84402180703552,
          5.256901823026858,
          1.716792858483035,
          2.7230732651936895,
          0.18390676547466733,
          9.14298806560499,
          1.1775108289014113,
          5.765164755142536,
          2.74055220687206,
          5.541780025157934,
          6.514203883518642,
          8.297418037072017,
          2.064212717606032,
          0.10995828658480478,
          1.3688563006880727,
          9.00018641848105,
          8.738900775625153,
          5.974131021703083,
          6.005168604336534,
          6.650366745462555,
          1.753712786234496,
          9.144119459249598,
          4.187705248920731,
          3.8313852824949746,
          5.189177052828375,
          0.46965966775055046,
          1.662833687560794,
          7.380336164263705,
          0.8279866792512647,
          6.031521094663882,
          2.4534910968132095,
          3.8929561404197655,
          2.8869373677069987,
          3.5567271646494913,
          7.1904590518424545,
          2.9712171562317504,
          5.664046402968972,
          4.760504021990997,
          6.636711653626481,
          9.36829739324758,
          7.325720972102503,
          2.149403785907568,
          0.3118313506128467,
          2.622640442998251,
          5.9507793070025485,
          0.5142581348425035,
          4.963662472012364,
          5.968428489168892,
          3.3424389081696084,
          7.7091220374582194,
          1.065982531337718,
          0.7513778173580876,
          7.281887562036033,
          4.954913162061985,
          6.88402396427736,
          4.348273386037462,
          2.464020332391068,
          8.191023176741997,
          7.994158789689792,
          6.946964708544268,
          2.7214513722996267,
          5.902306668690871,
          3.6097389694002677,
          0.9158207332663415,
          9.173135754622429,
          1.368186309189614,
          9.502373538208024,
          4.460057729579558
         ],
         "y": [
          1.8513292883861965,
          5.419009473783581,
          8.729458358764083,
          7.322248864095612,
          8.065611478614498,
          6.587833667107174,
          6.922765645178525,
          8.491956515653193,
          2.4966800885918596,
          4.894249636431405,
          2.2120944181960223,
          9.87668007996647,
          9.440593396866133,
          0.394268113685059,
          7.055751725156885,
          9.252483174156659,
          1.8057534512733353,
          5.679452305526294,
          9.154882975880419,
          0.3394597858579884,
          6.974202672468399,
          2.9734900737255074,
          9.243961953765304,
          9.710582451653679,
          9.442664891134338,
          4.742142166574638,
          8.620426509893134,
          8.445493985350703,
          3.1910047324325563,
          8.289154741506774,
          0.3700763471549262,
          5.96269878482053,
          2.3000883728770303,
          1.205668857772788,
          0.7695320162920916,
          6.962887758781397,
          3.3987496376806616,
          7.247667715287615,
          0.6535634079894237,
          3.152903378306103,
          5.394912923753372,
          7.907231648389636,
          3.187525029320699,
          6.2589137643700905,
          8.85977748236187,
          6.158631881823045,
          2.329594747536338,
          0.2440078155653802,
          8.700988739009299,
          0.21269410850387138,
          8.747016726841995,
          5.28937134027212,
          9.390676985128962,
          7.987832357736654,
          9.979341105333376,
          3.5071181545171015,
          7.671882889311269,
          4.019309136092422,
          4.798756203039089,
          6.275054632183701,
          8.736771141863388,
          9.840834691992951,
          7.682734138645182,
          4.177667821673338,
          4.213570022770702,
          7.375823015888915,
          2.3877714576830233,
          1.1047411313139466,
          3.546221576407765,
          2.8723899165408175,
          2.963081204559901,
          2.3360775104990994,
          0.42093189636361883,
          0.1787393473341381,
          9.877223897360315,
          4.277731337358624,
          3.8432664715968166,
          6.796472826930699,
          2.1825388786506417,
          9.499611839502254,
          7.863450144155521,
          0.8941100231225951,
          4.175807757849284,
          8.791183075621646,
          9.447320222914103,
          4.674015112498697,
          6.134113892107077,
          1.6703394609207523,
          9.911686261369766,
          2.3167170138344337,
          9.427317741351256,
          6.496466489923685,
          6.077367948788591,
          5.126885110165086,
          2.3066981171775867,
          1.7652803200550826,
          2.2048620907017535,
          1.8643826214425452,
          7.795844735667533,
          3.501252591667301,
          0.5784267656339637,
          9.691026301408113,
          8.837858849634257,
          9.27752283195213,
          9.949078226464353,
          1.738952492194873,
          3.9624201890265875,
          7.582384757040913,
          6.960206180537922,
          1.5389590633985506,
          8.158331249906178,
          2.2444057183666066,
          2.2381761482262306,
          5.3697442289341355,
          5.929399348417031,
          5.8008620783781115,
          0.9148683739775487,
          8.774608626303804,
          2.6560004258870604,
          1.2951492128280417,
          8.887480798689772,
          9.556514982297534,
          8.621276172654506,
          8.09516074724878,
          6.552419806390217,
          5.5085737060913935,
          0.8698675991141014,
          4.084532130706987,
          3.72688517012314,
          2.5975378376032623,
          7.234201136885849,
          4.9587573507877085,
          0.8104621590764793,
          2.2018320194981134,
          6.832587636595959,
          0.7613085949030018,
          8.512069140487688,
          4.951465270139743,
          4.80586577326648,
          5.924077846595176,
          8.246809659251491,
          3.4780920790219305,
          6.780161525590636,
          5.657319639957911,
          2.6702827016942132,
          8.78629986355158,
          7.974260216069281,
          6.584518346584255,
          8.505817290942419,
          8.672942009598025,
          7.083629767150348,
          8.37013328363672,
          6.974714616692836,
          6.801407717603004,
          6.186113782151843,
          7.527166395576412,
          1.586051052930737,
          8.808707591989284,
          8.71843527745232,
          0.29247283034559146,
          8.258167505647627,
          1.288698674734452,
          3.351188542591419,
          7.435082562916078,
          1.607598960483082,
          8.179670241190621,
          8.32134177957742,
          5.074677337608362,
          0.0638587171683358,
          2.870381331749128,
          6.169269183757422,
          9.811861780274235,
          6.3181352701666835,
          2.5980358106415977,
          6.340057030996114,
          5.3998537971585545,
          7.798453951511436,
          1.069806388269584,
          7.61027902502028,
          5.412665786761103,
          9.629920038589946,
          3.418721660386861,
          6.326218931339481,
          9.320281055100175,
          1.0250972799067926,
          9.372284872364512,
          6.878857223008134,
          0.678370591051719,
          3.0096356694681625,
          7.081720886452816,
          0.673506014687717,
          5.8217046017627325,
          3.4588305695295674,
          6.209155177674771,
          0.4574203381251285,
          8.715368061523762,
          9.734889691773969,
          9.688778552856915,
          7.496518317429247,
          1.3008624013063197,
          7.582631959290226,
          0.2458691645880151,
          0.22123551528997254,
          3.2361021914954122,
          4.886431904046658,
          7.704074178077932,
          6.832953766065052,
          4.459027063767484,
          2.736266662816659,
          9.971245001577111,
          4.261813022359729,
          4.513870243296755,
          1.6362382119166918,
          7.948095487499294,
          6.936822257814886,
          2.207696127887604,
          0.823810456158427,
          6.804993020747131,
          6.545112142811353,
          2.7325952699820935,
          9.508635622504103,
          1.5105789178090023,
          4.323348010426019,
          9.436159201675988,
          4.197273169261223,
          6.385259476640855,
          3.9759439796279428,
          2.7421520234867005,
          9.839776479598282,
          4.09334006315043,
          8.940992036791345,
          2.299546058910862,
          2.131047040250833,
          0.3113408288451136,
          6.5166682537588505,
          3.6852634372376114,
          8.64358249839637,
          4.732099066915572,
          9.681934279147217,
          1.8552551570312115,
          8.686231679556109,
          7.765968527917417,
          7.70921844644052,
          8.447832281168877,
          7.610239909429989,
          6.262203216314154,
          1.3124487768238757,
          0.32526179491251916,
          9.208478478156868,
          6.166503145207381,
          7.965372909761763,
          4.815223515125501,
          1.1730818896239448,
          1.2518579220255044,
          6.855652872289713,
          4.303058948994627,
          2.005247267003367,
          4.915945467414369,
          0.6420893707513409,
          5.819714019143988,
          2.6899340443509767,
          7.975591006371881,
          3.1036195892357377,
          4.552201490818012,
          0.11620539908100636,
          0.7244688779455888,
          3.924935564066848,
          4.799388347171235,
          6.000205481193037,
          2.9166257870930323,
          6.949818861265426,
          8.601223971892045,
          7.7985098889334985,
          0.39618825348357145,
          4.805069472578289,
          1.0493017841817487,
          2.4204501586252745,
          9.866625932671464,
          1.4249554290151323,
          4.988881534513561,
          6.181557343181191,
          7.024649705441039,
          5.5964868348691414,
          0.09770847419183659,
          3.2646130824399187,
          5.1771164338471145,
          0.8786649914483335,
          3.5062693120918076,
          0.33203108791366565,
          0.7857849715502074,
          3.9692327620159604,
          1.3271575404306035,
          5.675408482615581,
          6.894649691372657,
          8.005866991090828,
          2.0015024424481007,
          1.6748258225906976,
          1.0456784033440025,
          6.364302495436367,
          7.064757264869011,
          0.3158614482564204,
          9.362122462436899,
          0.5197128365147241,
          5.412963353010705,
          7.090605194509164,
          8.709691237460856,
          7.140869321324278,
          8.017280830697919,
          3.3945019254280604,
          8.148251137465122,
          0.8011484638467514,
          8.948166560605276,
          5.475923761537363,
          8.172977699624937,
          4.523182845183001,
          6.4357769519652495,
          5.264026609361132,
          7.315895217553319,
          0.8162998203058958,
          0.603520839905638,
          2.4710323401014644,
          1.5954468011318834,
          8.717835665922017,
          2.192139873580443,
          9.758652558191313,
          3.3689579177110685,
          1.8211791568869928,
          7.896985071424791,
          6.587077755008761,
          4.98195716453139,
          5.553635509376313,
          7.192017782722639,
          2.2845474133129873,
          9.963339160567418,
          9.747931621467831,
          6.503256863469369,
          1.9954245092914513,
          6.802282424312914,
          0.7219840897917584,
          0.30652502205806065,
          2.576828885112137,
          4.626229567393163,
          8.682725054083805,
          7.271690697663081,
          7.42706521199981,
          4.2549333444807536,
          3.4593499254696294,
          3.7103876298460268,
          9.876495637360579,
          0.4010919141248248,
          8.670314961224486,
          5.786754085723934,
          4.386154191895905,
          7.252576604151365,
          4.866689414247029,
          8.734232380816605,
          9.007018640112586,
          4.217209268734554,
          2.768277972350516,
          5.923503285933622,
          9.12363345616691,
          2.106621890056666,
          6.229665835634828,
          6.3156022009252055,
          7.33113022415281,
          1.315676851272598,
          7.158249646820885,
          9.09032520665641,
          1.7968310887024197,
          2.3754332492387764,
          9.713950940416396,
          1.8097695270948977,
          8.543850933695792,
          4.922778564480348,
          2.4723107440317706,
          8.707499012725114,
          4.453052550026655,
          5.148173539296902,
          3.5923336939976567,
          5.9295085143492745,
          1.6352387258502277,
          3.910815366517607,
          9.694123223352875,
          2.5813343270112754,
          6.567366645412922,
          3.251900642246949,
          7.734731256866007,
          1.3087366071834983,
          9.698210450785448,
          4.5378954138363925,
          2.3605046334646396,
          0.7349674733001266,
          1.6975790508754074,
          5.197739485560176,
          3.3700317643128628,
          8.288833658826094,
          4.308875236618059,
          2.487142725876299,
          6.171449866040301,
          7.067772168854458,
          1.6704190790094986,
          1.6761921628831766,
          0.3667142693354297,
          7.364020150656405,
          6.638045276218051,
          4.746308757498139,
          8.441704489691972,
          8.056701529500533,
          5.853543643967521,
          8.682712805132587,
          2.0584121003676827,
          1.1191961939772788,
          2.697496115169896,
          0.5708685608931485,
          5.31169528001032,
          9.366056922949614,
          0.39343540668509647,
          1.221099140100268,
          4.521990282834353,
          9.33875017527905,
          3.161561049767505,
          5.072348086883924,
          0.41572859050392097,
          1.4834320096208886,
          9.86630122958847,
          9.651186964360456,
          0.04939980934409616,
          9.51811785423239,
          6.391199378155004,
          8.679182945200221,
          4.547398556338591,
          5.155960285792503,
          4.888465802569202,
          6.668642575461043,
          1.396512547563129,
          0.2997358987267795,
          3.079299415911909,
          7.0468076273664675,
          2.0185345212294834,
          6.734324333249173,
          9.699120461072704,
          0.9390071578941839,
          6.726021182251262,
          4.437502193045711,
          8.681422543775053,
          1.771497894473859,
          6.926259522261645,
          8.381152896481103,
          9.446142194740233,
          6.832480282896459,
          4.971747640084273,
          6.178472402012138,
          8.689049844787181,
          5.706097466388297,
          0.3038705969683686,
          9.309486955069778,
          6.895267510315612,
          6.765133857772465,
          2.1567515239771717,
          6.5888547023265716,
          3.938644056541585,
          6.512329770414921,
          1.0659303030799072,
          6.5784530460303605,
          9.994137257706665,
          0.4821203886055603,
          9.771741842213173,
          4.069079607228706,
          8.707534503372592,
          7.823854840582735,
          5.6701626098666775,
          7.384492092513265,
          8.78515561301348,
          4.0414032165103295,
          3.270331615632387,
          6.675933855635847,
          8.078459419412585,
          7.622851347766158,
          7.978136488586345,
          4.35583314812933,
          8.178342161750216,
          1.2020905537060844,
          5.444890979608496,
          0.057586604981215705,
          3.2458582990027027,
          3.664615348713979,
          3.961726916092554,
          6.954672066898622,
          3.885581012703457,
          4.486936226225307,
          2.375441308743275,
          3.732517916293401,
          2.2726962726315145,
          0.7319592376844364,
          6.034485933813779,
          6.682127985550163,
          6.194903460096145,
          4.6349404380057235,
          3.797857801792298,
          8.633336495718252,
          5.190817851362181,
          4.79181877629731,
          0.2564206580643569,
          3.4124782762615635,
          3.8019561878585706,
          3.988227808969005,
          5.801723692273323,
          5.336025467268785,
          6.079050927934446,
          7.6488326154212825,
          8.129857387160936,
          7.181230762264944,
          9.555236959549347,
          0.1823258267636163,
          1.957779856835461,
          0.0756287497814212,
          6.47474714154603,
          8.98030548949987,
          2.4348229657629927,
          9.270345447963066,
          0.6026739028956085,
          9.344360268055143,
          3.516226872396344,
          1.0142082844921652,
          4.858717591863257,
          2.567765677205079,
          2.8487290196192285,
          3.0728996492628657,
          8.030258978326634,
          5.391612766752544,
          3.1130769915600363,
          6.103337833109183,
          7.161506742231936,
          2.7262400073353374,
          4.135491015253515,
          1.2188609333694755,
          1.8114934953468032,
          6.811178539649828,
          1.8143834769562694,
          5.251633836670601,
          7.090462617224327,
          1.0687692309474384,
          5.673122196289036,
          2.5656278370136376,
          9.629268752375799,
          4.835456467199247,
          8.059925497751582,
          5.502265421562617,
          0.43412532854819164,
          6.3315137559402235,
          9.51403342206657,
          6.016118201463312,
          8.191888594267901,
          8.842064633484078,
          2.2807977194893247,
          2.1204483990822665,
          6.1098098885099175,
          4.110284698067047,
          8.398613028667203,
          9.000231233980111,
          3.534213793027181,
          2.3687055897448204,
          7.805255152438618,
          2.748060355481361,
          8.226143185136785,
          4.237382536487628,
          6.675498992914704,
          0.9553531383466818,
          6.23859324676573,
          4.517676787372292,
          5.866084631754741,
          1.6801420774486342,
          7.368737449441821,
          8.627970775432285,
          2.1673980009077565,
          0.9571455552016173,
          0.23638586046336396,
          6.4197150044326605,
          6.070940360887808,
          5.4669741271407,
          2.3194709611597544,
          3.9090599590551465,
          5.944763351861731,
          4.967668588591694,
          9.877855202148872,
          1.3643975255673313,
          6.951445540475937,
          4.043187681042921,
          4.281996149256147,
          7.175977656581763,
          6.924361513243697,
          9.912559937021882,
          1.2839428945412523,
          1.0410964938416634,
          7.243388171287411,
          5.783869170064091,
          2.7416066655980584,
          0.794193689889866,
          0.8565824959643054,
          8.941908746641182,
          1.918673247187429,
          3.2337156211552074,
          2.26656402226988,
          3.5499630583193733,
          0.6942384274609337,
          5.190597909082704,
          0.676125635922149,
          8.003565078223616,
          2.3371208191043302,
          5.400119146045106,
          8.800790875614583,
          6.5087736904719415,
          5.329577865513353,
          3.243337531153756,
          3.330019130581979,
          6.694869551981901,
          9.941393612211675,
          6.618391898493786,
          5.577834173700249,
          7.306505102392461,
          4.652056122837181,
          0.6014234260078521,
          5.6229681587790985,
          9.576252845053801,
          1.7530294235765964,
          6.900048908206657,
          2.0093368865905648,
          5.3582768447308124,
          0.9667644964671962,
          4.503709362581851,
          7.561633288952461,
          3.4757152423898208,
          6.64911724487218,
          7.954499607897292,
          9.271778194794527,
          2.3464208185545354,
          3.993159158093081,
          1.5241601333041743,
          9.924835021583752,
          9.270009679242953,
          5.399571302805596,
          8.420332943764212,
          5.209579772720422,
          6.2358568800275975,
          0.8912443211601662,
          7.552704204968079,
          1.2771348363523483,
          8.260676302525283,
          7.820280876703859,
          7.087446977429765,
          0.36160380524762115,
          3.031283559453286,
          2.631125699108429,
          3.6013640747151907,
          0.8764274676383854,
          9.369578230310628,
          5.538022407123763,
          3.0552431065802352,
          3.969815170742834,
          4.472025405048356,
          6.005943333606173,
          5.156794276964978,
          9.193919732144174,
          4.969634829058302,
          9.921580148233126,
          8.514249577450958,
          2.085105143573358,
          9.305952146439163,
          1.163663978854761,
          8.174497084911916,
          3.806232934765801,
          8.779743204450694,
          8.680566901074503,
          8.059254001176212,
          7.900304363070614,
          3.046791390980408,
          0.8091928305125218,
          4.029801787651614,
          1.7352451498650867,
          6.9495108890246176,
          3.4609972653778556,
          9.756102008599148,
          6.40972077345332,
          8.224805636343609,
          1.3252467274184843,
          8.620144822726225,
          9.227571905133944,
          4.870619188189359,
          6.062529377509774,
          7.648098009029955,
          1.7483862726041255,
          5.0256607646344245,
          3.986630277723131,
          1.4637399216224911,
          3.6753442229153146,
          0.6817230938549357,
          0.25811906949486985,
          1.3516628915482276,
          9.631151115891738,
          5.49529535895017,
          9.6582216115322,
          4.32497878330132,
          3.1181613308525957,
          5.061418628402441,
          4.3951168863291015,
          1.0566468426174391,
          6.408263146902062,
          2.160381825095996,
          6.195879548978295,
          6.502010923981533,
          1.520248531286481,
          0.6134962711066816,
          7.807615860684399,
          4.5980042376932015,
          0.5816379550547579,
          9.948663171697671,
          0.5778056099636664,
          6.950352288585532,
          9.836789252634135,
          2.391801042159256,
          1.4224936868719618,
          1.213849394224289,
          3.0327514756759557,
          1.010458110106467,
          6.9216134169413195,
          0.6229179813006269,
          5.094221281497897,
          9.966968538529768,
          8.139702695060189,
          6.152194382310109,
          3.062536207866117,
          6.238958362916385,
          5.270414639116517,
          4.260833838903714,
          1.3071037674019947,
          8.866042152404667,
          4.497846488213225,
          1.9462251182076507,
          3.677593508772896,
          4.1412975252892705,
          8.275378955668742,
          7.336143805614021,
          7.693048936413398,
          0.11031264428647214,
          4.161539981797615,
          4.813441516353237,
          0.19192276823056686,
          2.598132087450342,
          7.60289823122135,
          1.3710970572899905,
          5.353101314525917,
          2.152018720172375,
          0.12120774643893273,
          2.412014575995415,
          9.758737549100537,
          8.015371118829895,
          9.595766443210334,
          4.878540439263625,
          1.097361986775035,
          5.47959488973693,
          4.543773345599609,
          8.44357082739616,
          0.9808258078424459,
          4.882411370217782,
          1.5004866469398426,
          3.2467592689005995,
          7.373570773877996,
          4.7601812936876655,
          3.7588828514576935,
          3.944762785700353,
          4.594467684059866,
          7.850165438370569,
          8.920846889402345,
          9.553346865039282,
          7.869033862552951,
          3.1540689574801273,
          6.881347060865421,
          4.376031240553919,
          2.5467062204605115,
          8.408715794259226,
          0.38426348962324997,
          9.017619921354235,
          4.614774646247342,
          6.3720147680828045,
          6.593539222057827,
          8.951177407065364,
          6.366696821672074,
          6.139335847600618,
          0.6665204056068996,
          5.18408021945204,
          1.5016900081704165,
          7.374337687214856,
          5.122219208126745,
          6.802277792083533,
          0.41672900602384266,
          0.8479201604580322,
          7.163233880626823,
          0.7208433599867337,
          0.712567277652586,
          0.1210847523488745,
          9.5650139829948,
          7.37508359459007,
          3.5325140850206416,
          2.9653558128765525,
          3.4970322974584955,
          7.746535311811819,
          6.613706110704144,
          1.8519556786746794,
          1.7410933533408435,
          0.9839564971339732,
          6.603027197013382,
          7.643726622217359,
          2.6504642832500402,
          0.20944961030912812,
          0.8217166747642735,
          9.678600348450304,
          2.9544477747742026,
          7.692231478381336,
          6.2466356885426375,
          3.8193963965289592,
          2.0568726219555513,
          1.2138641815940643,
          6.150129680388666,
          7.74633780637788,
          6.439042535411307,
          5.303021332491583,
          0.41951223431636264,
          9.684887775943839,
          7.987141916545745,
          2.928220367009647,
          9.799703293588507,
          6.018815896363221,
          5.824226582072464,
          7.4807317942953215,
          8.117697880901375,
          6.564786073315027,
          1.2809574636620003,
          3.382675059944984,
          9.280836403260498,
          2.2461561184385195,
          3.7216702383751334,
          4.32076882944196,
          4.394049896944522,
          6.129395824945255,
          9.430758377447075,
          2.40692711832505,
          1.2150137630091806,
          1.9747048985993731,
          8.869249002092696,
          6.458108126552061,
          2.859067892391601,
          8.159469389686173,
          8.61369996363436,
          8.465143386902781,
          9.189265336395545,
          2.522410201733616,
          7.550419287462783,
          4.6053949727414,
          8.419985528900614,
          7.284906771616132,
          7.764474464997246,
          6.561618376810715,
          1.7742876946970687,
          5.450269188969383,
          9.846697395245082,
          9.373880664971189,
          0.4317373579701167,
          1.6481481572943713,
          1.317287734545619,
          7.259799099852955,
          8.17785329856945,
          2.1351136631067194,
          5.05852692951829,
          8.407030280112,
          7.328015447662506,
          5.422372054918483,
          5.903476904587729,
          5.0836054691628,
          2.9754845131882055,
          5.650219928590161,
          6.888853020500907,
          8.733229158608077,
          6.362913539792481,
          7.61121537043158,
          1.60071634954573,
          4.6155747441978985,
          0.09331619827093296,
          2.46678864521623,
          7.264617151130048,
          9.918099513493635,
          0.9917809958721591,
          4.0149431586128825,
          8.000709686991595,
          2.0403563462889887,
          5.550849493022863,
          7.330712960296748,
          6.159854502601791,
          1.8802473461541613,
          3.553845686857394,
          7.837917844853973,
          5.542265141320167,
          0.052296135429127366,
          7.6099076002809385,
          0.3531135494023907,
          7.457337827312322,
          2.024805601652374,
          9.580734801193802,
          3.679407513020845,
          3.269316163380791,
          1.4888805033244468,
          3.0560421549021486,
          8.766507618282006,
          9.963343376272473,
          3.683095305068483,
          4.486106309545425,
          7.220709382027371,
          8.861957804650745,
          5.930443341867841,
          3.9152569817782936,
          4.126218408486237,
          6.956181464968068,
          0.032182636042786816,
          6.195893374598407,
          3.554930104413574,
          7.941973312770843,
          0.9299063982313216,
          5.882022669483905,
          4.809728898861238,
          6.423255259052274,
          0.6485359448296835,
          5.799837874281312,
          5.614845879595237,
          5.606600944161709,
          6.034876665964548,
          6.764679372263622,
          8.049889996807698,
          2.6982072012821434,
          8.250494101800621,
          4.982556822634536,
          0.7705827913433116,
          0.585509292439792,
          3.3423831869606078,
          7.8489697711146755,
          7.076809347409157,
          7.886149646724064,
          5.172690564416094,
          4.401989979554905,
          1.4745252670628395,
          3.2819275360931153,
          4.340193661738753,
          0.8860042967961723,
          2.2061195271121123,
          5.982252940637388,
          7.356631142391898,
          9.983475113929497,
          9.331133313435577,
          6.425651995351915,
          4.21248053294072,
          6.361773647082327,
          7.85651618080232,
          1.1833619092338732,
          4.099048896962882,
          8.398022856356173,
          3.83832951933044,
          5.718722712271865,
          5.877693608621982,
          1.8447625313363936,
          3.622354416522884,
          3.3451128874193214,
          0.26196708532064794,
          0.24191763891355245,
          8.316970436757735,
          2.7307080997281243,
          5.180787662388155,
          2.9872557358877305,
          9.406792451153406,
          2.5929675886577375,
          4.296568127389351,
          8.727302504846019,
          8.419335667918087,
          1.8610141784627732,
          8.026433097957105,
          4.581868867378926,
          4.829688720853552,
          1.3347997241594378,
          0.8060151375712465,
          7.279393069737652,
          4.964611523552998,
          4.3685070261517955,
          7.295082286523967,
          7.6551289899110975,
          1.5890816766935356,
          6.102251494776413,
          1.3535408227768553,
          7.513750860290457,
          6.569551562671395,
          9.56614621083458,
          0.6895801635642118,
          0.5705472115125432,
          2.8218707469320012
         ],
         "z": [
          31.56316894158193,
          194.64326702385273,
          134.52704900858473,
          93.58057531286029,
          32.10236429742169,
          23.069989813375535,
          24.17479209618247,
          176.27252010332103,
          80.24561713577965,
          113.99646113153824,
          2.67517748447621,
          220.17188044945613,
          170.27885973589363,
          9.56561625381428,
          28.16671794814658,
          37.46751442327468,
          21.136646160286507,
          69.3707127892963,
          66.4084892426595,
          14.757045369042455,
          95.44800546417531,
          12.069494887032352,
          46.93651450153932,
          56.36546246093335,
          66.70901992964231,
          140.82641201330216,
          33.970248947038364,
          76.25202133294808,
          80.81256109033785,
          28.465813997366375,
          71.76218920660085,
          23.869045032207158,
          9.87617903663922,
          184.65886841476768,
          188.20280844285134,
          151.05177055946925,
          28.161405170644322,
          24.0820835075271,
          93.18791845631722,
          42.41071912075159,
          20.345001643825235,
          73.65133880600035,
          6.40931695455756,
          181.4558247907442,
          42.5815620374001,
          109.72119608862744,
          27.175660096576063,
          51.516653625766885,
          85.53643339179823,
          10.206278647967435,
          213.47920949418736,
          134.88514724057225,
          204.76739890895072,
          182.79216450569996,
          102.23085525212113,
          184.87964945182497,
          25.820765284962906,
          20.7992628896678,
          14.572498739398652,
          35.755301701419484,
          58.28494900588458,
          45.42272397826437,
          160.78554855972936,
          44.470229428889255,
          29.827612865952013,
          78.31217571154994,
          11.998583974227081,
          134.85167142806503,
          13.574357789227346,
          201.06412456926617,
          131.9755691974876,
          15.176835528557891,
          4.15797455410428,
          135.66286316482297,
          130.2729690101987,
          122.95178857660598,
          132.39089961244107,
          22.994970602554723,
          33.36220265620781,
          31.40473067724033,
          172.01520716365593,
          81.76596679712382,
          34.10116682919343,
          27.773736637571673,
          46.80522642051358,
          35.946429093827646,
          128.85187541482858,
          84.36349525939096,
          188.62151652490044,
          54.050675201462816,
          32.913785084960956,
          121.91122021258383,
          131.8570628970398,
          78.21964933568758,
          127.08474558755802,
          55.2527119784569,
          63.36138307559931,
          46.71389216610768,
          24.86938554536469,
          15.300924528289544,
          1.7934269518188517,
          110.41598395555168,
          47.78516446689233,
          79.02865039809157,
          196.127276653769,
          21.05286782571206,
          43.41814782525209,
          139.88593330826214,
          33.95878496342351,
          6.230080549526757,
          37.56379946567725,
          12.338987386339884,
          182.922446417198,
          147.03847668095315,
          95.14241989004907,
          168.04779297568442,
          133.9770613368074,
          36.13178167085019,
          168.18556169128786,
          60.28071743437673,
          158.10574783007817,
          188.85939134920156,
          49.975579700927085,
          27.193417067747287,
          32.277792117731956,
          54.433680655004885,
          138.7382060678405,
          160.87861376685808,
          12.90079795457601,
          59.84943640755653,
          53.302140036311776,
          25.943396144521046,
          3.189234918184213,
          32.135222794957606,
          196.52711443218564,
          22.764024838596043,
          79.65407383266194,
          113.6263556569135,
          41.4681711422533,
          204.46943191162813,
          211.92841484833252,
          21.949197156773636,
          68.19906555873581,
          38.277331540861006,
          23.41698653796383,
          26.43910390903962,
          99.19787605251666,
          68.74403527165266,
          27.847721071077803,
          43.604117268003705,
          187.14881249057802,
          39.98000349982289,
          26.165000064936205,
          65.98234912862789,
          212.7911204459061,
          38.43855162597843,
          95.28566182619008,
          142.27796926777654,
          41.11722207150546,
          106.57985085846111,
          47.364414089979306,
          85.28456349423567,
          90.28509143250976,
          78.32944401242308,
          7.9391252423290055,
          165.66406399600987,
          47.347270452984944,
          21.91345491114071,
          0.9488945550832573,
          78.52081177973562,
          111.2833963414801,
          31.812483974315846,
          67.61429798777034,
          21.850603902314447,
          100.36719263596987,
          24.246922917527215,
          120.13949250118606,
          35.654633361607594,
          197.69266842650418,
          19.65827018992422,
          52.82936827938534,
          14.09332067884447,
          190.76802974344264,
          180.2739232566979,
          14.288716809750246,
          114.4070492918077,
          156.22962752570396,
          65.65958412592724,
          65.0830624436815,
          32.569958275806734,
          3.9148416763189195,
          180.33002306813015,
          172.0307274783987,
          98.3182445492162,
          25.1675521072819,
          51.95313396076976,
          136.76693206584793,
          193.43341737642626,
          174.64367591898696,
          127.63131891523311,
          103.74934124126253,
          -1.7321010906709324,
          6.93421838172315,
          175.35633508447356,
          87.54532312240428,
          24.97738306781961,
          25.77939746556945,
          104.6491081003921,
          12.463421103829248,
          38.423506722565705,
          72.87908796575508,
          106.87248396531668,
          89.7269124281535,
          33.09375527617733,
          126.54203592645884,
          18.818938696655977,
          23.103235654636237,
          133.026177004047,
          103.37276267770953,
          157.5446262400956,
          115.0568090582055,
          68.89097996126083,
          14.425032162634773,
          53.20102284687433,
          26.397621664592364,
          30.638613197733715,
          200.7901881962256,
          37.958137030490164,
          187.25442831371925,
          92.38946013636166,
          152.03935022920413,
          58.66238572897017,
          73.161245804639,
          44.60428561290963,
          26.510742485898163,
          115.60305013992607,
          43.37349356362351,
          17.216513063831886,
          109.76016961465488,
          13.330099101956154,
          203.3905379723808,
          206.43437448565382,
          191.07779920480002,
          51.27142599463353,
          22.15300927382832,
          188.69096847286806,
          41.59347291338121,
          186.71572767324233,
          217.90735692027098,
          163.69002468156515,
          40.12632623178104,
          40.32427351301087,
          145.20397363182292,
          20.334030787198213,
          26.998508936130772,
          75.67440306651172,
          178.61461314028693,
          113.85380023015135,
          64.60307244723023,
          19.572758386008122,
          87.70802531276183,
          221.42507206470722,
          14.683375027151099,
          64.8756921169585,
          149.6144508820521,
          110.63592975174926,
          109.8614924377749,
          111.70920352391417,
          42.18670079973638,
          27.321844036970614,
          151.59835876064565,
          157.40964064309105,
          174.72487682184197,
          168.23979355287403,
          63.51541472123583,
          54.820799252792845,
          136.26195952945974,
          115.24693002750321,
          104.76915693271647,
          142.81189088063252,
          178.37898129427498,
          43.52275405771315,
          42.42741821276166,
          2.5948747233168175,
          74.90065124752834,
          15.910392862317385,
          44.28924892620702,
          69.17374235350218,
          16.487496379039722,
          67.33747650622405,
          11.973212396338376,
          4.569763820120291,
          152.7909486720038,
          43.313020952051886,
          30.884473450555564,
          58.36455148639929,
          126.63340653588142,
          13.638228749971482,
          94.34799613757399,
          26.245493477124235,
          -1.3619028524196493,
          86.56558083697573,
          60.380890402348456,
          95.60735631387548,
          129.63633597632258,
          216.51389163280092,
          73.75883463934106,
          45.507378594081786,
          138.34250726580896,
          41.44627346973904,
          40.885331450153636,
          26.173587662731528,
          18.724305363203804,
          206.64561539470142,
          156.4700502454312,
          118.07449169939082,
          45.72235283007574,
          27.60663056887813,
          5.447057240041539,
          13.678204005194651,
          67.19948832560716,
          109.25942544793956,
          117.02000747154456,
          25.95812360842907,
          211.32638389438793,
          120.45035263473484,
          63.13209351151226,
          96.7974427239112,
          55.07999198127936,
          30.801345096997625,
          38.38398777895211,
          135.60488688225917,
          7.640377500160197,
          34.9204518555999,
          29.440046883054066,
          20.109898570654668,
          152.5775789197995,
          119.22066955516262,
          46.47661949192863,
          2.722908780305884,
          55.06035298877296,
          57.580874767837244,
          33.59534134504223,
          57.239641955848704,
          52.36379767074725,
          92.13366830042241,
          93.18631564546533,
          12.230944514008128,
          59.421638261688734,
          77.93054467566488,
          78.76549474949,
          164.69299229059024,
          100.33889864013658,
          28.3951741915744,
          12.949173942877044,
          107.40110728656231,
          25.94979455635519,
          81.6265980734351,
          189.53004253446682,
          87.02701744377646,
          59.06281189808379,
          90.74519049578609,
          55.09587616946007,
          75.6656053246181,
          197.19979747865284,
          31.60906488470172,
          205.08893633985593,
          191.5661421603634,
          10.248844304927665,
          10.944216754270979,
          30.831736953565798,
          6.392125976122213,
          33.01021178122174,
          106.54040299321206,
          4.807452556670001,
          46.60503127198402,
          159.40865093258523,
          19.278034784550893,
          142.84785080666296,
          34.049696630526654,
          7.757310992161051,
          109.95957915384834,
          114.45506571610228,
          160.1818395307867,
          128.19158521754764,
          141.78502678747168,
          41.48124844779473,
          11.139409169015707,
          144.29819636043035,
          144.17756933263624,
          204.0879812688275,
          33.99429267268038,
          33.59497303603919,
          135.94686251401788,
          34.80442636570136,
          198.6080279344997,
          163.69094612926048,
          44.047111006792846,
          127.67697644510227,
          137.83924307405672,
          6.28409317791354,
          167.13532091721567,
          49.088591989531714,
          161.89361766749707,
          35.13257237090443,
          181.3253617995956,
          57.60533481071561,
          24.94957210989256,
          180.84754112287473,
          29.814232472007003,
          28.02672095713762,
          184.65939316534354,
          190.7562820400537,
          66.29486809217813,
          94.85517128805867,
          68.0404424808808,
          17.26935960889103,
          27.047756277966016,
          105.82629688918165,
          137.29122739037808,
          138.11385227771137,
          140.95275269609562,
          2.7494235986620983,
          51.50304221186208,
          33.95816089946984,
          91.51061994879653,
          35.637306570503526,
          188.48860423738418,
          40.505044602748264,
          27.6749459982448,
          17.632421216385136,
          133.71479306006472,
          92.73436082780736,
          22.998114760669857,
          7.626472958180304,
          99.91195635494995,
          10.676988227900047,
          157.3069833217007,
          108.54770384709934,
          22.861817001650742,
          34.62748756063235,
          197.90716859299897,
          47.427582935268596,
          42.66409403971589,
          159.81874677292808,
          183.15838499931243,
          213.67038674936552,
          138.62165462641215,
          55.72024561619831,
          21.491285949786317,
          134.86200592783214,
          78.64447092457043,
          58.12263332948036,
          181.35590802045135,
          3.3293883260454082,
          74.84632509125636,
          21.32491418301995,
          64.21334023187023,
          4.975895373301057,
          21.038698967498856,
          14.66174107754627,
          101.18552657073148,
          116.61320293081258,
          86.02029266783089,
          215.25515446419314,
          24.087714068727443,
          48.13340080659095,
          161.89484914675919,
          37.78192583894674,
          209.34976552402637,
          19.06468430306866,
          206.94579776273514,
          21.909643173857372,
          172.4319723350346,
          69.25264302680658,
          218.29395727403755,
          26.639265174089637,
          82.32940849647471,
          213.31692998961438,
          65.32720753989243,
          105.04577474972116,
          101.69440304300691,
          58.1217852148555,
          83.45196188584531,
          79.37564148090874,
          173.6609241744835,
          13.368210462950296,
          32.65692699319922,
          191.58023430167447,
          171.8784487026783,
          47.335462551264364,
          89.16380887029673,
          21.566528314435143,
          11.724193583960536,
          59.1407223027773,
          43.69589806964864,
          84.63178331755931,
          16.202499021364275,
          203.41131609598224,
          218.9673744011504,
          111.92480883317495,
          70.37157520014941,
          16.317985143872825,
          142.97487136264505,
          105.54922963491249,
          20.663290230868096,
          183.3119394371841,
          152.05659196416985,
          199.31053117393793,
          128.6289479854385,
          100.55004979689322,
          54.83672844445621,
          204.28176135348914,
          149.10328334324336,
          2.218981109713094,
          -0.6391448975289512,
          49.04945545902504,
          162.0640526651713,
          204.50540976333053,
          36.79422620848192,
          71.42451826744363,
          57.82116948465397,
          198.11986945762288,
          144.5584475298113,
          157.08404953213727,
          53.88587519130089,
          42.79473960239074,
          24.66258279837879,
          25.43720186753033,
          166.99955868909203,
          140.5751423971503,
          212.07921583837307,
          217.88650009971613,
          67.68711931025206,
          131.19051272017867,
          181.50988647261835,
          149.94710601426934,
          35.33037229489834,
          45.95716630242674,
          20.14006859767204,
          203.75153264585234,
          73.71734177460532,
          29.488163721899895,
          99.04072543141217,
          107.52270970684661,
          37.47003368361682,
          24.762592619146016,
          108.05360495241106,
          54.40996862509969,
          136.47820356085248,
          81.03011961124308,
          165.36250229745852,
          82.75668718456365,
          92.95282960492955,
          160.00902137397478,
          39.94109983623681,
          21.252720279149358,
          14.55316446920893,
          139.62673111719945,
          104.46311712308048,
          111.44124190174887,
          15.736254481644618,
          29.54677794095066,
          8.328558131814285,
          48.81090748676755,
          80.40672851595649,
          44.04499901880977,
          39.240005771198106,
          186.4164755699163,
          39.23770329144059,
          68.57250216404668,
          128.4460291581688,
          52.4001985263509,
          105.01323863962455,
          154.1547865417431,
          184.77173695378167,
          6.488849273043734,
          191.57598144373915,
          65.5696155120972,
          29.623666827608847,
          50.15324765858877,
          205.35646713307625,
          63.74021277694198,
          34.97340438144399,
          111.02651235337605,
          19.1946687324114,
          19.43020068552465,
          14.09736985931073,
          17.830032532316597,
          26.6160145772789,
          25.156360443163607,
          113.37828092747537,
          10.7079657419917,
          29.185023473893597,
          179.24205590239706,
          58.74500117414121,
          98.44844355873322,
          5.322580132768103,
          9.896681120484985,
          31.76578569742788,
          12.839487164055011,
          27.02906032273008,
          12.167083447548997,
          12.683759458501779,
          4.408708378078776,
          55.94505411280968,
          13.207516336733578,
          51.33321411727383,
          55.21905531158406,
          111.96924189498337,
          28.902533916703575,
          149.6335525739416,
          97.41866843221514,
          10.76106029788327,
          162.6143242883163,
          186.46857738291624,
          31.54524665891132,
          35.540036073271104,
          148.9173277460768,
          134.15741757432318,
          21.148955095581353,
          10.915159032590498,
          41.32484126143363,
          79.85770059382605,
          78.57231706100364,
          46.952794131623854,
          52.29130015293929,
          128.1580175266027,
          2.580041442261632,
          26.327060713923085,
          124.56092644564188,
          174.85189793571658,
          66.03325379344858,
          82.83930143392745,
          29.130931707077373,
          46.26993623037642,
          67.69854998499929,
          18.118398250670243,
          42.388404362590336,
          57.600936086468465,
          19.892909281380117,
          43.7390889978353,
          25.329054168651844,
          37.70264346673792,
          6.6968309228955185,
          181.50388601800995,
          72.38904860513065,
          118.8756303512334,
          152.59338151989587,
          68.91258858905685,
          3.863838645955186,
          64.40711129653207,
          75.3265371396329,
          124.70228245280963,
          41.30091574672774,
          34.03058909306274,
          31.657907051626804,
          36.05639048957549,
          93.70171301001439,
          79.4765649286571,
          43.77446845375219,
          208.352470077625,
          100.78423919732434,
          27.137203394841514,
          32.69331404695912,
          31.696104796691195,
          23.676091881673386,
          34.579805739478296,
          10.296623609010231,
          40.085880857762824,
          20.692656840952367,
          188.05487447033795,
          27.485050619418196,
          81.18521710887543,
          59.45098466435749,
          201.56008150778024,
          1.415228741817128,
          45.650438098831025,
          191.70810813670218,
          172.16012737524113,
          141.86381667198572,
          45.835243943587656,
          22.645809058771704,
          116.30748667640522,
          176.63978623048624,
          85.98687763880434,
          92.66032107286334,
          31.839767412005603,
          136.8348756146667,
          31.861203032343216,
          30.233291565184192,
          46.942631176594446,
          66.45709669448475,
          16.903074868371373,
          13.638964470179463,
          73.00335882073472,
          16.343287095546373,
          72.79487689261622,
          35.38233615326117,
          64.10691051879749,
          82.95785484787253,
          14.361034042327534,
          30.287340305753347,
          20.15741935604552,
          16.666549257779778,
          197.3836925624149,
          33.7247199274809,
          139.5845767534423,
          31.993959957776333,
          112.73478300018006,
          123.53955317455477,
          69.51683115312261,
          68.21375664035652,
          49.38703104745753,
          21.353825491618423,
          204.2851862954014,
          138.77259663580696,
          205.9342362974325,
          35.15874311812492,
          114.62119831644063,
          178.90622945628954,
          10.900494748432447,
          9.419225667697592,
          111.08378084872489,
          86.81161536710081,
          141.3390841089636,
          21.13499115326151,
          159.16782198032323,
          30.28246450708271,
          22.464512806522947,
          18.966773632513437,
          149.419654360415,
          103.21087564378884,
          67.99379652350503,
          30.547305657089346,
          181.44652366173366,
          42.60874334162199,
          143.3687331073626,
          52.989323571546244,
          42.75217241031144,
          67.22398658375167,
          38.19008816984444,
          133.9714221497263,
          49.97674883522252,
          25.360155593261197,
          179.40551460831963,
          29.727357909105912,
          63.98437076866623,
          189.35480142366856,
          79.81261641489745,
          18.34697745729066,
          184.18884033999205,
          82.15967012866416,
          36.42771223938986,
          36.297939059392185,
          150.93189117657437,
          107.65740786976333,
          72.34910603426968,
          162.47055720711384,
          144.71168142313675,
          19.858872949477135,
          46.34071735350467,
          16.677867461362602,
          126.92773042879112,
          6.663049481756344,
          73.90349108280206,
          137.78441893266242,
          166.386898050925,
          36.0994749457123,
          149.91569466231817,
          18.158528315724183,
          171.01129924614665,
          31.83424882455103,
          61.81791377443177,
          149.5676627268412,
          15.180412880966468,
          32.470657013893224,
          120.29327247001687,
          112.36480978845907,
          107.95166305059426,
          94.11304591396879,
          85.41182759266724,
          28.98706589388613,
          42.86137540416283,
          27.395363157906758,
          193.23323978081052,
          85.75259336929335,
          47.48172520395345,
          44.30537235591635,
          195.36090121472097,
          11.122692056968349,
          88.933993046155,
          60.90562140543078,
          96.34028074879028,
          -0.37619647640851117,
          152.9236075294094,
          196.1118542067421,
          63.91171707475114,
          101.19673611100411,
          171.00406739484436,
          131.7994515004892,
          24.585139151438785,
          79.87050144724206,
          83.8093501128804,
          45.77632384190158,
          132.77171519789297,
          190.03213698617697,
          178.1543449282159,
          43.005974870625614,
          3.162792861666844,
          209.38643956609116,
          166.55811622431952,
          11.630739716867023,
          172.5222883797162,
          152.72026293675438,
          79.53879191472711,
          77.17214488981404,
          56.47765724583551,
          18.549199648518496,
          33.40317328681002,
          136.85735085588007,
          4.3463514280664395,
          41.746169332841696,
          56.99153147714233,
          74.57948781948774,
          182.15125047127628,
          23.193089711084838,
          54.294798048983715,
          131.8357636708743,
          47.76593021794942,
          41.88723542240339,
          56.95180752767193,
          21.596769666992653,
          27.764454216468234,
          72.86362336079335,
          51.118729097955836,
          172.9988920316713,
          38.99161249569756,
          92.09697405780877,
          85.49569809295166,
          9.173235972878576,
          100.44526656002245,
          20.645746224913548,
          199.04707449194407,
          32.8651188243444,
          39.493580881305334,
          5.921748647097772,
          204.68994118239561,
          75.50139180866842,
          89.31647595461381,
          9.965634167435788,
          137.66186064438233,
          39.552478518523536,
          190.38024023981527,
          35.244200466876194,
          18.257464410230384,
          24.59971826098055,
          55.195922741644125,
          90.64988093105733,
          25.866068794091774,
          142.24269550110287,
          56.99858276988888,
          61.695265966865,
          54.12151846567838,
          62.9157874050696,
          91.806933508875,
          6.988101420269633,
          9.957629997328304,
          155.0527492839908,
          202.54927059946888,
          51.707379616524875,
          21.934397528291594,
          94.87734903779062,
          59.376673257127955,
          23.006151353832838,
          21.3675969588826,
          122.32213896954615,
          101.35736332977149,
          11.45639614985998,
          24.756116059118003,
          31.214946106150794,
          117.331293259985,
          18.81606571519649,
          24.884876314590613,
          133.53174813797494,
          22.94817185562747,
          83.86812084133102,
          17.0029995582714,
          27.553344251065337,
          45.87625012092959,
          104.9847754045019,
          161.27271329240145,
          161.89660756510565,
          37.913393575462706,
          106.15219957220904,
          30.31475622480672,
          33.315318851962424,
          165.69299547694817,
          9.908836863775845,
          24.051014684048642,
          25.271616970489198,
          -1.8702528204507116,
          31.50641852368202,
          70.64556696175298,
          55.466841356722725,
          166.8420775999921,
          165.32132582337456,
          35.935809497657715,
          24.932250333783795,
          34.09402502019516,
          80.44745147485142,
          39.431677397761526,
          110.35747531375536,
          46.389501921778105,
          72.41643546788298,
          58.24850122209878,
          46.3359663791724,
          196.28728896087048,
          132.20219226054715,
          22.57155700353868,
          170.0363002104919,
          42.86589203458309,
          178.70498101544885,
          141.96695460815334,
          58.71743050915286,
          5.422112642841878,
          28.925053254098337,
          73.62907264851658,
          97.37834290222392,
          18.422091546185307,
          25.367458068785034,
          154.82788905641945,
          208.34343342702763,
          73.26913010076194,
          25.517589673468024,
          39.490169248448524,
          9.29921816910487,
          188.76487667278852,
          18.34982024757698,
          66.19387592503455,
          15.34848072914298,
          74.64164947709935,
          106.12755731365911,
          160.75314685352197,
          32.5353537023991,
          14.648251523375437,
          19.819366778726362,
          167.42621573165417,
          165.34730342221008,
          86.3969366852995,
          73.21253506735756,
          94.80106467031928,
          21.955731678114184,
          187.4488034861575,
          70.90482872584373,
          60.2010267764959,
          68.55158190397795,
          11.365614113742396,
          25.577938835303293,
          134.49524786075153,
          6.37773417939664,
          84.8723143947178,
          38.13506701805341,
          42.56526713486541,
          33.40380449234851,
          37.17287476026541,
          109.53847050669285,
          27.87670848082718,
          74.94763183642698,
          50.11649124387843,
          88.92792725532922,
          200.35691882184716,
          119.14855575635524,
          26.133378994722232,
          11.291349631866993,
          44.686373164985646,
          83.24246272761044,
          12.052680414170167,
          76.20293147525699,
          94.8756515544061,
          29.124525865721157,
          142.26417559494635,
          16.188924884857013,
          15.593638896113658,
          112.61476256509492,
          51.69416917555653,
          114.14816131518812,
          51.63466979221311,
          24.793201542626452,
          153.96744220488443,
          151.1371489231789,
          101.30529927138679,
          37.396995968158826,
          74.01370339703952,
          45.061510965356135,
          20.090348081739446,
          200.27306328719789,
          10.197525111000171,
          178.21075744031262,
          44.47098320445894
         ]
        }
       ],
       "layout": {
        "autosize": false,
        "height": 600,
        "margin": {
         "b": 65,
         "l": 65,
         "r": 50,
         "t": 90
        },
        "scene": {
         "xaxis": {
          "title": {
           "text": "Feature 1"
          }
         },
         "yaxis": {
          "title": {
           "text": "Feature 2"
          }
         },
         "zaxis": {
          "title": {
           "text": "Target"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Non-linear Synthetic Dataset with 2 Inputs and 1 Output"
        },
        "width": 800
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1, x2, y = generate_data(1000)\n",
    "fig = plot_data(x1, x2, y)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Normalization***(Terminology) is a step in preparing data for machine learning that makes all the data similar in scale. This is important because:\n",
    "\n",
    "- Helps Learn Faster: It makes the machine learning model learn and make predictions faster.\n",
    "- Fair Treatment: Ensures every piece of data is treated equally by the model, so no single type of data overpowers others.\n",
    "- Better Predictions: Leads to more accurate and stable predictions from the model.\n",
    "- Works Well with Many Models: Some machine learning models need data to be normalized to work correctly.\n",
    "- Avoids Problems: Prevents issues that can happen when data is in very different scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X1 = scaler.fit_transform(x1.reshape(-1, 1)).flatten()\n",
    "X2 = scaler.fit_transform(x2.reshape(-1, 1)).flatten()\n",
    "\n",
    "X = np.array([X1, X2]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37173493, 0.18260941],\n",
       "       [0.95075462, 0.54073995],\n",
       "       [0.73095408, 0.87304912],\n",
       "       ...,\n",
       "       [0.13283943, 0.06599082],\n",
       "       [0.95027532, 0.05404206],\n",
       "       [0.44355353, 0.28003421]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets manually initialize the weights and bias\n",
    "weights = np.array([-0.2, 0.4])\n",
    "bias = np.array([0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error(Loss):  [606.65951257]\n",
      "Updated weights and bias:  [-0.08425026  0.71344   ] [0.9666839]\n"
     ]
    }
   ],
   "source": [
    "# Start with a single example\n",
    "x_input = X[900]\n",
    "actual = y[900]\n",
    "\n",
    "output = forward(x_input, weights, bias)\n",
    "loss = loss_function(output, actual)\n",
    "print(\"Error(Loss): \", loss)\n",
    "weights, bias = backward(x_input, weights, bias, output, actual, learning_rate=0.1)\n",
    "print(\"Updated weights and bias: \", weights, bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Epoch loss: [10022.72649758]\n"
     ]
    }
   ],
   "source": [
    "epoch_loss = 0\n",
    "for iteration, (x_input,actual) in enumerate(zip(X, y)):\n",
    "    output = forward(x_input, weights, bias)\n",
    "    loss = loss_function(output, actual)\n",
    "    weights, bias = backward(x_input, weights, bias, output, actual, learning_rate=0.1)\n",
    "\n",
    "    epoch_loss += loss\n",
    "\n",
    "epoch_loss = epoch_loss / len(X)\n",
    "print(\"First Epoch loss:\", epoch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 0 10023.517666565402\n",
      "Epoch loss: 1 10022.709938004873\n",
      "Epoch loss: 2 10022.67171622697\n",
      "Epoch loss: 3 10022.655868239188\n",
      "Epoch loss: 4 10022.647112818275\n",
      "Epoch loss: 5 10022.641540692855\n",
      "Epoch loss: 6 10022.637676454788\n",
      "Epoch loss: 7 10022.634836445844\n",
      "Epoch loss: 8 10022.632659687835\n",
      "Epoch loss: 9 10022.630937333246\n",
      "Epoch loss: 10 10022.629540056389\n",
      "Epoch loss: 11 10022.62838344643\n",
      "Epoch loss: 12 10022.627410042829\n",
      "Epoch loss: 13 10022.626579361757\n",
      "Epoch loss: 14 10022.625862050414\n",
      "Epoch loss: 15 10022.625236303169\n",
      "Epoch loss: 16 10022.62468557953\n",
      "Epoch loss: 17 10022.624197103794\n",
      "Epoch loss: 18 10022.623760850329\n",
      "Epoch loss: 19 10022.623368840623\n",
      "Epoch loss: 20 10022.62301464556\n",
      "Epoch loss: 21 10022.62269302635\n",
      "Epoch loss: 22 10022.622399670807\n",
      "Epoch loss: 23 10022.622130997188\n",
      "Epoch loss: 24 10022.621884005355\n",
      "Epoch loss: 25 10022.621656163365\n",
      "Epoch loss: 26 10022.62144531951\n",
      "Epoch loss: 27 10022.621249633286\n",
      "Epoch loss: 28 10022.621067521162\n",
      "Epoch loss: 29 10022.620897613158\n",
      "Epoch loss: 30 10022.620738717955\n",
      "Epoch loss: 31 10022.62058979472\n",
      "Epoch loss: 32 10022.620449929958\n",
      "Epoch loss: 33 10022.620318318655\n",
      "Epoch loss: 34 10022.620194248628\n",
      "Epoch loss: 35 10022.620077087542\n",
      "Epoch loss: 36 10022.619966271843\n",
      "Epoch loss: 37 10022.619861297837\n",
      "Epoch loss: 38 10022.619761713808\n",
      "Epoch loss: 39 10022.619667113575\n",
      "Epoch loss: 40 10022.619577130858\n",
      "Epoch loss: 41 10022.619491434394\n",
      "Epoch loss: 42 10022.619409724011\n",
      "Epoch loss: 43 10022.6193317269\n",
      "Epoch loss: 44 10022.619257194681\n",
      "Epoch loss: 45 10022.619185900709\n",
      "Epoch loss: 46 10022.61911763766\n",
      "Epoch loss: 47 10022.619052215558\n",
      "Epoch loss: 48 10022.618989460136\n",
      "Epoch loss: 49 10022.618929210948\n",
      "Epoch loss: 50 10022.618871320288\n",
      "Epoch loss: 51 10022.618815651871\n",
      "Epoch loss: 52 10022.618762079654\n",
      "Epoch loss: 53 10022.618710487064\n",
      "Epoch loss: 54 10022.61866076591\n",
      "Epoch loss: 55 10022.618612815837\n",
      "Epoch loss: 56 10022.618566543604\n",
      "Epoch loss: 57 10022.618521862274\n",
      "Epoch loss: 58 10022.618478690943\n",
      "Epoch loss: 59 10022.618436954055\n",
      "Epoch loss: 60 10022.618396581023\n",
      "Epoch loss: 61 10022.618357505857\n",
      "Epoch loss: 62 10022.61831966671\n",
      "Epoch loss: 63 10022.618283005679\n",
      "Epoch loss: 64 10022.61824746838\n",
      "Epoch loss: 65 10022.618213003756\n",
      "Epoch loss: 66 10022.618179563768\n",
      "Epoch loss: 67 10022.618147103247\n",
      "Epoch loss: 68 10022.618115579631\n",
      "Epoch loss: 69 10022.618084952797\n",
      "Epoch loss: 70 10022.618055184854\n",
      "Epoch loss: 71 10022.618026240067\n",
      "Epoch loss: 72 10022.617998084637\n",
      "Epoch loss: 73 10022.617970686591\n",
      "Epoch loss: 74 10022.617944015681\n",
      "Epoch loss: 75 10022.617918043223\n",
      "Epoch loss: 76 10022.617892742046\n",
      "Epoch loss: 77 10022.617868086336\n",
      "Epoch loss: 78 10022.617844051683\n",
      "Epoch loss: 79 10022.617820614762\n",
      "Epoch loss: 80 10022.617797753512\n",
      "Epoch loss: 81 10022.61777544688\n",
      "Epoch loss: 82 10022.617753674895\n",
      "Epoch loss: 83 10022.617732418485\n",
      "Epoch loss: 84 10022.617711659448\n",
      "Epoch loss: 85 10022.617691380481\n",
      "Epoch loss: 86 10022.617671565113\n",
      "Epoch loss: 87 10022.617652197487\n",
      "Epoch loss: 88 10022.617633262618\n",
      "Epoch loss: 89 10022.617614746101\n",
      "Epoch loss: 90 10022.617596634136\n",
      "Epoch loss: 91 10022.617578913583\n",
      "Epoch loss: 92 10022.617561571864\n",
      "Epoch loss: 93 10022.617544596891\n",
      "Epoch loss: 94 10022.617527977118\n",
      "Epoch loss: 95 10022.61751170146\n",
      "Epoch loss: 96 10022.61749575933\n",
      "Epoch loss: 97 10022.617480140538\n",
      "Epoch loss: 98 10022.617464835299\n",
      "Epoch loss: 99 10022.617449834253\n"
     ]
    }
   ],
   "source": [
    "weights = np.array([-0.2, 0.4])\n",
    "bias = np.array([0.4])\n",
    "epoch_losses = []\n",
    "for epoch in range(100): # This is the number of times we iterate through the entire dataset\n",
    "\n",
    "    epoch_loss = 0\n",
    "    for iteration, (x_input, actual) in enumerate(zip(X, y)):\n",
    "        output = forward(x_input, weights, bias)\n",
    "        loss = loss_function(output, actual)\n",
    "        weights, bias = backward(x_input, weights, bias, output, actual, learning_rate=0.01)\n",
    "\n",
    "        # print(\"Previous output:\", output, \"Previous loss:\", loss)\n",
    "        # print(\"Updated output:\", updated_output, \"Updated loss:\", updated_loss)\n",
    "        epoch_loss += loss\n",
    "\n",
    "    epoch_loss = epoch_loss / len(X)\n",
    "    epoch_losses.append(epoch_loss)\n",
    "    print(f\"Epoch loss: {epoch}\", epoch_loss[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same data with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\sgnka\\anaconda3\\envs\\onnx\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\sgnka\\anaconda3\\envs\\onnx\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3 (12.00 Byte)\n",
      "Trainable params: 3 (12.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From c:\\Users\\sgnka\\anaconda3\\envs\\onnx\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers.experimental import SGD\n",
    "\n",
    "\n",
    "np.random.seed(402)\n",
    "tf.random.set_seed(42)\n",
    "weights = np.array([-0.2, 0.4])\n",
    "bias = np.array([0.4])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=402)\n",
    "\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid', input_shape=(2,),\n",
    "                          kernel_initializer=tf.keras.initializers.Constant(weights),\n",
    "                          bias_initializer=tf.keras.initializers.Constant(bias))\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='SGD', loss='mse')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Parameters\n",
    "- Resnet50 -> 25M\n",
    "\n",
    "- gpt-4 -> 1.76 trillion parameters\n",
    "\n",
    "- llama2 -> 7B, 13B, 70B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\sgnka\\anaconda3\\envs\\onnx\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "113/800 [===>..........................] - ETA: 0s - loss: 11818.6436"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 1s 1ms/step - loss: 10485.1143 - val_loss: 8175.1963\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 10484.5557 - val_loss: 8175.1562\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 10484.5303 - val_loss: 8175.1436\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 10484.5166 - val_loss: 8175.1362\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 10484.5137 - val_loss: 8175.1299\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 10484.5078 - val_loss: 8175.1289\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 10484.4990 - val_loss: 8175.1250\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 10484.5039 - val_loss: 8175.1235\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 10484.5107 - val_loss: 8175.1230\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 10484.5010 - val_loss: 8175.1211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x158b4987d90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=1, validation_data=(X_test, y_test), validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 6)                 18        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59 (236.00 Byte)\n",
      "Trainable params: 59 (236.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "20/20 [==============================] - 1s 8ms/step - loss: 10258.3682 - val_loss: 11900.0957\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 10221.9580 - val_loss: 11856.0977\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 10178.5918 - val_loss: 11802.4404\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 10126.4658 - val_loss: 11737.0850\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 10063.0859 - val_loss: 11661.3799\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9989.7744 - val_loss: 11573.1816\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9904.5605 - val_loss: 11470.0996\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9802.9668 - val_loss: 11347.2598\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9681.7959 - val_loss: 11198.5859\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9536.3262 - val_loss: 11025.4395\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 9367.9941 - val_loss: 10826.2480\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9177.7861 - val_loss: 10601.9844\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8965.7070 - val_loss: 10351.5410\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8729.5049 - val_loss: 10078.5996\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8475.4424 - val_loss: 9778.1602\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8196.3027 - val_loss: 9459.8193\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 7896.3643 - val_loss: 9125.7402\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 7588.7095 - val_loss: 8758.0303\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 7256.3765 - val_loss: 8380.6963\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6912.2944 - val_loss: 7991.9312\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6562.3516 - val_loss: 7585.2139\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6197.5239 - val_loss: 7178.2485\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5837.7100 - val_loss: 6752.0234\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5468.6689 - val_loss: 6327.4717\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5098.4180 - val_loss: 5910.1084\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4744.2588 - val_loss: 5485.6895\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4382.5752 - val_loss: 5096.8013\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4053.2097 - val_loss: 4711.6880\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3746.4141 - val_loss: 4339.3579\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3455.7273 - val_loss: 4008.1313\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3204.4004 - val_loss: 3703.8843\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2974.2910 - val_loss: 3446.4407\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2784.8667 - val_loss: 3217.3679\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2622.7134 - val_loss: 3019.9382\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 2486.9089 - val_loss: 2857.5168\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2382.1345 - val_loss: 2714.5981\n",
      "Epoch 37/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2293.1743 - val_loss: 2601.7048\n",
      "Epoch 38/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2224.4976 - val_loss: 2509.2759\n",
      "Epoch 39/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2169.1880 - val_loss: 2437.2605\n",
      "Epoch 40/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2129.0229 - val_loss: 2368.1851\n",
      "Epoch 41/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2092.7153 - val_loss: 2314.0364\n",
      "Epoch 42/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2062.6958 - val_loss: 2272.5125\n",
      "Epoch 43/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2040.1670 - val_loss: 2229.6497\n",
      "Epoch 44/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2016.5618 - val_loss: 2196.5601\n",
      "Epoch 45/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1996.9078 - val_loss: 2164.8809\n",
      "Epoch 46/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1976.4268 - val_loss: 2140.3308\n",
      "Epoch 47/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1957.7781 - val_loss: 2116.9829\n",
      "Epoch 48/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1940.2666 - val_loss: 2087.0933\n",
      "Epoch 49/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1920.9449 - val_loss: 2067.0913\n",
      "Epoch 50/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1902.5457 - val_loss: 2039.6715\n",
      "Epoch 51/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1883.6487 - val_loss: 2016.9221\n",
      "Epoch 52/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1864.6809 - val_loss: 1995.8455\n",
      "Epoch 53/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1846.0385 - val_loss: 1975.6628\n",
      "Epoch 54/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1826.4812 - val_loss: 1953.6793\n",
      "Epoch 55/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1807.1426 - val_loss: 1929.3196\n",
      "Epoch 56/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1787.5957 - val_loss: 1905.1204\n",
      "Epoch 57/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1767.7371 - val_loss: 1882.7683\n",
      "Epoch 58/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1747.7760 - val_loss: 1859.3239\n",
      "Epoch 59/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1727.3043 - val_loss: 1839.2067\n",
      "Epoch 60/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1707.3828 - val_loss: 1816.5332\n",
      "Epoch 61/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1686.0680 - val_loss: 1791.6420\n",
      "Epoch 62/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1665.0873 - val_loss: 1767.3512\n",
      "Epoch 63/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1644.0225 - val_loss: 1743.2064\n",
      "Epoch 64/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1622.4285 - val_loss: 1719.5212\n",
      "Epoch 65/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1600.8870 - val_loss: 1696.0883\n",
      "Epoch 66/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1578.9730 - val_loss: 1671.0056\n",
      "Epoch 67/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1557.0276 - val_loss: 1646.0381\n",
      "Epoch 68/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1534.5333 - val_loss: 1620.9362\n",
      "Epoch 69/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1512.3657 - val_loss: 1598.9264\n",
      "Epoch 70/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1489.3882 - val_loss: 1572.1504\n",
      "Epoch 71/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1466.2775 - val_loss: 1546.4738\n",
      "Epoch 72/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1443.2660 - val_loss: 1521.7578\n",
      "Epoch 73/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1420.1296 - val_loss: 1494.6647\n",
      "Epoch 74/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1396.6873 - val_loss: 1467.9622\n",
      "Epoch 75/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1373.7609 - val_loss: 1439.9559\n",
      "Epoch 76/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1349.1245 - val_loss: 1416.8788\n",
      "Epoch 77/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1325.7471 - val_loss: 1389.6898\n",
      "Epoch 78/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1301.7581 - val_loss: 1365.1360\n",
      "Epoch 79/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1278.3356 - val_loss: 1336.7537\n",
      "Epoch 80/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1254.4720 - val_loss: 1310.0895\n",
      "Epoch 81/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1230.4642 - val_loss: 1287.9430\n",
      "Epoch 82/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1206.5779 - val_loss: 1261.5647\n",
      "Epoch 83/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1183.3518 - val_loss: 1234.0651\n",
      "Epoch 84/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1159.6709 - val_loss: 1210.7731\n",
      "Epoch 85/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1137.1654 - val_loss: 1181.1204\n",
      "Epoch 86/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1112.9646 - val_loss: 1158.7354\n",
      "Epoch 87/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1090.1000 - val_loss: 1134.7738\n",
      "Epoch 88/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1067.3650 - val_loss: 1110.9254\n",
      "Epoch 89/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1044.4827 - val_loss: 1085.1792\n",
      "Epoch 90/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1022.0189 - val_loss: 1059.9509\n",
      "Epoch 91/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 999.5699 - val_loss: 1035.7838\n",
      "Epoch 92/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 977.6927 - val_loss: 1012.1621\n",
      "Epoch 93/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 955.7333 - val_loss: 985.1458\n",
      "Epoch 94/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 933.9167 - val_loss: 961.2687\n",
      "Epoch 95/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 912.0599 - val_loss: 939.9147\n",
      "Epoch 96/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 890.5649 - val_loss: 917.3353\n",
      "Epoch 97/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 869.4509 - val_loss: 894.4456\n",
      "Epoch 98/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 848.7094 - val_loss: 870.9122\n",
      "Epoch 99/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 828.0392 - val_loss: 850.4791\n",
      "Epoch 100/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 807.2512 - val_loss: 827.8063\n",
      "Epoch 101/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 787.1410 - val_loss: 805.0760\n",
      "Epoch 102/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 767.0900 - val_loss: 782.3732\n",
      "Epoch 103/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 746.9349 - val_loss: 763.0465\n",
      "Epoch 104/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 727.7344 - val_loss: 740.0425\n",
      "Epoch 105/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 708.2152 - val_loss: 721.8158\n",
      "Epoch 106/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 688.5386 - val_loss: 700.9319\n",
      "Epoch 107/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 667.5415 - val_loss: 676.7777\n",
      "Epoch 108/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 647.4033 - val_loss: 653.0199\n",
      "Epoch 109/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 626.5822 - val_loss: 633.2471\n",
      "Epoch 110/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 606.0734 - val_loss: 612.0988\n",
      "Epoch 111/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 586.7957 - val_loss: 593.5647\n",
      "Epoch 112/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 567.8412 - val_loss: 569.9761\n",
      "Epoch 113/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 549.0288 - val_loss: 551.0957\n",
      "Epoch 114/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 530.9996 - val_loss: 531.8127\n",
      "Epoch 115/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 513.6979 - val_loss: 515.4207\n",
      "Epoch 116/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 496.6244 - val_loss: 497.5522\n",
      "Epoch 117/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 479.8969 - val_loss: 480.2807\n",
      "Epoch 118/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 464.3683 - val_loss: 461.3416\n",
      "Epoch 119/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 448.6823 - val_loss: 447.1113\n",
      "Epoch 120/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 433.8954 - val_loss: 430.4747\n",
      "Epoch 121/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 419.2745 - val_loss: 417.0790\n",
      "Epoch 122/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 405.7858 - val_loss: 402.8339\n",
      "Epoch 123/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 392.9008 - val_loss: 388.2090\n",
      "Epoch 124/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 379.2046 - val_loss: 375.5201\n",
      "Epoch 125/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 366.9685 - val_loss: 362.2894\n",
      "Epoch 126/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 355.3111 - val_loss: 350.2679\n",
      "Epoch 127/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 343.7737 - val_loss: 338.1978\n",
      "Epoch 128/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 333.0358 - val_loss: 328.3037\n",
      "Epoch 129/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 322.9208 - val_loss: 315.5338\n",
      "Epoch 130/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 312.5496 - val_loss: 306.4153\n",
      "Epoch 131/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 303.0260 - val_loss: 297.7985\n",
      "Epoch 132/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 293.9994 - val_loss: 286.9830\n",
      "Epoch 133/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 285.3113 - val_loss: 277.4949\n",
      "Epoch 134/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 276.7176 - val_loss: 269.8559\n",
      "Epoch 135/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 268.9216 - val_loss: 261.0550\n",
      "Epoch 136/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 260.8224 - val_loss: 254.1061\n",
      "Epoch 137/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 253.7628 - val_loss: 247.2686\n",
      "Epoch 138/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 246.4259 - val_loss: 239.4905\n",
      "Epoch 139/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 239.9008 - val_loss: 232.2257\n",
      "Epoch 140/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 233.2718 - val_loss: 225.6897\n",
      "Epoch 141/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 227.1679 - val_loss: 220.7078\n",
      "Epoch 142/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 221.0076 - val_loss: 214.4797\n",
      "Epoch 143/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 215.4227 - val_loss: 207.7157\n",
      "Epoch 144/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 209.7690 - val_loss: 203.2651\n",
      "Epoch 145/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 204.2703 - val_loss: 197.2463\n",
      "Epoch 146/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 199.0830 - val_loss: 192.0334\n",
      "Epoch 147/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 194.1423 - val_loss: 187.8542\n",
      "Epoch 148/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 189.1929 - val_loss: 182.5840\n",
      "Epoch 149/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 184.5932 - val_loss: 178.2890\n",
      "Epoch 150/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 179.9767 - val_loss: 174.1745\n",
      "Epoch 151/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 175.8560 - val_loss: 169.9260\n",
      "Epoch 152/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 171.2759 - val_loss: 166.8079\n",
      "Epoch 153/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 167.7556 - val_loss: 161.7122\n",
      "Epoch 154/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 163.3244 - val_loss: 158.1590\n",
      "Epoch 155/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 159.5511 - val_loss: 155.8420\n",
      "Epoch 156/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 155.9667 - val_loss: 151.1153\n",
      "Epoch 157/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 152.1310 - val_loss: 148.0693\n",
      "Epoch 158/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 148.9875 - val_loss: 145.6979\n",
      "Epoch 159/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 145.3148 - val_loss: 142.2568\n",
      "Epoch 160/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 142.3299 - val_loss: 138.0566\n",
      "Epoch 161/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 138.9885 - val_loss: 135.6913\n",
      "Epoch 162/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 136.0451 - val_loss: 133.5711\n",
      "Epoch 163/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 133.1532 - val_loss: 130.1869\n",
      "Epoch 164/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 130.3172 - val_loss: 127.2513\n",
      "Epoch 165/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 127.5369 - val_loss: 125.6416\n",
      "Epoch 166/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 124.8128 - val_loss: 122.9176\n",
      "Epoch 167/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 122.1553 - val_loss: 120.3458\n",
      "Epoch 168/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 119.9211 - val_loss: 117.3560\n",
      "Epoch 169/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 117.0423 - val_loss: 115.6225\n",
      "Epoch 170/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 114.7118 - val_loss: 113.3680\n",
      "Epoch 171/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 112.2900 - val_loss: 111.7154\n",
      "Epoch 172/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 109.9820 - val_loss: 109.2787\n",
      "Epoch 173/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 107.6888 - val_loss: 106.8704\n",
      "Epoch 174/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 105.6314 - val_loss: 105.6997\n",
      "Epoch 175/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 102.9612 - val_loss: 102.8485\n",
      "Epoch 176/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 101.0799 - val_loss: 101.1675\n",
      "Epoch 177/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 98.6728 - val_loss: 98.9332\n",
      "Epoch 178/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 96.5318 - val_loss: 97.2232\n",
      "Epoch 179/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 94.5134 - val_loss: 95.6989\n",
      "Epoch 180/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 92.8559 - val_loss: 93.0434\n",
      "Epoch 181/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 90.2799 - val_loss: 91.7763\n",
      "Epoch 182/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 88.5433 - val_loss: 89.4319\n",
      "Epoch 183/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 86.3163 - val_loss: 88.1161\n",
      "Epoch 184/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 84.4365 - val_loss: 85.9392\n",
      "Epoch 185/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 82.4830 - val_loss: 84.3356\n",
      "Epoch 186/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 80.9281 - val_loss: 82.1108\n",
      "Epoch 187/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 78.7259 - val_loss: 81.2074\n",
      "Epoch 188/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 76.9487 - val_loss: 79.1881\n",
      "Epoch 189/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 75.1460 - val_loss: 77.0670\n",
      "Epoch 190/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 73.3521 - val_loss: 75.7791\n",
      "Epoch 191/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 71.5504 - val_loss: 73.8863\n",
      "Epoch 192/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 69.9011 - val_loss: 72.2356\n",
      "Epoch 193/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 68.2631 - val_loss: 71.0924\n",
      "Epoch 194/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 66.6567 - val_loss: 68.9819\n",
      "Epoch 195/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 64.9854 - val_loss: 67.5947\n",
      "Epoch 196/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 63.2218 - val_loss: 66.3253\n",
      "Epoch 197/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 61.6674 - val_loss: 64.8878\n",
      "Epoch 198/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 60.2488 - val_loss: 63.3302\n",
      "Epoch 199/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 58.6637 - val_loss: 62.0147\n",
      "Epoch 200/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 57.3401 - val_loss: 60.9507\n",
      "Epoch 201/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 55.7240 - val_loss: 58.9439\n",
      "Epoch 202/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 54.3624 - val_loss: 57.6771\n",
      "Epoch 203/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 52.9414 - val_loss: 56.5220\n",
      "Epoch 204/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 51.5266 - val_loss: 55.1970\n",
      "Epoch 205/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 50.2013 - val_loss: 53.9980\n",
      "Epoch 206/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 48.9978 - val_loss: 52.5377\n",
      "Epoch 207/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 47.6368 - val_loss: 51.3953\n",
      "Epoch 208/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 46.4057 - val_loss: 50.4365\n",
      "Epoch 209/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 45.1505 - val_loss: 48.9877\n",
      "Epoch 210/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 44.0057 - val_loss: 47.8213\n",
      "Epoch 211/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 42.8380 - val_loss: 46.7749\n",
      "Epoch 212/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 41.7651 - val_loss: 45.8930\n",
      "Epoch 213/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 40.6919 - val_loss: 44.4794\n",
      "Epoch 214/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 39.5991 - val_loss: 43.7239\n",
      "Epoch 215/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 38.5080 - val_loss: 42.6753\n",
      "Epoch 216/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 37.5196 - val_loss: 41.6471\n",
      "Epoch 217/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 36.5832 - val_loss: 40.6888\n",
      "Epoch 218/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 35.5961 - val_loss: 39.8054\n",
      "Epoch 219/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 34.6762 - val_loss: 38.9688\n",
      "Epoch 220/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 33.9997 - val_loss: 38.0172\n",
      "Epoch 221/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 32.9566 - val_loss: 37.1510\n",
      "Epoch 222/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 32.2079 - val_loss: 36.4650\n",
      "Epoch 223/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 31.3500 - val_loss: 35.6948\n",
      "Epoch 224/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.6237 - val_loss: 34.8724\n",
      "Epoch 225/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 29.8903 - val_loss: 34.1482\n",
      "Epoch 226/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 29.2438 - val_loss: 33.6334\n",
      "Epoch 227/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 28.6217 - val_loss: 32.6746\n",
      "Epoch 228/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 27.9788 - val_loss: 32.2383\n",
      "Epoch 229/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 27.2762 - val_loss: 31.4324\n",
      "Epoch 230/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 26.6879 - val_loss: 30.8715\n",
      "Epoch 231/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 26.1593 - val_loss: 30.3358\n",
      "Epoch 232/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 25.6137 - val_loss: 29.9087\n",
      "Epoch 233/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 24.9969 - val_loss: 29.1456\n",
      "Epoch 234/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 24.5554 - val_loss: 28.6729\n",
      "Epoch 235/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 24.0583 - val_loss: 28.1663\n",
      "Epoch 236/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 23.6571 - val_loss: 27.7691\n",
      "Epoch 237/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 23.1614 - val_loss: 27.2550\n",
      "Epoch 238/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 22.7205 - val_loss: 26.7592\n",
      "Epoch 239/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 22.4235 - val_loss: 26.4610\n",
      "Epoch 240/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 22.0169 - val_loss: 25.9650\n",
      "Epoch 241/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6865 - val_loss: 25.5963\n",
      "Epoch 242/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.3501 - val_loss: 25.1209\n",
      "Epoch 243/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 20.9176 - val_loss: 25.0185\n",
      "Epoch 244/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 20.6604 - val_loss: 24.3916\n",
      "Epoch 245/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 20.1771 - val_loss: 24.1191\n",
      "Epoch 246/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 19.9055 - val_loss: 23.7400\n",
      "Epoch 247/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 19.5892 - val_loss: 23.3669\n",
      "Epoch 248/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 19.4121 - val_loss: 23.1706\n",
      "Epoch 249/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 19.0790 - val_loss: 22.7381\n",
      "Epoch 250/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 18.7192 - val_loss: 22.5450\n",
      "Epoch 251/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 18.4957 - val_loss: 22.2123\n",
      "Epoch 252/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 18.2167 - val_loss: 21.9304\n",
      "Epoch 253/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 17.9535 - val_loss: 21.6140\n",
      "Epoch 254/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 17.8319 - val_loss: 21.3622\n",
      "Epoch 255/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 17.5276 - val_loss: 21.0778\n",
      "Epoch 256/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 17.2985 - val_loss: 20.8777\n",
      "Epoch 257/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 17.1195 - val_loss: 20.5429\n",
      "Epoch 258/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 16.8929 - val_loss: 20.3627\n",
      "Epoch 259/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 16.6455 - val_loss: 20.0603\n",
      "Epoch 260/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 16.4939 - val_loss: 19.8860\n",
      "Epoch 261/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 16.2375 - val_loss: 19.5826\n",
      "Epoch 262/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 16.0674 - val_loss: 19.3461\n",
      "Epoch 263/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.8846 - val_loss: 19.1590\n",
      "Epoch 264/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7549 - val_loss: 18.9953\n",
      "Epoch 265/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.5378 - val_loss: 18.7355\n",
      "Epoch 266/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.4410 - val_loss: 18.5491\n",
      "Epoch 267/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.2199 - val_loss: 18.3649\n",
      "Epoch 268/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.0885 - val_loss: 18.1000\n",
      "Epoch 269/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 14.9096 - val_loss: 17.9541\n",
      "Epoch 270/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 14.8036 - val_loss: 17.7326\n",
      "Epoch 271/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 14.6495 - val_loss: 17.5473\n",
      "Epoch 272/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 14.4923 - val_loss: 17.3868\n",
      "Epoch 273/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 14.3753 - val_loss: 17.2284\n",
      "Epoch 274/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 14.3723 - val_loss: 17.0322\n",
      "Epoch 275/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.0638 - val_loss: 16.9082\n",
      "Epoch 276/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 13.9944 - val_loss: 16.6771\n",
      "Epoch 277/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 13.9071 - val_loss: 16.5318\n",
      "Epoch 278/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 13.7633 - val_loss: 16.3462\n",
      "Epoch 279/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 13.5953 - val_loss: 16.1884\n",
      "Epoch 280/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 13.4608 - val_loss: 16.0278\n",
      "Epoch 281/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 13.3904 - val_loss: 15.8679\n",
      "Epoch 282/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 13.2302 - val_loss: 15.7163\n",
      "Epoch 283/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 13.1309 - val_loss: 15.5774\n",
      "Epoch 284/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 13.0072 - val_loss: 15.4280\n",
      "Epoch 285/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 12.9148 - val_loss: 15.2827\n",
      "Epoch 286/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 12.8110 - val_loss: 15.1423\n",
      "Epoch 287/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 12.7356 - val_loss: 15.0097\n",
      "Epoch 288/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 12.5886 - val_loss: 14.8759\n",
      "Epoch 289/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 12.5091 - val_loss: 14.7125\n",
      "Epoch 290/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 12.4069 - val_loss: 14.5789\n",
      "Epoch 291/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 12.3208 - val_loss: 14.4445\n",
      "Epoch 292/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 12.2080 - val_loss: 14.3223\n",
      "Epoch 293/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 12.1456 - val_loss: 14.1926\n",
      "Epoch 294/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 12.0091 - val_loss: 14.0374\n",
      "Epoch 295/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 11.9352 - val_loss: 13.9168\n",
      "Epoch 296/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 11.8273 - val_loss: 13.7666\n",
      "Epoch 297/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 11.7979 - val_loss: 13.6628\n",
      "Epoch 298/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 11.7213 - val_loss: 13.5095\n",
      "Epoch 299/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 11.6030 - val_loss: 13.4014\n",
      "Epoch 300/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 11.4839 - val_loss: 13.2498\n",
      "Epoch 301/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 11.3977 - val_loss: 13.1401\n",
      "Epoch 302/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 11.3139 - val_loss: 13.0479\n",
      "Epoch 303/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 11.2592 - val_loss: 12.8781\n",
      "Epoch 304/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 11.1099 - val_loss: 12.7748\n",
      "Epoch 305/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 11.0839 - val_loss: 12.6668\n",
      "Epoch 306/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 11.0086 - val_loss: 12.5309\n",
      "Epoch 307/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 10.9033 - val_loss: 12.4113\n",
      "Epoch 308/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 10.8735 - val_loss: 12.2963\n",
      "Epoch 309/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 10.7304 - val_loss: 12.2050\n",
      "Epoch 310/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 10.6846 - val_loss: 12.0496\n",
      "Epoch 311/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 10.5620 - val_loss: 11.9395\n",
      "Epoch 312/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 10.4863 - val_loss: 11.8165\n",
      "Epoch 313/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 10.5495 - val_loss: 11.7288\n",
      "Epoch 314/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 10.3406 - val_loss: 11.6053\n",
      "Epoch 315/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 10.3064 - val_loss: 11.4763\n",
      "Epoch 316/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 10.2118 - val_loss: 11.3503\n",
      "Epoch 317/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 10.1125 - val_loss: 11.2311\n",
      "Epoch 318/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 10.0560 - val_loss: 11.1614\n",
      "Epoch 319/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.9447 - val_loss: 11.0388\n",
      "Epoch 320/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.8784 - val_loss: 10.9149\n",
      "Epoch 321/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.8043 - val_loss: 10.8477\n",
      "Epoch 322/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 9.7167 - val_loss: 10.7051\n",
      "Epoch 323/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.6186 - val_loss: 10.5879\n",
      "Epoch 324/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.5677 - val_loss: 10.4627\n",
      "Epoch 325/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.4935 - val_loss: 10.3602\n",
      "Epoch 326/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.4495 - val_loss: 10.2553\n",
      "Epoch 327/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.3684 - val_loss: 10.1551\n",
      "Epoch 328/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.3147 - val_loss: 10.0561\n",
      "Epoch 329/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.2248 - val_loss: 9.9685\n",
      "Epoch 330/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.1867 - val_loss: 9.8991\n",
      "Epoch 331/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 9.0274 - val_loss: 9.7653\n",
      "Epoch 332/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.9941 - val_loss: 9.6502\n",
      "Epoch 333/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.9113 - val_loss: 9.5333\n",
      "Epoch 334/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.8612 - val_loss: 9.4345\n",
      "Epoch 335/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.7752 - val_loss: 9.3508\n",
      "Epoch 336/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.7300 - val_loss: 9.2422\n",
      "Epoch 337/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.6349 - val_loss: 9.1524\n",
      "Epoch 338/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.5625 - val_loss: 9.0369\n",
      "Epoch 339/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.4958 - val_loss: 8.9409\n",
      "Epoch 340/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.4337 - val_loss: 8.8469\n",
      "Epoch 341/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 8.3677 - val_loss: 8.7547\n",
      "Epoch 342/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.2956 - val_loss: 8.6510\n",
      "Epoch 343/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.2424 - val_loss: 8.5658\n",
      "Epoch 344/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.1784 - val_loss: 8.4508\n",
      "Epoch 345/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.0815 - val_loss: 8.3750\n",
      "Epoch 346/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 8.0029 - val_loss: 8.2767\n",
      "Epoch 347/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 7.9787 - val_loss: 8.2168\n",
      "Epoch 348/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 7.8791 - val_loss: 8.1505\n",
      "Epoch 349/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 7.8619 - val_loss: 8.0131\n",
      "Epoch 350/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 7.7621 - val_loss: 7.9538\n",
      "Epoch 351/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 7.7030 - val_loss: 7.8795\n",
      "Epoch 352/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 7.6161 - val_loss: 7.7864\n",
      "Epoch 353/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 7.5683 - val_loss: 7.7557\n",
      "Epoch 354/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 7.5552 - val_loss: 7.6616\n",
      "Epoch 355/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 7.4421 - val_loss: 7.5831\n",
      "Epoch 356/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 7.3430 - val_loss: 7.5239\n",
      "Epoch 357/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 7.3293 - val_loss: 7.4611\n",
      "Epoch 358/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 7.2407 - val_loss: 7.3649\n",
      "Epoch 359/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 7.1684 - val_loss: 7.3376\n",
      "Epoch 360/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 7.1373 - val_loss: 7.2434\n",
      "Epoch 361/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 7.0860 - val_loss: 7.2253\n",
      "Epoch 362/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 7.0481 - val_loss: 7.1145\n",
      "Epoch 363/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.9901 - val_loss: 7.0503\n",
      "Epoch 364/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.9269 - val_loss: 6.9925\n",
      "Epoch 365/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.8979 - val_loss: 6.9701\n",
      "Epoch 366/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.9030 - val_loss: 6.8942\n",
      "Epoch 367/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.7892 - val_loss: 6.9025\n",
      "Epoch 368/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.7559 - val_loss: 6.8042\n",
      "Epoch 369/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.7994 - val_loss: 6.8764\n",
      "Epoch 370/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.6819 - val_loss: 6.7227\n",
      "Epoch 371/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.6752 - val_loss: 6.7126\n",
      "Epoch 372/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.6943 - val_loss: 6.8004\n",
      "Epoch 373/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.5943 - val_loss: 6.7464\n",
      "Epoch 374/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.6410 - val_loss: 6.6352\n",
      "Epoch 375/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.5446 - val_loss: 6.5787\n",
      "Epoch 376/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.4908 - val_loss: 6.5428\n",
      "Epoch 377/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.4807 - val_loss: 6.5596\n",
      "Epoch 378/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.5451 - val_loss: 6.5451\n",
      "Epoch 379/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.5137 - val_loss: 6.5101\n",
      "Epoch 380/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.4896 - val_loss: 6.5615\n",
      "Epoch 381/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 6.4545 - val_loss: 6.4633\n",
      "Epoch 382/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.3860 - val_loss: 6.4547\n",
      "Epoch 383/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.3847 - val_loss: 6.4165\n",
      "Epoch 384/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.3625 - val_loss: 6.4028\n",
      "Epoch 385/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.3306 - val_loss: 6.3546\n",
      "Epoch 386/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.3913 - val_loss: 6.4607\n",
      "Epoch 387/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.3347 - val_loss: 6.3312\n",
      "Epoch 388/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.2830 - val_loss: 6.3367\n",
      "Epoch 389/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.3191 - val_loss: 6.3048\n",
      "Epoch 390/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.3425 - val_loss: 6.4499\n",
      "Epoch 391/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.3394 - val_loss: 6.3013\n",
      "Epoch 392/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.2579 - val_loss: 6.3170\n",
      "Epoch 393/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.2576 - val_loss: 6.2578\n",
      "Epoch 394/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.3121 - val_loss: 6.3923\n",
      "Epoch 395/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.3116 - val_loss: 6.2386\n",
      "Epoch 396/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.2621 - val_loss: 6.2249\n",
      "Epoch 397/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.2807 - val_loss: 6.2290\n",
      "Epoch 398/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.3114 - val_loss: 6.2406\n",
      "Epoch 399/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.2839 - val_loss: 6.2141\n",
      "Epoch 400/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.2361 - val_loss: 6.1933\n",
      "Epoch 401/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.2229 - val_loss: 6.1678\n",
      "Epoch 402/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.2326 - val_loss: 6.1874\n",
      "Epoch 403/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.2534 - val_loss: 6.2411\n",
      "Epoch 404/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1987 - val_loss: 6.1521\n",
      "Epoch 405/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.2558 - val_loss: 6.1682\n",
      "Epoch 406/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.3144 - val_loss: 6.2078\n",
      "Epoch 407/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.2084 - val_loss: 6.1565\n",
      "Epoch 408/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1992 - val_loss: 6.1279\n",
      "Epoch 409/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.2140 - val_loss: 6.1758\n",
      "Epoch 410/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1726 - val_loss: 6.1275\n",
      "Epoch 411/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1881 - val_loss: 6.1111\n",
      "Epoch 412/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1795 - val_loss: 6.1136\n",
      "Epoch 413/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1933 - val_loss: 6.1604\n",
      "Epoch 414/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.2096 - val_loss: 6.1260\n",
      "Epoch 415/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.2044 - val_loss: 6.1054\n",
      "Epoch 416/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 6.2029 - val_loss: 6.2572\n",
      "Epoch 417/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.3924 - val_loss: 6.1250\n",
      "Epoch 418/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.2233 - val_loss: 6.1030\n",
      "Epoch 419/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.2341 - val_loss: 6.0986\n",
      "Epoch 420/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.2129 - val_loss: 6.2286\n",
      "Epoch 421/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1811 - val_loss: 6.1238\n",
      "Epoch 422/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1830 - val_loss: 6.0768\n",
      "Epoch 423/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.2340 - val_loss: 6.3066\n",
      "Epoch 424/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.2926 - val_loss: 6.1898\n",
      "Epoch 425/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1222 - val_loss: 6.1114\n",
      "Epoch 426/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1703 - val_loss: 6.1246\n",
      "Epoch 427/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.2055 - val_loss: 6.1016\n",
      "Epoch 428/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1490 - val_loss: 6.1549\n",
      "Epoch 429/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1421 - val_loss: 6.0993\n",
      "Epoch 430/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1907 - val_loss: 6.1116\n",
      "Epoch 431/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.2070 - val_loss: 6.1446\n",
      "Epoch 432/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 6.1465 - val_loss: 6.2154\n",
      "Epoch 433/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 6.1673 - val_loss: 6.1028\n",
      "Epoch 434/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 6.1352 - val_loss: 6.0735\n",
      "Epoch 435/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 6.1206 - val_loss: 6.0832\n",
      "Epoch 436/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1331 - val_loss: 6.0674\n",
      "Epoch 437/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 6.1261 - val_loss: 6.1139\n",
      "Epoch 438/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 6.1902 - val_loss: 6.0782\n",
      "Epoch 439/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1137 - val_loss: 6.0752\n",
      "Epoch 440/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 6.1285 - val_loss: 6.1517\n",
      "Epoch 441/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1238 - val_loss: 6.0950\n",
      "Epoch 442/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1177 - val_loss: 6.0969\n",
      "Epoch 443/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1275 - val_loss: 6.0959\n",
      "Epoch 444/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1000 - val_loss: 6.0809\n",
      "Epoch 445/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.2255 - val_loss: 6.2982\n",
      "Epoch 446/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1191 - val_loss: 6.5618\n",
      "Epoch 447/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.4561 - val_loss: 6.0938\n",
      "Epoch 448/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1830 - val_loss: 6.1140\n",
      "Epoch 449/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1186 - val_loss: 6.0738\n",
      "Epoch 450/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.0930 - val_loss: 6.0949\n",
      "Epoch 451/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 6.1124 - val_loss: 6.0729\n",
      "Epoch 452/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 6.0865 - val_loss: 6.0900\n",
      "Epoch 453/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1550 - val_loss: 6.1205\n",
      "Epoch 454/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1227 - val_loss: 6.0595\n",
      "Epoch 455/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.0882 - val_loss: 6.1864\n",
      "Epoch 456/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.0837 - val_loss: 6.1248\n",
      "Epoch 457/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1314 - val_loss: 6.0600\n",
      "Epoch 458/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.0963 - val_loss: 6.0842\n",
      "Epoch 459/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1071 - val_loss: 6.0915\n",
      "Epoch 460/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1029 - val_loss: 6.0799\n",
      "Epoch 461/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1021 - val_loss: 6.1390\n",
      "Epoch 462/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1077 - val_loss: 6.0787\n",
      "Epoch 463/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 6.0629 - val_loss: 6.0849\n",
      "Epoch 464/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.0635 - val_loss: 6.1513\n",
      "Epoch 465/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.0923 - val_loss: 6.1049\n",
      "Epoch 466/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.0622 - val_loss: 6.0796\n",
      "Epoch 467/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.0866 - val_loss: 6.0936\n",
      "Epoch 468/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.0781 - val_loss: 6.1132\n",
      "Epoch 469/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.0771 - val_loss: 6.1334\n",
      "Epoch 470/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 6.2912 - val_loss: 6.3053\n",
      "Epoch 471/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1030 - val_loss: 6.1535\n",
      "Epoch 472/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.2259 - val_loss: 6.1366\n",
      "Epoch 473/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 6.1658 - val_loss: 6.0937\n",
      "Epoch 474/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 6.0223 - val_loss: 6.1606\n",
      "Epoch 475/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.0861 - val_loss: 6.1219\n",
      "Epoch 476/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.0204 - val_loss: 6.1807\n",
      "Epoch 477/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 6.0326 - val_loss: 6.1321\n",
      "Epoch 478/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 6.0862 - val_loss: 6.1101\n",
      "Epoch 479/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.0868 - val_loss: 6.1784\n",
      "Epoch 480/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.0394 - val_loss: 6.1085\n",
      "Epoch 481/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.0562 - val_loss: 6.1803\n",
      "Epoch 482/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1307 - val_loss: 6.2223\n",
      "Epoch 483/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1892 - val_loss: 6.1985\n",
      "Epoch 484/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.0364 - val_loss: 6.1251\n",
      "Epoch 485/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.0347 - val_loss: 6.1537\n",
      "Epoch 486/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1382 - val_loss: 6.1035\n",
      "Epoch 487/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.0227 - val_loss: 6.1106\n",
      "Epoch 488/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.0104 - val_loss: 6.2087\n",
      "Epoch 489/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.1173 - val_loss: 6.1073\n",
      "Epoch 490/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.0703 - val_loss: 6.1135\n",
      "Epoch 491/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5.9991 - val_loss: 6.1119\n",
      "Epoch 492/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5.9922 - val_loss: 6.0826\n",
      "Epoch 493/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.0029 - val_loss: 6.1206\n",
      "Epoch 494/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.0188 - val_loss: 6.1274\n",
      "Epoch 495/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5.9849 - val_loss: 6.1382\n",
      "Epoch 496/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.0458 - val_loss: 6.2259\n",
      "Epoch 497/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5.9895 - val_loss: 6.0820\n",
      "Epoch 498/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5.9880 - val_loss: 6.0884\n",
      "Epoch 499/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5.9921 - val_loss: 6.0963\n",
      "Epoch 500/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5.9992 - val_loss: 6.2087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x158b5b4e550>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=6, activation='relu', input_shape=(2,),\n",
    "                          ),\n",
    "    tf.keras.layers.Dense(units=5, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "\n",
    "])\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Machine Learning Model vs Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step\n",
      "Mean Squared Error for Neural Network : 6.463613956419199\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error for Neural Network :\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for Random Forest: 6.4331221269193986\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=100, n_jobs=-1)\n",
    "rf.fit(X_train, y_train.ravel())\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error for Random Forest:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters vs Hyperparameters\n",
    "\n",
    "- Definition: Parameters are learned from data; hyperparameters are set before training.\n",
    "- Role: Parameters make predictions; hyperparameters guide the learning process.\n",
    "- Adjustment: Parameters adjust automatically; hyperparameters are chosen manually (or can use searched using algorithms).\n",
    "- Examples: Parameters are weights/biases; hyperparameters include learning rate, epochs.\n",
    "- Optimization: Parameters optimized during training; hyperparameters through testing various settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BMI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('bmi_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>174</td>\n",
       "      <td>96</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>189</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>185</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>195</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>149</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Height  Weight  Index\n",
       "0    Male     174      96      4\n",
       "1    Male     189      87      2\n",
       "2  Female     185     110      4\n",
       "3  Female     195     104      3\n",
       "4    Male     149      61      3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a classification task, here we are trying to predict BMI based on Gender, Height and Weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "\n",
    "- Convert Gender to numeric categorical variable\n",
    "- Normalize the input data for better neural network performance.\n",
    "- Split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>96</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>195</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Height  Weight  Index\n",
       "0       0     174      96      4\n",
       "1       0     189      87      2\n",
       "2       1     185     110      4\n",
       "3       1     195     104      3\n",
       "4       0     149      61      3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df[['Gender', 'Height', 'Weight']].values  \n",
    "\n",
    "# Normalize X\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification problem we have to change few things.\n",
    "- Input shape\n",
    "- Activation in the output layer\n",
    "- Loss Function\n",
    "\n",
    "You can have 6 outputs(one hot encoded) with softmax or 1 output(0 to 6) with sigmoid. The loss function will depend on what you choose for the ouput layer.\n",
    "\n",
    "In this example we are using one hot encoded y, softmax with categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 -> [1, 0, 0, 0, 0, 0]\n",
    "\n",
    "1 -> [0, 1, 0, 0, 0, 0]\n",
    "\n",
    "2 -> [0, 0, 1, 0, 0, 0]\n",
    "\n",
    "and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "Y = to_categorical(df['Index'].values)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 16)                64        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 6)                 54        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 254 (1016.00 Byte)\n",
      "Trainable params: 254 (1016.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\sgnka\\anaconda3\\envs\\onnx\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "10/10 [==============================] - 1s 20ms/step - loss: 1.8194 - accuracy: 0.1406 - val_loss: 1.7994 - val_accuracy: 0.2375\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.7962 - accuracy: 0.2313 - val_loss: 1.7769 - val_accuracy: 0.2625\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.7764 - accuracy: 0.2344 - val_loss: 1.7602 - val_accuracy: 0.2500\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.7620 - accuracy: 0.2031 - val_loss: 1.7448 - val_accuracy: 0.1875\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.7457 - accuracy: 0.2344 - val_loss: 1.7263 - val_accuracy: 0.2375\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.7277 - accuracy: 0.2500 - val_loss: 1.7070 - val_accuracy: 0.2625\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.7098 - accuracy: 0.2625 - val_loss: 1.6865 - val_accuracy: 0.2500\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.6906 - accuracy: 0.3031 - val_loss: 1.6658 - val_accuracy: 0.3000\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.6716 - accuracy: 0.3406 - val_loss: 1.6445 - val_accuracy: 0.3375\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.6508 - accuracy: 0.3594 - val_loss: 1.6237 - val_accuracy: 0.3375\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.6298 - accuracy: 0.3625 - val_loss: 1.6026 - val_accuracy: 0.3625\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.6080 - accuracy: 0.3719 - val_loss: 1.5815 - val_accuracy: 0.4000\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.5866 - accuracy: 0.4000 - val_loss: 1.5597 - val_accuracy: 0.4125\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.5634 - accuracy: 0.4094 - val_loss: 1.5392 - val_accuracy: 0.4125\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.5428 - accuracy: 0.4156 - val_loss: 1.5190 - val_accuracy: 0.4125\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5227 - accuracy: 0.4031 - val_loss: 1.5004 - val_accuracy: 0.4125\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.5043 - accuracy: 0.3938 - val_loss: 1.4834 - val_accuracy: 0.4125\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4897 - accuracy: 0.3938 - val_loss: 1.4677 - val_accuracy: 0.4125\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4732 - accuracy: 0.3938 - val_loss: 1.4558 - val_accuracy: 0.4125\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4600 - accuracy: 0.3938 - val_loss: 1.4443 - val_accuracy: 0.4125\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4483 - accuracy: 0.3938 - val_loss: 1.4341 - val_accuracy: 0.4125\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4357 - accuracy: 0.3938 - val_loss: 1.4242 - val_accuracy: 0.4125\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4241 - accuracy: 0.3938 - val_loss: 1.4144 - val_accuracy: 0.4125\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4130 - accuracy: 0.3938 - val_loss: 1.4043 - val_accuracy: 0.4125\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4017 - accuracy: 0.3938 - val_loss: 1.3951 - val_accuracy: 0.4125\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3901 - accuracy: 0.3938 - val_loss: 1.3843 - val_accuracy: 0.4125\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3784 - accuracy: 0.3938 - val_loss: 1.3728 - val_accuracy: 0.4125\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3665 - accuracy: 0.3938 - val_loss: 1.3615 - val_accuracy: 0.4125\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3542 - accuracy: 0.3938 - val_loss: 1.3500 - val_accuracy: 0.4125\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3410 - accuracy: 0.4031 - val_loss: 1.3373 - val_accuracy: 0.4250\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3275 - accuracy: 0.4062 - val_loss: 1.3237 - val_accuracy: 0.4250\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3132 - accuracy: 0.4094 - val_loss: 1.3095 - val_accuracy: 0.4250\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.2983 - accuracy: 0.4219 - val_loss: 1.2944 - val_accuracy: 0.4250\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.2828 - accuracy: 0.4313 - val_loss: 1.2788 - val_accuracy: 0.4375\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.2665 - accuracy: 0.4344 - val_loss: 1.2609 - val_accuracy: 0.4375\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.2487 - accuracy: 0.4375 - val_loss: 1.2411 - val_accuracy: 0.4500\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.2293 - accuracy: 0.4375 - val_loss: 1.2215 - val_accuracy: 0.4500\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.2097 - accuracy: 0.4375 - val_loss: 1.2031 - val_accuracy: 0.4500\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1916 - accuracy: 0.4437 - val_loss: 1.1853 - val_accuracy: 0.4625\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1742 - accuracy: 0.4531 - val_loss: 1.1684 - val_accuracy: 0.4625\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1568 - accuracy: 0.4563 - val_loss: 1.1514 - val_accuracy: 0.4875\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1393 - accuracy: 0.4719 - val_loss: 1.1351 - val_accuracy: 0.5000\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1228 - accuracy: 0.4781 - val_loss: 1.1183 - val_accuracy: 0.5000\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1060 - accuracy: 0.4844 - val_loss: 1.1024 - val_accuracy: 0.5125\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0895 - accuracy: 0.5125 - val_loss: 1.0865 - val_accuracy: 0.5250\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0736 - accuracy: 0.5312 - val_loss: 1.0701 - val_accuracy: 0.5250\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0572 - accuracy: 0.5312 - val_loss: 1.0541 - val_accuracy: 0.5375\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0414 - accuracy: 0.5500 - val_loss: 1.0387 - val_accuracy: 0.5625\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0257 - accuracy: 0.5656 - val_loss: 1.0245 - val_accuracy: 0.5875\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0110 - accuracy: 0.5813 - val_loss: 1.0095 - val_accuracy: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x158b813d4f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For classification p\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=16, activation='relu', input_shape=(3,),\n",
    "                          ),\n",
    "    tf.keras.layers.Dense(units=8, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=6, activation='softmax'),\n",
    "\n",
    "])\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) # for classification problems, we use categorical_crossentropy\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Softmax](https://docs-assets.developer.apple.com/published/c2185dfdcf/0ab139bc-3ff6-49d2-8b36-dcc98ef31102.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onnx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
