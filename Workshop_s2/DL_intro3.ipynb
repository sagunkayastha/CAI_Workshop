{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagunkayastha/CAI_Workshop/blob/main/Workshop_s2/DL_intro3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tP857islOIOa"
      },
      "outputs": [],
      "source": [
        "!wget -q https://raw.githubusercontent.com/sagunkayastha/CAI_Workshop/main/Workshop_s2/utils/utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jrU7TTE2OAC1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\sgnka\\anaconda3\\envs\\onnx\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'plot_images' from 'utils' (unknown location)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical, plot_model\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_images\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Load CIFAR-10 data\u001b[39;00m\n\u001b[0;32m     10\u001b[0m (X_train, y_train), (X_test, y_test) \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mcifar10\u001b[38;5;241m.\u001b[39mload_data()\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name 'plot_images' from 'utils' (unknown location)"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from utils import plot_images\n",
        "\n",
        "# Load CIFAR-10 data\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1ee7mkiOAC2"
      },
      "outputs": [],
      "source": [
        "# Plot 9 images from the training dataset\n",
        "plot_images(X_train, y_train, 3, 3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu3ovFdvOAC2"
      },
      "source": [
        "***Normalization*** is a step in preparing data for machine learning that makes all the data similar in scale. This is important because:\n",
        "\n",
        "- Helps Learn Faster: It makes the machine learning model learn and make predictions faster.\n",
        "- Fair Treatment: Ensures every piece of data is treated equally by the model, so no single type of data overpowers others.\n",
        "- Better Predictions: Leads to more accurate and stable predictions from the model.\n",
        "- Works Well with Many Models: Some machine learning models need data to be normalized to work correctly.\n",
        "- Avoids Problems: Prevents issues that can happen when data is in very different scales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baQVr3SFOVGw"
      },
      "outputs": [],
      "source": [
        "# X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkQp31_pOAC3"
      },
      "outputs": [],
      "source": [
        "## Preprocess data\n",
        "\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0  # Normalize pixel values to be between 0 and 1, the maximum value of a pixel in an image is 255.0. you can print a sample image to see the pixel values.\n",
        "\n",
        "# Convert labels to one-hot encoding if necessary\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10) # convert to one-hot encoding\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9w0y6OnOAC3"
      },
      "outputs": [],
      "source": [
        "# Reshape the input data to 1D array for the input layer, Since we are using a fully connected network\n",
        "x_train_flattened = X_train.reshape(X_train.shape[0],-1)\n",
        "x_test_flattened = X_test.reshape(X_test.shape[0],-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjWnwD6YOAC3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Number of classes\n",
        "num_classes = 10  # CIFAR-10 total classes (0-9)\n",
        "\n",
        "model = Sequential([\n",
        "    # First layer (input layer): Specify input shape\n",
        "    Dense(1024, activation='relu', input_shape=(3072,)),\n",
        "    # Second layer\n",
        "    Dense(512, activation='relu'),\n",
        "    # Third layer\n",
        "    Dense(256, activation='relu'),\n",
        "    # Fourth layer\n",
        "    Dense(128, activation='relu'),\n",
        "    # Output layer: Use softmax for multi-class classification\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(x_train_flattened, y_train, epochs=50, batch_size=64, shuffle=True, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "On-cXGWNPSfZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Using the model's evaluate method for accuracy\n",
        "test_loss, test_accuracy = model.evaluate(x_test_flattened, y_test)\n",
        "print(f\"Evaluated Test Accuracy: {test_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GQO3EVZOAC4"
      },
      "source": [
        "## CNNS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i790n820OAC4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    Flatten(),\n",
        "    # Dense layers\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55EWGKHHPkPd"
      },
      "source": [
        "Compare number of parameters in MLP and CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1w1rU-CYPGlf"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# We are using original 32x32x3 images ( X_train not x_train)\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=64, shuffle=True, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DBl8NzlPcas"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Using the model's evaluate method for accuracy\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Evaluated Test Accuracy: {test_accuracy}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
