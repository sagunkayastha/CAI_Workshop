{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagunkayastha/CAI_Workshop/blob/main/Workshop_1/DS_intro1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IrO4wZDqRIv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BlJPKxiqRIx"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.*?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcKdeIugqRIx"
      },
      "source": [
        "## The Boston Housing Dataset   \n",
        "We explore the Boston housing dataset, which contains US census data concerning houses in various areas around the city of Boston.\n",
        "\n",
        "Boston Housing Data: This dataset was taken from the StatLib library and is maintained by Carnegie Mellon University. This dataset concerns the housing prices in the housing city of Boston. The dataset provided has 506 instances with 13 features.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ROKobnoqRIy"
      },
      "outputs": [],
      "source": [
        "# Common standard libraries\n",
        "\n",
        "import datetime\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxSoz9DXqRIy"
      },
      "outputs": [],
      "source": [
        "# Common external libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn # scikit-learn\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrOp1La9qRIz"
      },
      "outputs": [],
      "source": [
        "# Visualization libraries\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CwXe3cPqRIz"
      },
      "outputs": [],
      "source": [
        "# Setting plot appearance\n",
        "# See here for more options: https://matplotlib.org/users/customizing.html\n",
        "\n",
        "%config InlineBackend.figure_format='retina'\n",
        "sns.set() # Revert to matplotlib defaults\n",
        "plt.rcParams['figure.figsize'] = (9, 6)\n",
        "plt.rcParams['axes.labelpad'] = 10\n",
        "sns.set_style(\"darkgrid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KklURvf1qRIz"
      },
      "source": [
        "### Loading the data\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment following or upload the file\n",
        "# !wget https://raw.githubusercontent.com/sagunkayastha/CAI_Workshop/main/Workshop_1/data/BostonHousing.csv\n"
      ],
      "metadata": {
        "id": "oDMUKHOeqVcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khDeEW8iqRIz"
      },
      "outputs": [],
      "source": [
        "\n",
        "boston = pd.read_csv('BostonHousing.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo3KLvz-qRI0"
      },
      "source": [
        "![Alt text](https://raw.githubusercontent.com/sagunkayastha/CAI_Workshop/main/Workshop_1/images/image-1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLT9ISPmqRI0"
      },
      "source": [
        "proxy for socio-economic status."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF4xT7feqRI0"
      },
      "outputs": [],
      "source": [
        "boston"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwLH0mmFqRI0"
      },
      "source": [
        "Question - What do we want to do with this data? What is our Goal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iELdw0ZqqRI0"
      },
      "outputs": [],
      "source": [
        "# What fields are in the dictionary?\n",
        "boston.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRJpjpJUqRI1"
      },
      "source": [
        "We want to predict housing price(medv) (using 12 features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEz7sp0BqRI1"
      },
      "source": [
        "## Basic EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3gZuIgNqRI1"
      },
      "outputs": [],
      "source": [
        "# changing the name of data set.\n",
        "df = boston.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwO4xkRpqRI1"
      },
      "outputs": [],
      "source": [
        "summary_stats = df.describe()\n",
        "summary_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfTxamK8qRI1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Set the aesthetic style of the plots\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Draw histograms for each feature\n",
        "df.hist(figsize=(16, 14), bins=30)\n",
        "plt.suptitle('Feature Distributions', fontsize=20)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1f717mhqRI1"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPcifHcGqRI1"
      },
      "outputs": [],
      "source": [
        "# Identify and NaNs\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJpph3rOqRI2"
      },
      "outputs": [],
      "source": [
        "# Calculate the correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Generate a heatmap\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap', fontsize=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKHvIgeDqRI2"
      },
      "outputs": [],
      "source": [
        "# Focus on these columns\n",
        "# Domain Expertise\n",
        "cols = ['rm', 'age', 'tax', 'lstat', 'medv']\n",
        "\n",
        "# The pairwise correlations\n",
        "df[cols].corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63RBF52bqRI2"
      },
      "outputs": [],
      "source": [
        "# Pairwise correlation heatmap\n",
        "\n",
        "ax = sns.heatmap(\n",
        "    df[cols].corr(),annot=True,\n",
        "    cmap=sns.cubehelix_palette(20, light=0.95, dark=0.15),\n",
        ")\n",
        "ax.xaxis.tick_top() # move labels to the top\n",
        "\n",
        "# plt.savefig(\n",
        "#     'boston-housing-corr.png',\n",
        "#     bbox_inches='tight',\n",
        "#     dpi=300,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QZZtsU2qRI2"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(\n",
        "    df[cols],\n",
        "    plot_kws={'alpha': 0.6},\n",
        "    diag_kws={'bins': 30},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhB3p692qRI2"
      },
      "outputs": [],
      "source": [
        "# Categorize AGE into 3 bins\n",
        "\n",
        "def get_age_category(x):\n",
        "    if x < 50:\n",
        "        age = 'Relatively New'\n",
        "    elif 50 <= x < 85:\n",
        "        age = 'Relatively Old'\n",
        "    else:\n",
        "        age = 'Very Old'\n",
        "    return age\n",
        "\n",
        "df['age_category'] = df.age.apply(get_age_category)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvtVe9wvqRI3"
      },
      "outputs": [],
      "source": [
        "# Check the segmented counts\n",
        "df.groupby('age_category').size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vW3d_1FyqRI3"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(\n",
        "    x='medv',\n",
        "    y='age_category',\n",
        "    data=df,\n",
        "    order=['Relatively New', 'Relatively Old', 'Very Old'],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPWCSfowqRI3"
      },
      "outputs": [],
      "source": [
        "sns.violinplot(\n",
        "    x='medv',\n",
        "    y='age_category',\n",
        "    data=df,\n",
        "    order=['Relatively New', 'Relatively Old', 'Very Old'],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6u7PdH3qRI3"
      },
      "outputs": [],
      "source": [
        "cols = ['rm', 'age', 'tax', 'lstat', 'medv', 'age_category']\n",
        "sns.pairplot(\n",
        "    df[cols],\n",
        "    hue='age_category',\n",
        "    hue_order=['Relatively New', 'Relatively Old', 'Very Old'],\n",
        "    plot_kws={'alpha': 0.5},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ICyggmzqRI3"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Li0M3w1IqRI4"
      },
      "outputs": [],
      "source": [
        "y = df['medv'].values\n",
        "x = df['lstat'].values.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xt1pfKMXqRI4"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly = PolynomialFeatures(degree=3)\n",
        "x_poly = poly.fit_transform(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDtgFHt8qRI4"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "clf = LinearRegression(fit_intercept=False)\n",
        "clf.fit(x_poly, y)\n",
        "x_0, x_1, x_2, x_3 = clf.coef_\n",
        "msg = (\n",
        "    'model: y = {:.3f} + {:.3f}x + {:.3f}x^2 + {:.3f}x^3'\n",
        "    .format(x_0, x_1, x_2, x_3)\n",
        ")\n",
        "print(msg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8yXwisdqRI4"
      },
      "outputs": [],
      "source": [
        "y_pred = clf.predict(x_poly)\n",
        "resid_MEDV = y - y_pred\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "error = mean_squared_error(y, y_pred)\n",
        "print('mse = {:.2f}'.format(error))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4IR8IYkqRI4"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Plot the samples\n",
        "ax.scatter(x.flatten(), y, alpha=0.6)\n",
        "\n",
        "# Plot the polynomial model\n",
        "x_ = np.linspace(2, 38, 50).reshape(-1, 1)\n",
        "x_poly = poly.fit_transform(x_)\n",
        "y_ = clf.predict(x_poly)\n",
        "ax.plot(x_, y_, color='red', alpha=0.8)\n",
        "\n",
        "ax.set_xlabel('LSTAT')\n",
        "ax.set_ylabel('MEDV')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNX7xmz-qRI4"
      },
      "source": [
        "Sklearn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72ULQb8IqRI4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Extract features and target variable from the dataset\n",
        "X = df.drop(['medv','age_category'], axis=1)\n",
        "\n",
        "\n",
        "y = df['medv']\n",
        "\n",
        "# Split the data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGsaSxZjqRI5"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform both the training and test data\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize the Linear Regression model\n",
        "lr_model_scaled = LinearRegression()\n",
        "\n",
        "# Fit the model to the scaled training data\n",
        "lr_model_scaled.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the scaled test set\n",
        "y_pred_scaled = lr_model_scaled.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics for the scaled data\n",
        "mse_scaled = mean_squared_error(y_test, y_pred_scaled)\n",
        "rmse_scaled = np.sqrt(mse_scaled)\n",
        "r2_scaled = r2_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(f\"Mean Squared Error (MSE) for LR: {mse_scaled :.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE) for LR: {rmse_scaled:.2f}\")\n",
        "print(f\"R-squared (R2) for LR: {r2_scaled:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NysYOCAiqRI5"
      },
      "outputs": [],
      "source": [
        "# Retrieve the intercept and coefficients from the model\n",
        "intercept = lr_model_scaled.intercept_\n",
        "coefficients = lr_model_scaled.coef_\n",
        "\n",
        "# Create a dictionary to show feature names along with their corresponding coefficients\n",
        "feature_coef_dict = {feature: coef for feature, coef in zip(X.columns, coefficients)}\n",
        "\n",
        "intercept, feature_coef_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3VdCAN7qRI5"
      },
      "source": [
        "medv=22.80−1.00×crim+0.70×zn+0.28×indus+0.72×chas−2.02×nox+3.15×rm−0.18×age−3.08×dis+2.25×rad−1.77×tax−2.04×ptratio+1.13×b−3.61×lstat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eESc0OIPqRI6"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "# Initialize the Support Vector Regressor model\n",
        "svr_model = SVR()\n",
        "\n",
        "# Fit the model to the scaled training data\n",
        "svr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the scaled test set\n",
        "y_pred_svr = svr_model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics for the SVR model\n",
        "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
        "rmse_svr = np.sqrt(mse_svr)\n",
        "r2_svr = r2_score(y_test, y_pred_svr)\n",
        "\n",
        "print(f\"Mean Squared Error (MSE) for SVR: {mse_svr:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE) for SVR: {rmse_svr:.2f}\")\n",
        "print(f\"R-squared (R2) for SVR: {r2_svr:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfFTpT59qRI6"
      },
      "outputs": [],
      "source": [
        "# Extract features and target variable from the dataset\n",
        "X = df.drop(['medv','age_category'], axis=1)\n",
        "\n",
        "cols = ['rm', 'age', 'tax', 'lstat']\n",
        "X = df[cols]\n",
        "y = df['medv']\n",
        "\n",
        "# Split the data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform both the training and test data\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize the Linear Regression model\n",
        "lr_model_scaled = LinearRegression()\n",
        "\n",
        "# Fit the model to the scaled training data\n",
        "lr_model_scaled.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the scaled test set\n",
        "y_pred_scaled = lr_model_scaled.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics for the scaled data\n",
        "mse_scaled = mean_squared_error(y_test, y_pred_scaled)\n",
        "rmse_scaled = np.sqrt(mse_scaled)\n",
        "r2_scaled = r2_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(f\"Mean Squared Error (MSE) for LR with selected cols: {mse_scaled :.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE) for LR with selected cols: {rmse_scaled:.2f}\")\n",
        "print(f\"R-squared (R2) for LR with selected cols: {r2_scaled :.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTpjAucZqRI6"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "# Initialize the Support Vector Regressor model\n",
        "svr_model = SVR()\n",
        "\n",
        "# Fit the model to the scaled training data\n",
        "svr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the scaled test set\n",
        "y_pred_svr = svr_model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics for the SVR model\n",
        "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
        "rmse_svr = np.sqrt(mse_svr)\n",
        "r2_svr = r2_score(y_test, y_pred_svr)\n",
        "\n",
        "\n",
        "print(f\"Mean Squared Error (MSE) for SVR with selected cols: {mse_svr:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE) for SVR with selected cols: {rmse_svr:.2f}\")\n",
        "print(f\"R-squared (R2) for SVR with selected cols: {r2_svr:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxYNh6yuqRI6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To try other datasets\n",
        "\n",
        "https://github.com/selva86/datasets/tree/master"
      ],
      "metadata": {
        "id": "sgIx3rbrrWSM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "83E0eOTRrX4y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}