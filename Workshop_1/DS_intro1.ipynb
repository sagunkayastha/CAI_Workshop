{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagunkayastha/CAI_Workshop/blob/main/Workshop_1/DS_intro1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5IrO4wZDqRIv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;31mInit signature:\u001b[0m\n",
            "\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
            "\u001b[0m    \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
            "\u001b[0m    \u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Axes | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
            "\u001b[0m    \u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Axes | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
            "\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Dtype | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
            "\u001b[0m    \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
            "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'None'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mDocstring:\u001b[0m     \n",
            "Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
            "\n",
            "Data structure also contains labeled axes (rows and columns).\n",
            "Arithmetic operations align on both row and column labels. Can be\n",
            "thought of as a dict-like container for Series objects. The primary\n",
            "pandas data structure.\n",
            "\n",
            "Parameters\n",
            "----------\n",
            "data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
            "    Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n",
            "    data is a dict, column order follows insertion-order. If a dict contains Series\n",
            "    which have an index defined, it is aligned by its index.\n",
            "\n",
            "    .. versionchanged:: 0.25.0\n",
            "       If data is a list of dicts, column order follows insertion-order.\n",
            "\n",
            "index : Index or array-like\n",
            "    Index to use for resulting frame. Will default to RangeIndex if\n",
            "    no indexing information part of input data and no index provided.\n",
            "columns : Index or array-like\n",
            "    Column labels to use for resulting frame when data does not have them,\n",
            "    defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n",
            "    will perform column selection instead.\n",
            "dtype : dtype, default None\n",
            "    Data type to force. Only a single dtype is allowed. If None, infer.\n",
            "copy : bool or None, default None\n",
            "    Copy data from inputs.\n",
            "    For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n",
            "    or 2d ndarray input, the default of None behaves like ``copy=False``.\n",
            "    If data is a dict containing one or more Series (possibly of different dtypes),\n",
            "    ``copy=False`` will ensure that these inputs are not copied.\n",
            "\n",
            "    .. versionchanged:: 1.3.0\n",
            "\n",
            "See Also\n",
            "--------\n",
            "DataFrame.from_records : Constructor from tuples, also record arrays.\n",
            "DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n",
            "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
            "read_table : Read general delimited file into DataFrame.\n",
            "read_clipboard : Read text from clipboard into DataFrame.\n",
            "\n",
            "Notes\n",
            "-----\n",
            "Please reference the :ref:`User Guide <basics.dataframe>` for more information.\n",
            "\n",
            "Examples\n",
            "--------\n",
            "Constructing DataFrame from a dictionary.\n",
            "\n",
            ">>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
            ">>> df = pd.DataFrame(data=d)\n",
            ">>> df\n",
            "   col1  col2\n",
            "0     1     3\n",
            "1     2     4\n",
            "\n",
            "Notice that the inferred dtype is int64.\n",
            "\n",
            ">>> df.dtypes\n",
            "col1    int64\n",
            "col2    int64\n",
            "dtype: object\n",
            "\n",
            "To enforce a single dtype:\n",
            "\n",
            ">>> df = pd.DataFrame(data=d, dtype=np.int8)\n",
            ">>> df.dtypes\n",
            "col1    int8\n",
            "col2    int8\n",
            "dtype: object\n",
            "\n",
            "Constructing DataFrame from a dictionary including Series:\n",
            "\n",
            ">>> d = {'col1': [0, 1, 2, 3], 'col2': pd.Series([2, 3], index=[2, 3])}\n",
            ">>> pd.DataFrame(data=d, index=[0, 1, 2, 3])\n",
            "   col1  col2\n",
            "0     0   NaN\n",
            "1     1   NaN\n",
            "2     2   2.0\n",
            "3     3   3.0\n",
            "\n",
            "Constructing DataFrame from numpy ndarray:\n",
            "\n",
            ">>> df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
            "...                    columns=['a', 'b', 'c'])\n",
            ">>> df2\n",
            "   a  b  c\n",
            "0  1  2  3\n",
            "1  4  5  6\n",
            "2  7  8  9\n",
            "\n",
            "Constructing DataFrame from a numpy ndarray that has labeled columns:\n",
            "\n",
            ">>> data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n",
            "...                 dtype=[(\"a\", \"i4\"), (\"b\", \"i4\"), (\"c\", \"i4\")])\n",
            ">>> df3 = pd.DataFrame(data, columns=['c', 'a'])\n",
            "...\n",
            ">>> df3\n",
            "   c  a\n",
            "0  3  1\n",
            "1  6  4\n",
            "2  9  7\n",
            "\n",
            "Constructing DataFrame from dataclass:\n",
            "\n",
            ">>> from dataclasses import make_dataclass\n",
            ">>> Point = make_dataclass(\"Point\", [(\"x\", int), (\"y\", int)])\n",
            ">>> pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n",
            "   x  y\n",
            "0  0  0\n",
            "1  0  3\n",
            "2  2  3\n",
            "\u001b[1;31mFile:\u001b[0m           c:\\users\\sgnka\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\n",
            "\u001b[1;31mType:\u001b[0m           type\n",
            "\u001b[1;31mSubclasses:\u001b[0m     SubclassedDataFrame"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0BlJPKxiqRIx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sns.FacetGrid\n",
            "sns.JointGrid\n",
            "sns.PairGrid\n",
            "sns.__annotations__\n",
            "sns.__builtins__\n",
            "sns.__cached__\n",
            "sns.__class__\n",
            "sns.__delattr__\n",
            "sns.__dict__\n",
            "sns.__dir__\n",
            "sns.__doc__\n",
            "sns.__eq__\n",
            "sns.__file__\n",
            "sns.__format__\n",
            "sns.__ge__\n",
            "sns.__getattribute__\n",
            "sns.__gt__\n",
            "sns.__hash__\n",
            "sns.__init__\n",
            "sns.__init_subclass__\n",
            "sns.__le__\n",
            "sns.__loader__\n",
            "sns.__lt__\n",
            "sns.__name__\n",
            "sns.__ne__\n",
            "sns.__new__\n",
            "sns.__package__\n",
            "sns.__path__\n",
            "sns.__reduce__\n",
            "sns.__reduce_ex__\n",
            "sns.__repr__\n",
            "sns.__setattr__\n",
            "sns.__sizeof__\n",
            "sns.__spec__\n",
            "sns.__str__\n",
            "sns.__subclasshook__\n",
            "sns.__version__\n",
            "sns.algorithms\n",
            "sns.axes_style\n",
            "sns.axisgrid\n",
            "sns.barplot\n",
            "sns.blend_palette\n",
            "sns.boxenplot\n",
            "sns.boxplot\n",
            "sns.categorical\n",
            "sns.catplot\n",
            "sns.choose_colorbrewer_palette\n",
            "sns.choose_cubehelix_palette\n",
            "sns.choose_dark_palette\n",
            "sns.choose_diverging_palette\n",
            "sns.choose_light_palette\n",
            "sns.clustermap\n",
            "sns.cm\n",
            "sns.color_palette\n",
            "sns.colors\n",
            "sns.countplot\n",
            "sns.crayon_palette\n",
            "sns.crayons\n",
            "sns.cubehelix_palette\n",
            "sns.dark_palette\n",
            "sns.desaturate\n",
            "sns.despine\n",
            "sns.displot\n",
            "sns.distplot\n",
            "sns.distributions\n",
            "sns.diverging_palette\n",
            "sns.dogplot\n",
            "sns.ecdfplot\n",
            "sns.external\n",
            "sns.get_data_home\n",
            "sns.get_dataset_names\n",
            "sns.heatmap\n",
            "sns.histplot\n",
            "sns.hls_palette\n",
            "sns.husl_palette\n",
            "sns.jointplot\n",
            "sns.kdeplot\n",
            "sns.light_palette\n",
            "sns.lineplot\n",
            "sns.lmplot\n",
            "sns.load_dataset\n",
            "sns.matrix\n",
            "sns.miscplot\n",
            "sns.move_legend\n",
            "sns.mpl\n",
            "sns.mpl_palette\n",
            "sns.pairplot\n",
            "sns.palettes\n",
            "sns.palplot\n",
            "sns.plotting_context\n",
            "sns.pointplot\n",
            "sns.rcmod\n",
            "sns.regplot\n",
            "sns.regression\n",
            "sns.relational\n",
            "sns.relplot\n",
            "sns.reset_defaults\n",
            "sns.reset_orig\n",
            "sns.residplot\n",
            "sns.rugplot\n",
            "sns.saturate\n",
            "sns.scatterplot\n",
            "sns.set\n",
            "sns.set_color_codes\n",
            "sns.set_context\n",
            "sns.set_hls_values\n",
            "sns.set_palette\n",
            "sns.set_style\n",
            "sns.set_theme\n",
            "sns.stripplot\n",
            "sns.swarmplot\n",
            "sns.utils\n",
            "sns.violinplot\n",
            "sns.widgets\n",
            "sns.xkcd_palette\n",
            "sns.xkcd_rgb"
          ]
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "sns.*?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcKdeIugqRIx"
      },
      "source": [
        "## The Boston Housing Dataset   \n",
        "We explore the Boston housing dataset, which contains US census data concerning houses in various areas around the city of Boston.\n",
        "\n",
        "Boston Housing Data: This dataset was taken from the StatLib library and is maintained by Carnegie Mellon University. This dataset concerns the housing prices in the housing city of Boston. The dataset provided has 506 instances with 13 features.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8ROKobnoqRIy"
      },
      "outputs": [],
      "source": [
        "# Common standard libraries\n",
        "\n",
        "import datetime\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NxSoz9DXqRIy"
      },
      "outputs": [],
      "source": [
        "# Common external libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn # scikit-learn\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lrOp1La9qRIz"
      },
      "outputs": [],
      "source": [
        "# Visualization libraries\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-CwXe3cPqRIz"
      },
      "outputs": [],
      "source": [
        "# Setting plot appearance\n",
        "# See here for more options: https://matplotlib.org/users/customizing.html\n",
        "\n",
        "%config InlineBackend.figure_format='retina'\n",
        "sns.set() # Revert to matplotlib defaults\n",
        "plt.rcParams['figure.figsize'] = (9, 6)\n",
        "plt.rcParams['axes.labelpad'] = 10\n",
        "sns.set_style(\"darkgrid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KklURvf1qRIz"
      },
      "source": [
        "### Loading the data\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oDMUKHOeqVcb"
      },
      "outputs": [],
      "source": [
        "# Uncomment following or upload the file\n",
        "# !wget https://raw.githubusercontent.com/sagunkayastha/CAI_Workshop/main/Workshop_1/data/BostonHousing.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "khDeEW8iqRIz"
      },
      "outputs": [],
      "source": [
        "\n",
        "boston = pd.read_csv('data/BostonHousing.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo3KLvz-qRI0"
      },
      "source": [
        "![Alt text](https://raw.githubusercontent.com/sagunkayastha/CAI_Workshop/main/Workshop_1/images/image-1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLT9ISPmqRI0"
      },
      "source": [
        "proxy for socio-economic status."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LF4xT7feqRI0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>crim</th>\n",
              "      <th>zn</th>\n",
              "      <th>indus</th>\n",
              "      <th>chas</th>\n",
              "      <th>nox</th>\n",
              "      <th>rm</th>\n",
              "      <th>age</th>\n",
              "      <th>dis</th>\n",
              "      <th>rad</th>\n",
              "      <th>tax</th>\n",
              "      <th>ptratio</th>\n",
              "      <th>b</th>\n",
              "      <th>lstat</th>\n",
              "      <th>medv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1</td>\n",
              "      <td>296</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>0.06263</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.593</td>\n",
              "      <td>69.1</td>\n",
              "      <td>2.4786</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>21.0</td>\n",
              "      <td>391.99</td>\n",
              "      <td>9.67</td>\n",
              "      <td>22.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>0.04527</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.120</td>\n",
              "      <td>76.7</td>\n",
              "      <td>2.2875</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.08</td>\n",
              "      <td>20.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>0.06076</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.976</td>\n",
              "      <td>91.0</td>\n",
              "      <td>2.1675</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.64</td>\n",
              "      <td>23.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>0.10959</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.794</td>\n",
              "      <td>89.3</td>\n",
              "      <td>2.3889</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>21.0</td>\n",
              "      <td>393.45</td>\n",
              "      <td>6.48</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>0.04741</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.030</td>\n",
              "      <td>80.8</td>\n",
              "      <td>2.5050</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>7.88</td>\n",
              "      <td>11.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>506 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
              "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
              "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
              "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
              "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
              "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
              "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
              "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273   \n",
              "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273   \n",
              "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273   \n",
              "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273   \n",
              "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273   \n",
              "\n",
              "     ptratio       b  lstat  medv  \n",
              "0       15.3  396.90   4.98  24.0  \n",
              "1       17.8  396.90   9.14  21.6  \n",
              "2       17.8  392.83   4.03  34.7  \n",
              "3       18.7  394.63   2.94  33.4  \n",
              "4       18.7  396.90   5.33  36.2  \n",
              "..       ...     ...    ...   ...  \n",
              "501     21.0  391.99   9.67  22.4  \n",
              "502     21.0  396.90   9.08  20.6  \n",
              "503     21.0  396.90   5.64  23.9  \n",
              "504     21.0  393.45   6.48  22.0  \n",
              "505     21.0  396.90   7.88  11.9  \n",
              "\n",
              "[506 rows x 14 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "boston"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwLH0mmFqRI0"
      },
      "source": [
        "Question - What do we want to do with this data? What is our Goal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iELdw0ZqqRI0"
      },
      "outputs": [],
      "source": [
        "# What fields are in the dictionary?\n",
        "boston.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRJpjpJUqRI1"
      },
      "source": [
        "We want to predict housing price(medv) (using 12 features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEz7sp0BqRI1"
      },
      "source": [
        "## Basic EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3gZuIgNqRI1"
      },
      "outputs": [],
      "source": [
        "# changing the name of data set.\n",
        "df = boston.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwO4xkRpqRI1"
      },
      "outputs": [],
      "source": [
        "summary_stats = df.describe()\n",
        "summary_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfTxamK8qRI1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Set the aesthetic style of the plots\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Draw histograms for each feature\n",
        "df.hist(figsize=(16, 14), bins=30)\n",
        "plt.suptitle('Feature Distributions', fontsize=20)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1f717mhqRI1"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPcifHcGqRI1"
      },
      "outputs": [],
      "source": [
        "# Identify and NaNs\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJpph3rOqRI2"
      },
      "outputs": [],
      "source": [
        "# Calculate the correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Generate a heatmap\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap', fontsize=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Try some other plots from \n",
        "https://seaborn.pydata.org/examples/index.html\n",
        "\n",
        "\n",
        "https://pandas.pydata.org/docs/user_guide/visualization.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot line chart for rm vs medv\n",
        "# area plot or box plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Domain expertise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKHvIgeDqRI2"
      },
      "outputs": [],
      "source": [
        "# Focus on these columns\n",
        "# Domain Expertise\n",
        "cols = ['rm', 'age', 'tax', 'lstat', 'medv']\n",
        "\n",
        "# The pairwise correlations\n",
        "df[cols].corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63RBF52bqRI2"
      },
      "outputs": [],
      "source": [
        "# Pairwise correlation heatmap\n",
        "\n",
        "ax = sns.heatmap(\n",
        "    df[cols].corr(),annot=True,\n",
        "    cmap=sns.cubehelix_palette(20, light=0.95, dark=0.15),\n",
        ")\n",
        "ax.xaxis.tick_top() # move labels to the top\n",
        "\n",
        "# plt.savefig(\n",
        "#     'boston-housing-corr.png',\n",
        "#     bbox_inches='tight',\n",
        "#     dpi=300,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QZZtsU2qRI2"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(\n",
        "    df[cols],\n",
        "    plot_kws={'alpha': 0.6},\n",
        "    diag_kws={'bins': 30},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhB3p692qRI2"
      },
      "outputs": [],
      "source": [
        "# Categorize AGE into 3 bins\n",
        "\n",
        "def get_age_category(x):\n",
        "    if x < 50:\n",
        "        age = 'Relatively New'\n",
        "    elif 50 <= x < 85:\n",
        "        age = 'Relatively Old'\n",
        "    else:\n",
        "        age = 'Very Old'\n",
        "    return age\n",
        "\n",
        "df['age_category'] = df.age.apply(get_age_category)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvtVe9wvqRI3"
      },
      "outputs": [],
      "source": [
        "# Check the segmented counts\n",
        "df.groupby('age_category').size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vW3d_1FyqRI3"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(\n",
        "    x='medv',\n",
        "    y='age_category',\n",
        "    data=df,\n",
        "    order=['Relatively New', 'Relatively Old', 'Very Old'],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPWCSfowqRI3"
      },
      "outputs": [],
      "source": [
        "sns.violinplot(\n",
        "    x='medv',\n",
        "    y='age_category',\n",
        "    data=df,\n",
        "    order=['Relatively New', 'Relatively Old', 'Very Old'],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6u7PdH3qRI3"
      },
      "outputs": [],
      "source": [
        "cols = ['rm', 'age', 'tax', 'lstat', 'medv', 'age_category']\n",
        "sns.pairplot(\n",
        "    df[cols],\n",
        "    hue='age_category',\n",
        "    hue_order=['Relatively New', 'Relatively Old', 'Very Old'],\n",
        "    plot_kws={'alpha': 0.5},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ICyggmzqRI3"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Li0M3w1IqRI4"
      },
      "outputs": [],
      "source": [
        "y = df['medv'].values\n",
        "x = df['lstat'].values.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xt1pfKMXqRI4"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "## converting into polynomial features of degree 3 (ax^3 + bx^2 + cx + d)\n",
        "poly = PolynomialFeatures(degree=3)\n",
        "x_poly = poly.fit_transform(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDtgFHt8qRI4"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "# fitting the polynomial regression model\n",
        "clf = LinearRegression(fit_intercept=False)\n",
        "clf.fit(x_poly, y)\n",
        "x_0, x_1, x_2, x_3 = clf.coef_\n",
        "msg = (\n",
        "    'model: y = {:.3f} + {:.3f}x + {:.3f}x^2 + {:.3f}x^3'\n",
        "    .format(x_0, x_1, x_2, x_3)\n",
        ")\n",
        "print(msg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8yXwisdqRI4"
      },
      "outputs": [],
      "source": [
        "y_pred = clf.predict(x_poly)\n",
        "resid_MEDV = y - y_pred\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "error = mean_squared_error(y, y_pred)\n",
        "print('mse = {:.2f}'.format(error))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4IR8IYkqRI4"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Plot the samples\n",
        "ax.scatter(x.flatten(), y, alpha=0.6)\n",
        "\n",
        "# Plot the polynomial model\n",
        "x_ = np.linspace(2, 38, 50).reshape(-1, 1)\n",
        "x_poly = poly.fit_transform(x_)\n",
        "y_ = clf.predict(x_poly)\n",
        "ax.plot(x_, y_, color='red', alpha=0.8)\n",
        "\n",
        "ax.set_xlabel('LSTAT')\n",
        "ax.set_ylabel('MEDV')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNX7xmz-qRI4"
      },
      "source": [
        "Sklearn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72ULQb8IqRI4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Extract features and target variable from the dataset\n",
        "X = df.drop(['medv','age_category'], axis=1)\n",
        "\n",
        "\n",
        "y = df['medv']\n",
        "\n",
        "# Split the data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGsaSxZjqRI5"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform both the training and test data\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize the Linear Regression model\n",
        "lr_model_scaled = LinearRegression()\n",
        "\n",
        "# Fit the model to the scaled training data\n",
        "lr_model_scaled.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the scaled test set\n",
        "y_pred_scaled = lr_model_scaled.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics for the scaled data\n",
        "mse_scaled = mean_squared_error(y_test, y_pred_scaled)\n",
        "rmse_scaled = np.sqrt(mse_scaled)\n",
        "r2_scaled = r2_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(f\"Mean Squared Error (MSE) for LR: {mse_scaled :.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE) for LR: {rmse_scaled:.2f}\")\n",
        "print(f\"R-squared (R2) for LR: {r2_scaled:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NysYOCAiqRI5"
      },
      "outputs": [],
      "source": [
        "# Retrieve the intercept and coefficients from the model\n",
        "intercept = lr_model_scaled.intercept_\n",
        "coefficients = lr_model_scaled.coef_\n",
        "\n",
        "# Create a dictionary to show feature names along with their corresponding coefficients\n",
        "feature_coef_dict = {feature: coef for feature, coef in zip(X.columns, coefficients)}\n",
        "\n",
        "intercept, feature_coef_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3VdCAN7qRI5"
      },
      "source": [
        "medv=22.80−1.00×crim+0.70×zn+0.28×indus+0.72×chas−2.02×nox+3.15×rm−0.18×age−3.08×dis+2.25×rad−1.77×tax−2.04×ptratio+1.13×b−3.61×lstat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eESc0OIPqRI6"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "# Initialize the Support Vector Regressor model\n",
        "svr_model = SVR()\n",
        "\n",
        "# Fit the model to the scaled training data\n",
        "svr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the scaled test set\n",
        "y_pred_svr = svr_model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics for the SVR model\n",
        "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
        "rmse_svr = np.sqrt(mse_svr)\n",
        "r2_svr = r2_score(y_test, y_pred_svr)\n",
        "\n",
        "print(f\"Mean Squared Error (MSE) for SVR: {mse_svr:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE) for SVR: {rmse_svr:.2f}\")\n",
        "print(f\"R-squared (R2) for SVR: {r2_svr:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfFTpT59qRI6"
      },
      "outputs": [],
      "source": [
        "# Extract features and target variable from the dataset\n",
        "\n",
        "\n",
        "cols = ['rm', 'age', 'tax', 'lstat']\n",
        "X = df[cols]\n",
        "y = df['medv']\n",
        "\n",
        "# Split the data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform both the training and test data\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize the Linear Regression model\n",
        "lr_model_scaled = LinearRegression()\n",
        "\n",
        "# Fit the model to the scaled training data\n",
        "lr_model_scaled.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the scaled test set\n",
        "y_pred_scaled = lr_model_scaled.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics for the scaled data\n",
        "mse_scaled = mean_squared_error(y_test, y_pred_scaled)\n",
        "rmse_scaled = np.sqrt(mse_scaled)\n",
        "r2_scaled = r2_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(f\"Mean Squared Error (MSE) for LR with selected cols: {mse_scaled :.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE) for LR with selected cols: {rmse_scaled:.2f}\")\n",
        "print(f\"R-squared (R2) for LR with selected cols: {r2_scaled :.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTpjAucZqRI6"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "# Initialize the Support Vector Regressor model\n",
        "svr_model = SVR()\n",
        "\n",
        "# Fit the model to the scaled training data\n",
        "svr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the scaled test set\n",
        "y_pred_svr = svr_model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics for the SVR model\n",
        "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
        "rmse_svr = np.sqrt(mse_svr)\n",
        "r2_svr = r2_score(y_test, y_pred_svr)\n",
        "\n",
        "\n",
        "print(f\"Mean Squared Error (MSE) for SVR with selected cols: {mse_svr:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE) for SVR with selected cols: {rmse_svr:.2f}\")\n",
        "print(f\"R-squared (R2) for SVR with selected cols: {r2_svr:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxYNh6yuqRI6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgIx3rbrrWSM"
      },
      "source": [
        "To try other datasets\n",
        "\n",
        "https://github.com/selva86/datasets/tree/master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83E0eOTRrX4y"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
